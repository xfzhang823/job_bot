{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248fa16e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e766cd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        column  non_null  nulls  min_len  max_len     avg_len\n",
      "0          url        19      0       47      241  122.684211\n",
      "1      company        19      0        3       18    9.578947\n",
      "2    job_title        19      0       19       71   40.684211\n",
      "3  source_file        19      0       67       67   67.000000\n",
      "4        stage        19      0       13       13   13.000000\n",
      "5    timestamp        19      0       26       26   26.000000\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from project_config import DUCKDB_FILE\n",
    "\n",
    "\n",
    "def describe_duckdb_table(db_path: str | Path, table_name: str) -> pd.DataFrame:\n",
    "    con = duckdb.connect(database=db_path, read_only=True)\n",
    "\n",
    "    columns_df = con.execute(f\"PRAGMA table_info('{table_name}')\").fetchdf()\n",
    "    columns = columns_df[\"name\"].tolist()\n",
    "\n",
    "    summary_rows = []\n",
    "\n",
    "    for col in columns:\n",
    "        row = con.execute(\n",
    "            f\"\"\"\n",
    "            SELECT\n",
    "                '{col}' AS column,\n",
    "                COUNT(\"{col}\") AS non_null,\n",
    "                COUNT(*) - COUNT(\"{col}\") AS nulls,\n",
    "                MIN(LENGTH(CAST(\"{col}\" AS VARCHAR))) AS min_len,\n",
    "                MAX(LENGTH(CAST(\"{col}\" AS VARCHAR))) AS max_len,\n",
    "                AVG(LENGTH(CAST(\"{col}\" AS VARCHAR))) AS avg_len\n",
    "            FROM {table_name}\n",
    "        \"\"\"\n",
    "        ).fetchone()\n",
    "        summary_rows.append(row)\n",
    "\n",
    "    summary_df = pd.DataFrame(\n",
    "        summary_rows,\n",
    "        columns=[\"column\", \"non_null\", \"nulls\", \"min_len\", \"max_len\", \"avg_len\"],\n",
    "    )\n",
    "    con.close()\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "summary = describe_duckdb_table(DUCKDB_FILE, \"job_urls\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6408e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         column  non_null  nulls  min_len  max_len      avg_len\n",
      "0           url        38      0       44      377   145.631579\n",
      "1        status        38      0        7        7     7.000000\n",
      "2       message        30      8       37       37    37.000000\n",
      "3     job_title        38      0       18       71    39.973684\n",
      "4       company        38      0        3       25     9.921053\n",
      "5      location        27     11       10      693    74.592593\n",
      "6   salary_info        25     13       20      323    81.840000\n",
      "7   posted_date         9     29        0       19     8.777778\n",
      "8       content        38      0      229     9045  3754.789474\n",
      "9   source_file        38      0       61       61    61.000000\n",
      "10        stage        38      0       13       13    13.000000\n",
      "11    timestamp        38      0       26       26    26.000000\n",
      "                                                 url  \\\n",
      "0  https://www.google.com/about/careers/applicati...   \n",
      "1  https://www.capitalonecareers.com/job/-/-/234/...   \n",
      "2  https://boards.greenhouse.io/embed/job_app?tok...   \n",
      "3  https://www.amazon.jobs/en/jobs/2696123/resear...   \n",
      "4  https://www.amazon.jobs/en/jobs/2742527/sr-gen...   \n",
      "5  https://www.amazon.jobs/en/jobs/2684745/produc...   \n",
      "6  https://jobs.careers.microsoft.com/us/en/job/1...   \n",
      "7  https://searchjobs.libertymutualgroup.com/care...   \n",
      "8  https://www.metacareers.com/jobs/5222322868250...   \n",
      "9  https://careers.adobe.com/us/en/job/ADOBUSR151...   \n",
      "\n",
      "                                             content  \n",
      "0  {\"minimum_qualifications\": [\"Bachelor's degree...  \n",
      "1  {\"overview\": \"We are looking for an experience...  \n",
      "2  {\"overview\": \"Amplitude is a leading digital a...  \n",
      "3  {\"overview\": \"As a Research Manager within the...  \n",
      "4  {\"overview\": \"Amazon Web Services (AWS) is loo...  \n",
      "5  {\"overview\": \"\", \"minimum_qualifications\": [\"1...  \n",
      "6  {\"Overview\": \"The Business Development team at...  \n",
      "7  {\"Job Category\": \"Strategy & Planning\", \"Subca...  \n",
      "8  {\"Mission\": \"Product Strategyâ€™s mission is to ...  \n",
      "9  {\"description\": \"We are looking for a Sr. Dire...  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import duckdb\n",
    "from project_config import DUCKDB_FILE as db_path\n",
    "\n",
    "\n",
    "def describe_duckdb_table(db_path: str | Path, table_name: str) -> pd.DataFrame:\n",
    "    con = duckdb.connect(database=db_path, read_only=True)\n",
    "\n",
    "    columns_df = con.execute(f\"PRAGMA table_info('{table_name}')\").fetchdf()\n",
    "    columns = columns_df[\"name\"].tolist()\n",
    "\n",
    "    summary_rows = []\n",
    "\n",
    "    for col in columns:\n",
    "        row = con.execute(\n",
    "            f\"\"\"\n",
    "            SELECT\n",
    "                '{col}' AS column,\n",
    "                COUNT(\"{col}\") AS non_null,\n",
    "                COUNT(*) - COUNT(\"{col}\") AS nulls,\n",
    "                MIN(LENGTH(CAST(\"{col}\" AS VARCHAR))) AS min_len,\n",
    "                MAX(LENGTH(CAST(\"{col}\" AS VARCHAR))) AS max_len,\n",
    "                AVG(LENGTH(CAST(\"{col}\" AS VARCHAR))) AS avg_len\n",
    "            FROM {table_name}\n",
    "        \"\"\"\n",
    "        ).fetchone()\n",
    "        summary_rows.append(row)\n",
    "\n",
    "    summary_df = pd.DataFrame(\n",
    "        summary_rows,\n",
    "        columns=[\"column\", \"non_null\", \"nulls\", \"min_len\", \"max_len\", \"avg_len\"],\n",
    "    )\n",
    "    con.close()\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def print_columns(\n",
    "    db_path: Path | str, table_name: str, columns: list[str], limit: int = 10\n",
    "):\n",
    "    con = duckdb.connect(str(db_path))\n",
    "\n",
    "    col_str = \", \".join(columns)\n",
    "    query = f\"SELECT {col_str} FROM {table_name} LIMIT {limit}\"\n",
    "\n",
    "    df = con.execute(query).fetchdf()\n",
    "    print(df)\n",
    "\n",
    "    con.close()\n",
    "\n",
    "\n",
    "summary = describe_duckdb_table(db_path, \"job_postings\")\n",
    "print(summary)\n",
    "\n",
    "print_columns(db_path, \"job_postings\", [\"url\", \"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
