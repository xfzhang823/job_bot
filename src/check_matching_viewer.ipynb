{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewer to Check Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Job URLs, Descriptions/Postings, & Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "from IPython.display import display, Markdown\n",
    "from project_config import (\n",
    "    JOB_POSTING_URLS_FILE,\n",
    "    JOB_POSTING_URLS_FILTERED_FILE,\n",
    "    JOB_POSTING_URLS_TO_EXCLUDE_FILE,\n",
    "    JOB_DESCRIPTIONS_JSON_FILE,\n",
    "    JOB_REQUIREMENTS_JSON_FILE,\n",
    ")\n",
    "\n",
    "\n",
    "def load_and_decode_json(json_file):\n",
    "    \"\"\"Load a JSON file and decode all Unicode escape sequences.\"\"\"\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)  # JSON decoder auto-converts \\u2013 and \\u2014\n",
    "    return data\n",
    "\n",
    "\n",
    "def format_json_readable(json_obj, indent=2, wrap_width=80):\n",
    "    \"\"\"\n",
    "    Formats JSON with indentation and wraps long text for easier readability.\n",
    "    \"\"\"\n",
    "    formatted_json = json.dumps(\n",
    "        json_obj, indent=indent, ensure_ascii=False\n",
    "    )  # Pretty print JSON\n",
    "\n",
    "    # Wrap long lines within values\n",
    "    formatted_json = \"\\n\".join(\n",
    "        [\n",
    "            textwrap.fill(line, width=wrap_width) if len(line) > wrap_width else line\n",
    "            for line in formatted_json.split(\"\\n\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Simulate line breaks: Insert extra spacing between key sections\n",
    "    formatted_json = formatted_json.replace(\"{\", \"{\\n\\n\")  # Before nested objects\n",
    "    formatted_json = formatted_json.replace(\"},\", \"},\\n\\n\")  # After objects\n",
    "    formatted_json = formatted_json.replace(\"]\", \"]\\n\\n\")  # After lists\n",
    "\n",
    "    return formatted_json\n",
    "\n",
    "\n",
    "def display_json_pretty(json_file, wrap_width=100):\n",
    "    \"\"\"Loads, decodes, formats, and displays JSON with simulated line breaks in Jupyter Notebook.\"\"\"\n",
    "\n",
    "    # Load and decode JSON\n",
    "    data = load_and_decode_json(json_file)\n",
    "\n",
    "    # Format JSON for readability\n",
    "    formatted_json = format_json_readable(data, wrap_width=wrap_width)\n",
    "\n",
    "    # Display with Markdown to prevent horizontal scrolling\n",
    "    display(Markdown(f\"```json\\n{formatted_json}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Posting URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Pipeline to Filter URLs File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 11:39:33,351 - pipelines.filter_job_posting_urls_mini_pipeline - INFO - Loading main job postings from C:\\github\\job_bot\\input_output\\input\\job_posting_urls.json\n",
      "2025-03-08 11:39:33,352 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\input\\job_posting_urls.json\n",
      "2025-03-08 11:39:33,353 - pipelines.filter_job_posting_urls_mini_pipeline - INFO - Loading exclusion URLs from C:\\github\\job_bot\\input_output\\input\\job_posting_urls_to_exclude.json\n",
      "2025-03-08 11:39:33,373 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\input\\job_posting_urls_to_exclude.json\n",
      "2025-03-08 11:39:33,375 - pipelines.filter_job_posting_urls_mini_pipeline - INFO - Excluding 19 URLs from main job postings.\n",
      "2025-03-08 11:39:33,376 - pipelines.filter_job_posting_urls_mini_pipeline - INFO - Filtered out 19 job postings; 13 remain.\n",
      "2025-03-08 11:39:33,378 - utils.generic_utils - INFO - Data successfully saved to C:\\github\\job_bot\\input_output\\input\\job_posting_urls_filtered.json.\n",
      "2025-03-08 11:39:33,380 - pipelines.filter_job_posting_urls_mini_pipeline - INFO - Filtered job postings saved successfully to C:\\github\\job_bot\\input_output\\input\\job_posting_urls_filtered.json\n"
     ]
    }
   ],
   "source": [
    "from pipelines.filter_job_posting_urls_mini_pipeline import (\n",
    "    run_filtering_job_posting_urls_mini_pipe_line as filter_urls,\n",
    ")\n",
    "\n",
    "filter_urls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "['AWS', 'Accenture', 'Adobe', 'Advisor360 Degrees', 'Airtable', 'Amazon', 'Amazon', 'Amazon', 'Amplitude', 'Blend', 'Capital One', 'DEPT', 'Deloitte', 'Deloitte', 'Deloitte', 'DigitalOcean', 'Figma', 'Flextronics', 'Glean', 'Google', 'Liberty Mutual', 'Liberty Mutual', 'Liberty Mutual Insurance', 'Meta', 'Microsoft', 'MongoDB', 'Oracle', 'PwC', 'Snowflake', 'TRACE3', 'ThermoFisher Scientific', 'Veeva']\n"
     ]
    }
   ],
   "source": [
    "json_file = JOB_POSTING_URLS_FILE\n",
    "\n",
    "data = load_and_decode_json(json_file=json_file)\n",
    "print(len(data))\n",
    "companies = sorted(\n",
    "    [job_data.get(\"company\", \"Unknown Company\") for job_data in data.values()]\n",
    ")\n",
    "print(companies)\n",
    "# for key, value in data.items():\n",
    "\n",
    "\n",
    "# display_json_pretty(json_file, wrap_width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtered URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Accenture',\n",
       " 'Advisor360 Degrees',\n",
       " 'Airtable',\n",
       " 'Amazon',\n",
       " 'Blend',\n",
       " 'Deloitte',\n",
       " 'Deloitte',\n",
       " 'Deloitte',\n",
       " 'DigitalOcean',\n",
       " 'Glean',\n",
       " 'Liberty Mutual',\n",
       " 'Snowflake',\n",
       " 'Veeva']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "json_file = JOB_POSTING_URLS_FILTERED_FILE\n",
    "\n",
    "data = load_and_decode_json(json_file=json_file)\n",
    "print(len(data))\n",
    "companies = sorted(\n",
    "    [job_data.get(\"company\", \"Unknown Company\") for job_data in data.values()]\n",
    ")\n",
    "display(companies)\n",
    "# for key, value in data.items():\n",
    "\n",
    "\n",
    "# display_json_pretty(json_file, wrap_width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Postings/Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "https://careers.snowflake.com/us/en/job/SNCOUS5AF10A9C7A01464788ABD17AECBEE52EEXTERNALENUS1CC71A00229E4662B768527743E6164F/Director-Product-Marketing-Analytics?utm_source=Q2P9NP2NNP&utm_medium=phenom-feeds&gh_src=ed5543a62\n"
     ]
    }
   ],
   "source": [
    "json_file = JOB_DESCRIPTIONS_JSON_FILE\n",
    "\n",
    "data = load_and_decode_json(json_file=json_file)\n",
    "print(len(data))\n",
    "for key in data.keys():\n",
    "    print(key) if \"snowflake\" in key else None\n",
    "# json_file = r\"C:\\github\\job_bot\\input_output\\preprocessing\\jobpostings.json\"\n",
    "# display_json_pretty(JOB_REQUIREMENTS_JSON_FILE, wrap_width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "dict_keys(['https://www.google.com/about/careers/applications/jobs/results/113657145978692294-ai-market-intelligence-principal/?src=Online/LinkedIn/linkedin_us&utm_source=linkedin&utm_medium=jobposting&utm_campaign=contract&utm_medium=jobboard&utm_source=linkedin', 'https://www.capitalonecareers.com/job/-/-/234/66270465536?p_sid=ep3Sfxb&p_uid=sDBMWC5VxQ&source=rd_linkedin_job_posting_tm&ss=paid&utm_campaign=capone_all_jobs_24&utm_content=pj_board&utm_medium=jobad&utm_source=linkedin+slotted&dclid=CPGV3bef44gDFUEGTwgd4DoHPg', 'https://boards.greenhouse.io/embed/job_app?token=7600823002&gh_src=ab9f35b82', 'https://www.amazon.jobs/en/jobs/2696123/research-manager-strategy-and-insights-gca-marketing?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid', 'https://www.amazon.jobs/en/jobs/2742527/sr-generative-ai-strategist-generative-ai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid', 'https://www.amazon.jobs/en/jobs/2684745/product-manager-artificial-general-intelligence-data-services?cmpid=SPLICX0248M&ss=paid&utm_campaign=cxro&utm_content=job_posting&utm_medium=social_media&utm_source=linkedin.com', 'https://jobs.careers.microsoft.com/us/en/job/1771714/Head-of-Partner-Intelligence-and-Strategy?jobsource=linkedin', 'https://searchjobs.libertymutualgroup.com/careers/job/618499888480?microsite=libertymutual.com&domain=libertymutual.com&utm_source=Job+Board&utm_campaign=LinkedIn+Jobs&extcmp=bof-paid-text-lkin-aljb', 'https://www.metacareers.com/jobs/522232286825036/?rx_campaign=Linkedin1&rx_ch=connector&rx_group=126320&rx_job=a1KDp00000E28eGMAR&rx_medium=post&rx_r=none&rx_source=Linkedin&rx_ts=20240927T121201Z&rx_vp=slots&utm_campaign=Job%2Bboard&utm_medium=jobs&utm_source=LIpaid&rx_viewer=e3efacca649311ef917d17a1705b89ba0dc4e1e7a57f4231bbce94a604c83931', 'https://flextronics.wd1.myworkdayjobs.com/en-US/Careers/job/Sr-Manager-AI-Strategy_WD191060?source=LinkedIn_Slots', 'https://www.digitalocean.com/careers/position/apply?gh_jid=6437995&gh_src=312a08e31us', 'https://careers.adobe.com/us/en/job/ADOBUSR151695EXTERNALENUS/Sr-Director-Applied-AI-ML-Discovery?utm_source=linkedin&utm_medium=phenom-feeds&source=LinkedIn', 'https://boards.greenhouse.io/gleanwork/jobs/4425502005?source=LinkedIn', 'https://jobs.thermofisher.com/global/en/job/R-01298008/Market-Competitive-Intelligence-Manager?rx_ch=jobpost&rx_job=R-01298008-1&rx_medium=post&rx_paid=0&rx_r=none&rx_source=linkedin&rx_ts=20250206T184002Z&rx_vp=linkedindirectindex&utm_medium=post&utm_source=recruitics_linkedindirectindex&refId=34jd24&rx_viewer=e3efacca649311ef917d17a1705b89ba0dc4e1e7a57f4231bbce94a604c83931', 'https://searchjobs.libertymutualgroup.com/careers/job/618501232921?microsite=libertymutual.com&domain=libertymutual.com&utm_source=Job+Board&utm_campaign=LinkedIn+Jobs&extcmp=bof-paid-text-lkin-aljb', 'https://job-boards.greenhouse.io/airtable/jobs/7603873002?gh_src=aef790d02us', 'https://careers.veeva.com/job/365ff44c-8e0a-42b4-a117-27b409a77753/director-crossix-analytics-services-boston-ma/?lever-source=Linkedin', 'https://job-boards.greenhouse.io/figma/jobs/5336109004?gh_jid=5336109004&gh_src=28109e334us&source=LinkedIn', 'https://job-boards.greenhouse.io/trace3/jobs/6163213?gh_src=b81c67b41us', 'https://jobs.us.pwc.com/job/-/-/932/76064801072?utm_source=linkedin.com&utm_campaign=core_media&utm_medium=social_media&utm_content=job_posting&ss=paid&dclid=CjgKEAiAwaG9BhCY3ayl47PW8lcSJAA_gCfjt-rzWhQetHLIbJdJBVocWQm2BRNcBgOARxhGyR9bgvD_BwE', 'https://boards.greenhouse.io/dept/jobs/6564521', 'https://www.mongodb.com/careers/jobs/6466537', 'https://apply.deloitte.com/careers/InviteToApply?jobId=210031&source=LinkedIn', 'https://apply.deloitte.com/careers/InviteToApply?jobId=199586&source=LinkedIn', 'https://apply.deloitte.com/careers/InviteToApply?jobId=201718&source=LinkedIn', 'https://advisor360.breezy.hr/p/2e1636328c7d-senior-product-manager-ai-analytics-insights', 'https://careers.snowflake.com/us/en/job/SNCOUS5AF10A9C7A01464788ABD17AECBEE52EEXTERNALENUS1CC71A00229E4662B768527743E6164F/Director-Product-Marketing-Analytics?utm_source=Q2P9NP2NNP&utm_medium=phenom-feeds&gh_src=ed5543a62', 'https://www.amazon.jobs/en/jobs/2905092/senior-manger-partner-strategy-genai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid', 'https://www.accenture.com/us-en/careers/jobdetails?id=R00251798_en&src=LINKEDINJP', 'https://jobs.smartrecruiters.com/Blend360/744000042638791-director-ai-strategy?trid=2d92f286-613b-4daf-9dfa-6340ffbecf73'])\n"
     ]
    }
   ],
   "source": [
    "json_file = JOB_REQUIREMENTS_JSON_FILE\n",
    "\n",
    "data = load_and_decode_json(json_file=json_file)\n",
    "print(len(data))\n",
    "print(data.keys())\n",
    "# json_file = r\"C:\\github\\job_bot\\input_output\\preprocessing\\jobpostings.json\"\n",
    "# display_json_pretty(JOB_REQUIREMENTS_JSON_FILE, wrap_width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Iteration 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import textwrap\n",
    "from IPython.display import display, Markdown\n",
    "from project_config import (\n",
    "    JOB_POSTING_URLS_FILE,\n",
    "    JOB_DESCRIPTIONS_JSON_FILE,\n",
    "    JOB_REQUIREMENTS_JSON_FILE,\n",
    "    ITERATE_0_OPENAI_DIR,\n",
    "    mapping_file_name,\n",
    "    REQS_FILES_ITERATE_0_OPENAI_DIR,\n",
    "    RESPS_FILES_ITERATE_0_OPENAI_DIR,\n",
    "    SIMILARITY_METRICS_ITERATE_0_OPENAI_DIR,\n",
    "    ITERATE_0_ANTHROPIC_DIR,\n",
    "    REQS_FILES_ITERATE_0_ANTHROPIC_DIR,\n",
    "    RESPS_FILES_ITERATE_0_ANTHROPIC_DIR,\n",
    "    SIMILARITY_METRICS_ITERATE_0_ANTHROPIC_DIR,\n",
    "    # URL_TO_FILE_MAPPING_FILE_ITERATE_0_OPENAI,\n",
    "    # URL_TO_FILE_MAPPING_FILE_ITERATE_0_ANTHROPIC,\n",
    ")\n",
    "\n",
    "\n",
    "def load_and_decode_json(json_file):\n",
    "    \"\"\"Load a JSON file and decode all Unicode escape sequences.\"\"\"\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)  # JSON decoder auto-converts \\u2013 and \\u2014\n",
    "    return data\n",
    "\n",
    "\n",
    "def format_json_readable(json_obj, indent=2, wrap_width=80):\n",
    "    \"\"\"\n",
    "    Formats JSON with indentation and wraps long text for easier readability.\n",
    "    \"\"\"\n",
    "    formatted_json = json.dumps(\n",
    "        json_obj, indent=indent, ensure_ascii=False\n",
    "    )  # Pretty print JSON\n",
    "\n",
    "    # Wrap long lines within values\n",
    "    formatted_json = \"\\n\".join(\n",
    "        [\n",
    "            textwrap.fill(line, width=wrap_width) if len(line) > wrap_width else line\n",
    "            for line in formatted_json.split(\"\\n\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Simulate line breaks: Insert extra spacing between key sections\n",
    "    formatted_json = formatted_json.replace(\"{\", \"{\\n\\n\")  # Before nested objects\n",
    "    formatted_json = formatted_json.replace(\"},\", \"},\\n\\n\")  # After objects\n",
    "    formatted_json = formatted_json.replace(\"]\", \"]\\n\\n\")  # After lists\n",
    "\n",
    "    return formatted_json\n",
    "\n",
    "\n",
    "def display_json_pretty(json_file, wrap_width=100):\n",
    "    \"\"\"Loads, decodes, formats, and displays JSON with simulated line breaks in Jupyter Notebook.\"\"\"\n",
    "\n",
    "    # Load and decode JSON\n",
    "    data = load_and_decode_json(json_file)\n",
    "\n",
    "    # Format JSON for readability\n",
    "    formatted_json = format_json_readable(data, wrap_width=wrap_width)\n",
    "\n",
    "    # Display with Markdown to prevent horizontal scrolling\n",
    "    display(Markdown(f\"```json\\n{formatted_json}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 19:20:11,073 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\url_to_file_mapping.json\n",
      "2025-03-08 19:20:11,074 - evaluation_optimization.create_mapping_file - INFO - Loaded and validated mapping file from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\url_to_file_mapping.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job URLs:\n",
      "Number of URLs: 30\n",
      "1. https://www.google.com/about/careers/applications/jobs/results/113657145978692294-ai-market-intelligence-principal/?src=Online/LinkedIn/linkedin_us&utm_source=linkedin&utm_medium=jobposting&utm_campaign=contract&utm_medium=jobboard&utm_source=linkedin\n",
      "\n",
      "2. https://www.capitalonecareers.com/job/-/-/234/66270465536?p_sid=ep3Sfxb&p_uid=sDBMWC5VxQ&source=rd_linkedin_job_posting_tm&ss=paid&utm_campaign=capone_all_jobs_24&utm_content=pj_board&utm_medium=jobad&utm_source=linkedin+slotted&dclid=CPGV3bef44gDFUEGTwgd4DoHPg\n",
      "\n",
      "3. https://boards.greenhouse.io/embed/job_app?token=7600823002&gh_src=ab9f35b82\n",
      "\n",
      "4. https://www.amazon.jobs/en/jobs/2696123/research-manager-strategy-and-insights-gca-marketing?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "\n",
      "5. https://www.amazon.jobs/en/jobs/2742527/sr-generative-ai-strategist-generative-ai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "\n",
      "6. https://www.amazon.jobs/en/jobs/2684745/product-manager-artificial-general-intelligence-data-services?cmpid=SPLICX0248M&ss=paid&utm_campaign=cxro&utm_content=job_posting&utm_medium=social_media&utm_source=linkedin.com\n",
      "\n",
      "7. https://jobs.careers.microsoft.com/us/en/job/1771714/Head-of-Partner-Intelligence-and-Strategy?jobsource=linkedin\n",
      "\n",
      "8. https://searchjobs.libertymutualgroup.com/careers/job/618499888480?microsite=libertymutual.com&domain=libertymutual.com&utm_source=Job+Board&utm_campaign=LinkedIn+Jobs&extcmp=bof-paid-text-lkin-aljb\n",
      "\n",
      "9. https://www.metacareers.com/jobs/522232286825036/?rx_campaign=Linkedin1&rx_ch=connector&rx_group=126320&rx_job=a1KDp00000E28eGMAR&rx_medium=post&rx_r=none&rx_source=Linkedin&rx_ts=20240927T121201Z&rx_vp=slots&utm_campaign=Job%2Bboard&utm_medium=jobs&utm_source=LIpaid&rx_viewer=e3efacca649311ef917d17a1705b89ba0dc4e1e7a57f4231bbce94a604c83931\n",
      "\n",
      "10. https://job-boards.greenhouse.io/airtable/jobs/7603873002?gh_src=aef790d02us\n",
      "\n",
      "11. https://careers.adobe.com/us/en/job/ADOBUSR151695EXTERNALENUS/Sr-Director-Applied-AI-ML-Discovery?utm_source=linkedin&utm_medium=phenom-feeds&source=LinkedIn\n",
      "\n",
      "12. https://jobs.us.pwc.com/job/-/-/932/76064801072?utm_source=linkedin.com&utm_campaign=core_media&utm_medium=social_media&utm_content=job_posting&ss=paid&dclid=CjgKEAiAwaG9BhCY3ayl47PW8lcSJAA_gCfjt-rzWhQetHLIbJdJBVocWQm2BRNcBgOARxhGyR9bgvD_BwE\n",
      "\n",
      "13. https://apply.deloitte.com/careers/InviteToApply?jobId=199586&source=LinkedIn\n",
      "\n",
      "14. https://careers.snowflake.com/us/en/job/SNCOUS5AF10A9C7A01464788ABD17AECBEE52EEXTERNALENUS1CC71A00229E4662B768527743E6164F/Director-Product-Marketing-Analytics?utm_source=Q2P9NP2NNP&utm_medium=phenom-feeds&gh_src=ed5543a62\n",
      "\n",
      "15. https://apply.deloitte.com/careers/InviteToApply?jobId=201718&source=LinkedIn\n",
      "\n",
      "16. https://advisor360.breezy.hr/p/2e1636328c7d-senior-product-manager-ai-analytics-insights\n",
      "\n",
      "17. https://apply.deloitte.com/careers/InviteToApply?jobId=210031&source=LinkedIn\n",
      "\n",
      "18. https://www.accenture.com/us-en/careers/jobdetails?id=R00251798_en&src=LINKEDINJP\n",
      "\n",
      "19. https://flextronics.wd1.myworkdayjobs.com/en-US/Careers/job/Sr-Manager-AI-Strategy_WD191060?source=LinkedIn_Slots\n",
      "\n",
      "20. https://www.digitalocean.com/careers/position/apply?gh_jid=6437995&gh_src=312a08e31us\n",
      "\n",
      "21. https://job-boards.greenhouse.io/figma/jobs/5336109004?gh_jid=5336109004&gh_src=28109e334us&source=LinkedIn\n",
      "\n",
      "22. https://boards.greenhouse.io/dept/jobs/6564521\n",
      "\n",
      "23. https://boards.greenhouse.io/gleanwork/jobs/4425502005?source=LinkedIn\n",
      "\n",
      "24. https://job-boards.greenhouse.io/trace3/jobs/6163213?gh_src=b81c67b41us\n",
      "\n",
      "25. https://www.mongodb.com/careers/jobs/6466537\n",
      "\n",
      "26. https://careers.veeva.com/job/365ff44c-8e0a-42b4-a117-27b409a77753/director-crossix-analytics-services-boston-ma/?lever-source=Linkedin\n",
      "\n",
      "27. https://jobs.smartrecruiters.com/Blend360/744000042638791-director-ai-strategy?trid=2d92f286-613b-4daf-9dfa-6340ffbecf73\n",
      "\n",
      "28. https://jobs.thermofisher.com/global/en/job/R-01298008/Market-Competitive-Intelligence-Manager?rx_ch=jobpost&rx_job=R-01298008-1&rx_medium=post&rx_paid=0&rx_r=none&rx_source=linkedin&rx_ts=20250206T184002Z&rx_vp=linkedindirectindex&utm_medium=post&utm_source=recruitics_linkedindirectindex&refId=34jd24&rx_viewer=e3efacca649311ef917d17a1705b89ba0dc4e1e7a57f4231bbce94a604c83931\n",
      "\n",
      "29. https://www.amazon.jobs/en/jobs/2905092/senior-manger-partner-strategy-genai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "\n",
      "30. https://searchjobs.libertymutualgroup.com/careers/job/618501232921?microsite=libertymutual.com&domain=libertymutual.com&utm_source=Job+Board&utm_campaign=LinkedIn+Jobs&extcmp=bof-paid-text-lkin-aljb\n",
      "\n",
      "\n",
      "\n",
      "sim_metrics paths:\n",
      "1. Google_AI_Market_Intelligence_Principal_sim_metrics_iter0.csv\n",
      "\n",
      "2. Capital_One_Director__AI_Platforms_sim_metrics_iter0.csv\n",
      "\n",
      "3. Amplitude_Marketing_Strategy___Analytics_Manager_sim_metrics_iter0.csv\n",
      "\n",
      "4. Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_sim_metrics_iter0.csv\n",
      "\n",
      "5. Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_sim_metrics_iter0.csv\n",
      "\n",
      "6. Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_sim_metrics_iter0.csv\n",
      "\n",
      "7. Microsoft_Head_of_Partner_Intelligence_and_Strategy_sim_metrics_iter0.csv\n",
      "\n",
      "8. Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_sim_metrics_iter0.csv\n",
      "\n",
      "9. Meta_Product_Strategy_Lead_sim_metrics_iter0.csv\n",
      "\n",
      "10. Airtable_Product_Manager__AI_sim_metrics_iter0.csv\n",
      "\n",
      "11. Adobe_Sr__Director__Applied_AI_ML__Discovery__sim_metrics_iter0.csv\n",
      "\n",
      "12. PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_sim_metrics_iter0.csv\n",
      "\n",
      "13. Deloitte_AI_Data_Specialist_sim_metrics_iter0.csv\n",
      "\n",
      "14. Snowflake_Director__Product_Marketing_-_Analytics_sim_metrics_iter0.csv\n",
      "\n",
      "15. Deloitte_Global_Business_Services__GBS__Strategy_Manager_sim_metrics_iter0.csv\n",
      "\n",
      "16. Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_sim_metrics_iter0.csv\n",
      "\n",
      "17. Deloitte_Market_Research_Sr_Manager_sim_metrics_iter0.csv\n",
      "\n",
      "18. Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_sim_metrics_iter0.csv\n",
      "\n",
      "19. Flex_Sr__Manager_AI_Strategy_sim_metrics_iter0.csv\n",
      "\n",
      "20. DigitalOcean_Director__Product_Management__AI_ML__sim_metrics_iter0.csv\n",
      "\n",
      "21. Figma_Researcher__Strategic_Growth_sim_metrics_iter0.csv\n",
      "\n",
      "22. DEPT__Director_of_Applied_AI_Strategy__Media_sim_metrics_iter0.csv\n",
      "\n",
      "23. Glean_Head_of_Competitive_Intelligence_sim_metrics_iter0.csv\n",
      "\n",
      "24. Trace3_Senior_Consultant__AI_Strategy__Remote__sim_metrics_iter0.csv\n",
      "\n",
      "25. MongoDB_Director__Competitive_Intelligence_sim_metrics_iter0.csv\n",
      "\n",
      "26. Veeva_Systems_Director_-_Crossix_Analytics_Services_sim_metrics_iter0.csv\n",
      "\n",
      "27. Blend_Director__AI_Strategy_sim_metrics_iter0.csv\n",
      "\n",
      "28. Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_sim_metrics_iter0.csv\n",
      "\n",
      "29. Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_sim_metrics_iter0.csv\n",
      "\n",
      "30. Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_sim_metrics_iter0.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "from models.resume_job_description_io_models import JobFileMappings\n",
    "from evaluation_optimization.create_mapping_file import load_mappings_model_from_json\n",
    "\n",
    "# from project_config import URL_TO_FILE_MAPPING_FILE_ITERATE_0_OPENAI\n",
    "\n",
    "directory = ITERATE_0_OPENAI_DIR\n",
    "mapping_file = directory / mapping_file_name\n",
    "\n",
    "file_mapping_model = load_mappings_model_from_json(mapping_file)\n",
    "\n",
    "print(\"Job URLs:\")\n",
    "print(f\"Number of URLs: {len(file_mapping_model.root.keys())}\")\n",
    "\n",
    "for index, url in enumerate(file_mapping_model.root.keys(), start=1):\n",
    "    print(f\"{index}. {url}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"sim_metrics paths:\")\n",
    "for index, jobpaths in enumerate(file_mapping_model.root.values(), start=1):\n",
    "    print(f\"{index}. {Path(jobpaths.sim_metrics).name}\")\n",
    "    print()\n",
    "\n",
    "# for job_url in mapping_model.root.keys():\n",
    "#     print(f\"{i}: {job_url}\")\n",
    "#     print()\n",
    "#     i += 1\n",
    "\n",
    "search_terms = [\"blend\", \"Amazon\", \"Blend\", \"Snowflake\"]\n",
    "\n",
    "\n",
    "# # Find URLs that contain the search term\n",
    "# matching_urls = [\n",
    "#     url\n",
    "#     for url in file_mapping_model.root.keys()\n",
    "#     if any(term.lower() in str(url).lower() for term in search_terms)\n",
    "# ]\n",
    "\n",
    "# print(\"Matching URLs:\")\n",
    "# for index, url in enumerate(matching_urls, start=1):\n",
    "#     print(f\"{index}. {url}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 19:24:50,044 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\url_to_file_mapping.json\n",
      "2025-03-08 19:24:50,045 - evaluation_optimization.create_mapping_file - INFO - Loaded and validated mapping file from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\url_to_file_mapping.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_metrics files\n",
      "Number of files: 11\n",
      "1. Adobe_Sr__Director__Applied_AI_ML__Discovery__sim_metrics_iter0.csv\n",
      "\n",
      "2. Airtable_Product_Manager__AI_sim_metrics_iter0.csv\n",
      "\n",
      "3. Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_sim_metrics_iter0.csv\n",
      "\n",
      "4. Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_sim_metrics_iter0.csv\n",
      "\n",
      "5. Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_sim_metrics_iter0.csv\n",
      "\n",
      "6. Amplitude_Marketing_Strategy___Analytics_Manager_sim_metrics_iter0.csv\n",
      "\n",
      "7. Capital_One_Director__AI_Platforms_sim_metrics_iter0.csv\n",
      "\n",
      "8. Google_AI_Market_Intelligence_Principal_sim_metrics_iter0.csv\n",
      "\n",
      "9. Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_sim_metrics_iter0.csv\n",
      "\n",
      "10. Meta_Product_Strategy_Lead_sim_metrics_iter0.csv\n",
      "\n",
      "11. Microsoft_Head_of_Partner_Intelligence_and_Strategy_sim_metrics_iter0.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "from models.resume_job_description_io_models import JobFileMappings\n",
    "from evaluation_optimization.create_mapping_file import load_mappings_model_from_json\n",
    "\n",
    "# from project_config import URL_TO_FILE_MAPPING_FILE_ITERATE_0_OPENAI\n",
    "\n",
    "directory = SIMILARITY_METRICS_ITERATE_0_OPENAI_DIR\n",
    "file_list = get_file_names(directory_path=directory)\n",
    "\n",
    "file_mapping_model = load_mappings_model_from_json(mapping_file)\n",
    "\n",
    "print(\"sim_metrics files\")\n",
    "print(f\"Number of files: {len(file_list)}\")\n",
    "\n",
    "for index, file_name in enumerate(file_list, start=1):\n",
    "    print(f\"{index}. {file_name}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "from IPython.display import display, Markdown\n",
    "from project_config import (\n",
    "    JOB_POSTING_URLS_FILE,\n",
    "    JOB_DESCRIPTIONS_JSON_FILE,\n",
    "    JOB_REQUIREMENTS_JSON_FILE,\n",
    "    ITERATE_1_ANTHROPIC_DIR,\n",
    "    mapping_file_name,\n",
    "    REQS_FILES_ITERATE_1_ANTHROPIC_DIR,\n",
    "    RESPS_FILES_ITERATE_1_ANTHROPIC_DIR,\n",
    "    SIMILARITY_METRICS_ITERATE_1_ANTHROPIC_DIR,\n",
    ")\n",
    "\n",
    "\n",
    "def load_and_decode_json(json_file):\n",
    "    \"\"\"Load a JSON file and decode all Unicode escape sequences.\"\"\"\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)  # JSON decoder auto-converts \\u2013 and \\u2014\n",
    "    return data\n",
    "\n",
    "\n",
    "def format_json_readable(json_obj, indent=2, wrap_width=80):\n",
    "    \"\"\"\n",
    "    Formats JSON with indentation and wraps long text for easier readability.\n",
    "    \"\"\"\n",
    "    formatted_json = json.dumps(\n",
    "        json_obj, indent=indent, ensure_ascii=False\n",
    "    )  # Pretty print JSON\n",
    "\n",
    "    # Wrap long lines within values\n",
    "    formatted_json = \"\\n\".join(\n",
    "        [\n",
    "            textwrap.fill(line, width=wrap_width) if len(line) > wrap_width else line\n",
    "            for line in formatted_json.split(\"\\n\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Simulate line breaks: Insert extra spacing between key sections\n",
    "    formatted_json = formatted_json.replace(\"{\", \"{\\n\\n\")  # Before nested objects\n",
    "    formatted_json = formatted_json.replace(\"},\", \"},\\n\\n\")  # After objects\n",
    "    formatted_json = formatted_json.replace(\"]\", \"]\\n\\n\")  # After lists\n",
    "\n",
    "    return formatted_json\n",
    "\n",
    "\n",
    "def display_json_pretty(json_file, wrap_width=100):\n",
    "    \"\"\"Loads, decodes, formats, and displays JSON with simulated line breaks in Jupyter Notebook.\"\"\"\n",
    "\n",
    "    # Load and decode JSON\n",
    "    data = load_and_decode_json(json_file)\n",
    "\n",
    "    # Format JSON for readability\n",
    "    formatted_json = format_json_readable(data, wrap_width=wrap_width)\n",
    "\n",
    "    # Display with Markdown to prevent horizontal scrolling\n",
    "    display(Markdown(f\"```json\\n{formatted_json}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responsibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_resps_nested_iter1.json',\n",
       " 'Adobe_Sr__Director__Applied_AI_ML__Discovery__resps_nested_iter1.json',\n",
       " 'Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_resps_nested_iter1.json',\n",
       " 'Airtable_Product_Manager__AI_resps_nested_iter1.json',\n",
       " 'Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_resps_nested_iter1.json',\n",
       " 'Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_resps_nested_iter1.json',\n",
       " 'Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_resps_nested_iter1.json',\n",
       " 'Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_resps_nested_iter1.json',\n",
       " 'Amplitude_Marketing_Strategy___Analytics_Manager_resps_nested_iter1.json',\n",
       " 'Blend_Director__AI_Strategy_resps_nested_iter1.json',\n",
       " 'Capital_One_Director__AI_Platforms_resps_nested_iter1.json',\n",
       " 'Deloitte_AI_Data_Specialist_resps_nested_iter1.json',\n",
       " 'Deloitte_Global_Business_Services__GBS__Strategy_Manager_resps_nested_iter1.json',\n",
       " 'Deloitte_Market_Research_Sr_Manager_resps_nested_iter1.json',\n",
       " 'DEPT__Director_of_Applied_AI_Strategy__Media_resps_nested_iter1.json',\n",
       " 'DigitalOcean_Director__Product_Management__AI_ML__resps_nested_iter1.json',\n",
       " 'Figma_Researcher__Strategic_Growth_resps_nested_iter1.json',\n",
       " 'Flex_Sr__Manager_AI_Strategy_resps_nested_iter1.json',\n",
       " 'Glean_Head_of_Competitive_Intelligence_resps_nested_iter1.json',\n",
       " 'Google_AI_Market_Intelligence_Principal_resps_nested_iter1.json',\n",
       " 'Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_resps_nested_iter1.json',\n",
       " 'Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_resps_nested_iter1.json',\n",
       " 'Meta_Product_Strategy_Lead_resps_nested_iter1.json',\n",
       " 'Microsoft_Head_of_Partner_Intelligence_and_Strategy_resps_nested_iter1.json',\n",
       " 'MongoDB_Director__Competitive_Intelligence_resps_nested_iter1.json',\n",
       " 'PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_resps_nested_iter1.json',\n",
       " 'Snowflake_Director__Product_Marketing_-_Analytics_resps_nested_iter1.json',\n",
       " 'Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_resps_nested_iter1.json',\n",
       " 'Trace3_Senior_Consultant__AI_Strategy__Remote__resps_nested_iter1.json',\n",
       " 'Veeva_Systems_Director_-_Crossix_Analytics_Services_resps_nested_iter1.json']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "\n",
    "directory = RESPS_FILES_ITERATE_1_ANTHROPIC_DIR\n",
    "\n",
    "files = get_file_names(directory_path=directory)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "\n",
      "File: Adobe_Sr__Director__Applied_AI_ML__Discovery__resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.0 -> Matches: 6\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "Least Matched Responsibility: 3.responsibilities.0 -> Matches: 7\n",
      "\n",
      "File: Airtable_Product_Manager__AI_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.3 -> Matches: 5\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 2.responsibilities.0 -> Matches: 8\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.5 -> Matches: 8\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.4 -> Matches: 12\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "\n",
      "File: Amplitude_Marketing_Strategy___Analytics_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.2 -> Matches: 13\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Blend_Director__AI_Strategy_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "\n",
      "File: Capital_One_Director__AI_Platforms_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 2.responsibilities.0 -> Matches: 9\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Deloitte_AI_Data_Specialist_resps_nested_iter1.json\n",
      "Total Responsibilities: 31\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "\n",
      "File: Deloitte_Global_Business_Services__GBS__Strategy_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 31\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 17\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 17\n",
      "\n",
      "File: Deloitte_Market_Research_Sr_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 31\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 6\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 6\n",
      "\n",
      "File: DEPT__Director_of_Applied_AI_Strategy__Media_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 9\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 9\n",
      "\n",
      "File: DigitalOcean_Director__Product_Management__AI_ML__resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 4.responsibilities.0 -> Matches: 6\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Figma_Researcher__Strategic_Growth_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 9\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 9\n",
      "\n",
      "File: Flex_Sr__Manager_AI_Strategy_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "\n",
      "File: Glean_Head_of_Competitive_Intelligence_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "\n",
      "File: Google_AI_Market_Intelligence_Principal_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.3 -> Matches: 12\n",
      "Least Matched Responsibility: 0.responsibilities.7 -> Matches: 1\n",
      "\n",
      "File: Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.3 -> Matches: 14\n",
      "Least Matched Responsibility: 0.responsibilities.1 -> Matches: 1\n",
      "\n",
      "File: Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 1.responsibilities.8 -> Matches: 14\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Meta_Product_Strategy_Lead_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.5 -> Matches: 11\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Microsoft_Head_of_Partner_Intelligence_and_Strategy_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.3 -> Matches: 15\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: MongoDB_Director__Competitive_Intelligence_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "\n",
      "File: PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 16\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 16\n",
      "\n",
      "File: Snowflake_Director__Product_Marketing_-_Analytics_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "\n",
      "File: Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Trace3_Senior_Consultant__AI_Strategy__Remote__resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 6\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 6\n",
      "\n",
      "File: Veeva_Systems_Director_-_Crossix_Analytics_Services_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 5\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models.resume_job_description_io_models import NestedResponsibilities\n",
    "\n",
    "# Load and validate the JSON data\n",
    "# file_name = \"Blend_Director__AI_Strategy_resps_nested_iter1.json\"\n",
    "file_name = (\n",
    "    \"Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_resps_nested_iter1.json\"\n",
    ")\n",
    "\n",
    "for file in files:\n",
    "    # file_name = \"Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_resps_nested_iter1.json\"\n",
    "    file_path = RESPS_FILES_ITERATE_1_ANTHROPIC_DIR / file\n",
    "\n",
    "    data = load_and_decode_json(file_path)\n",
    "    validated_data = NestedResponsibilities(**data)\n",
    "\n",
    "    # Compute the number of matched requirements per responsibility\n",
    "    num_requirements_per_responsibility = {\n",
    "        resp_key: len(resp.optimized_by_requirements)\n",
    "        for resp_key, resp in validated_data.responsibilities.items()\n",
    "    }\n",
    "\n",
    "    # Display some insights\n",
    "    most_matched_resp = max(\n",
    "        num_requirements_per_responsibility,\n",
    "        key=lambda k: num_requirements_per_responsibility[k],\n",
    "    )\n",
    "\n",
    "    least_matched_resp = min(\n",
    "        num_requirements_per_responsibility,\n",
    "        key=lambda k: num_requirements_per_responsibility[k],\n",
    "    )\n",
    "\n",
    "    print(f\"File: {file}\")\n",
    "    print(f\"Total Responsibilities: {len(num_requirements_per_responsibility)}\")\n",
    "    print(\n",
    "        f\"Most Matched Responsibility: {most_matched_resp} -> Matches: {num_requirements_per_responsibility[most_matched_resp]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Least Matched Responsibility: {least_matched_resp} -> Matches: {num_requirements_per_responsibility[least_matched_resp]}\"\n",
    "    )\n",
    "    print()\n",
    "\n",
    "# Find responsibilities with zero matches\n",
    "no_match_resps = [\n",
    "    resp_key\n",
    "    for resp_key, count in num_requirements_per_responsibility.items()\n",
    "    if count == 0\n",
    "]\n",
    "# print(f\"Responsibilities with no matched requirements: {len(no_match_resps)}\")\n",
    "\n",
    "# matches_list = validated_data.responsibilities[\"2.responsibilities.7\"]\n",
    "# match_list = matches_list.model_dump()\n",
    "# match_list\n",
    "# # Distribution of matches\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.hist(num_requirements_per_responsibility.values(), bins=10, edgecolor=\"black\")\n",
    "# plt.xlabel(\"Number of Matched Requirements\")\n",
    "# plt.ylabel(\"Number of Responsibilities\")\n",
    "# plt.title(\"Distribution of Requirement Matches per Responsibility\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_reqs_flat_iter1.json',\n",
       " 'Adobe_Sr__Director__Applied_AI_ML__Discovery__reqs_flat_iter1.json',\n",
       " 'Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_reqs_flat_iter1.json',\n",
       " 'Airtable_Product_Manager__AI_reqs_flat_iter1.json',\n",
       " 'Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_reqs_flat_iter1.json',\n",
       " 'Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_reqs_flat_iter1.json',\n",
       " 'Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_reqs_flat_iter1.json',\n",
       " 'Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_reqs_flat_iter1.json',\n",
       " 'Amplitude_Marketing_Strategy___Analytics_Manager_reqs_flat_iter1.json',\n",
       " 'Blend_Director__AI_Strategy_reqs_flat_iter1.json',\n",
       " 'Capital_One_Director__AI_Platforms_reqs_flat_iter1.json',\n",
       " 'Deloitte_AI_Data_Specialist_reqs_flat_iter1.json',\n",
       " 'Deloitte_Global_Business_Services__GBS__Strategy_Manager_reqs_flat_iter1.json',\n",
       " 'Deloitte_Market_Research_Sr_Manager_reqs_flat_iter1.json',\n",
       " 'DEPT__Director_of_Applied_AI_Strategy__Media_reqs_flat_iter1.json',\n",
       " 'DigitalOcean_Director__Product_Management__AI_ML__reqs_flat_iter1.json',\n",
       " 'Figma_Researcher__Strategic_Growth_reqs_flat_iter1.json',\n",
       " 'Flex_Sr__Manager_AI_Strategy_reqs_flat_iter1.json',\n",
       " 'Glean_Head_of_Competitive_Intelligence_reqs_flat_iter1.json',\n",
       " 'Google_AI_Market_Intelligence_Principal_reqs_flat_iter1.json',\n",
       " 'Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_reqs_flat_iter1.json',\n",
       " 'Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_reqs_flat_iter1.json',\n",
       " 'Meta_Product_Strategy_Lead_reqs_flat_iter1.json',\n",
       " 'Microsoft_Head_of_Partner_Intelligence_and_Strategy_reqs_flat_iter1.json',\n",
       " 'MongoDB_Director__Competitive_Intelligence_reqs_flat_iter1.json',\n",
       " 'PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_reqs_flat_iter1.json',\n",
       " 'Snowflake_Director__Product_Marketing_-_Analytics_reqs_flat_iter1.json',\n",
       " 'Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_reqs_flat_iter1.json',\n",
       " 'Trace3_Senior_Consultant__AI_Strategy__Remote__reqs_flat_iter1.json',\n",
       " 'Veeva_Systems_Director_-_Crossix_Analytics_Services_reqs_flat_iter1.json']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "\n",
    "directory = REQS_FILES_ITERATE_1_ANTHROPIC_DIR\n",
    "\n",
    "files = get_file_names(directory_path=directory)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_reqs_flat_iter1.json\n",
      "Number of requirements: 10\n"
     ]
    }
   ],
   "source": [
    "from models.resume_job_description_io_models import Requirements\n",
    "\n",
    "# Load and validate the JSON data\n",
    "\n",
    "file_name = \"Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_reqs_flat_iter1.json\"\n",
    "# file_name = \"Blend_Director__AI_Strategy_reqs_flat_iter1.json\"\n",
    "# file_name = 'Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_reqs_flat_iter1.json'\n",
    "\n",
    "file_path = REQS_FILES_ITERATE_1_ANTHROPIC_DIR / file_name\n",
    "\n",
    "data = load_and_decode_json(file_path)\n",
    "validated_data = Requirements(**data)\n",
    "\n",
    "print(f\"File: {file_name}\")\n",
    "print(f\"Number of requirements: {len(validated_data.requirements)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get File List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "from project_config import (\n",
    "    ITERATE_1_ANTHROPIC_DIR,\n",
    "    SIMILARITY_METRICS_ITERATE_1_ANTHROPIC_DIR,\n",
    ")\n",
    "\n",
    "files_dir = SIMILARITY_METRICS_ITERATE_1_ANTHROPIC_DIR\n",
    "\n",
    "file_list = get_file_names(files_dir, True)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Sim Metrics Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "csv_file = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_1\\similarity_metrics\\MongoDB_Director__Competitive_Intelligence_sim_metrics_iter1.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "set(df.requirement_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Tab Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "\n",
    "# Load similarity metrics CSV\n",
    "file_path = file_list[1]  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Pivot the data to match heatmap format\n",
    "pivot_df = df.pivot(\n",
    "    index=\"responsibility\", columns=\"requirement\", values=\"composite_score\"\n",
    ")\n",
    "\n",
    "# Create the heatmap\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "sns.heatmap(\n",
    "    pivot_df,\n",
    "    annot=False,\n",
    "    fmt=\".2f\",\n",
    "    cmap=cmap,\n",
    "    linewidths=1,\n",
    "    linecolor=\"black\",\n",
    "    cbar=True,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to wrap text inside heatmap cells\n",
    "def wrap_text(text, width=20):\n",
    "    return \"\\n\".join(textwrap.wrap(str(text), width))\n",
    "\n",
    "\n",
    "# Wrap y-axis labels\n",
    "wrapped_y_labels = [textwrap.fill(label, width=20) for label in pivot_df.index]\n",
    "ax.set_yticklabels(wrapped_y_labels, rotation=0)\n",
    "\n",
    "# Overlay text inside each cell (display composite score + wrapped requirement)\n",
    "for i, res in enumerate(pivot_df.index):\n",
    "    for j, req in enumerate(pivot_df.columns):\n",
    "        match = df[(df[\"responsibility\"] == res) & (df[\"requirement\"] == req)]\n",
    "        if not match.empty:\n",
    "            score = match.iloc[0][\"composite_score\"]\n",
    "            req_text = wrap_text(match.iloc[0][\"requirement\"], width=20)\n",
    "            display_text = f\"{score:.2f}\\n{req_text}\"\n",
    "            ax.text(\n",
    "                j + 0.5,\n",
    "                i + 0.5,\n",
    "                display_text,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=8,\n",
    "                color=\"black\",\n",
    "            )\n",
    "\n",
    "# Formatting adjustments\n",
    "ax.set_title(\"Responsibility vs Requirement Matching Grid (Text Inside Cells)\")\n",
    "ax.set_xlabel(\"Requirements\")\n",
    "ax.set_ylabel(\"Responsibilities\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Increase left margin\n",
    "plt.subplots_adjust(left=0.5)\n",
    "# box = ax.get_position()\n",
    "# ax.set_position([box.x0 + 0.2, box.y0, box.width, box.height])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "import numpy as np\n",
    "\n",
    "# Sample Responsibilities and Requirements\n",
    "responsibilities = [\n",
    "    \"Led strategic initiatives for IT transformation\",\n",
    "    \"Managed global vendor relationships\",\n",
    "    \"Optimized business intelligence reporting\",\n",
    "    \"Developed AI-driven analytics models\",\n",
    "    \"Implemented cloud security protocols\",\n",
    "]\n",
    "\n",
    "requirements = [\n",
    "    \"Experience in strategic IT leadership\",\n",
    "    \"Vendor management expertise\",\n",
    "    \"Business intelligence reporting experience\",\n",
    "    \"AI and machine learning proficiency\",\n",
    "    \"Cloud security best practices\",\n",
    "]\n",
    "\n",
    "# Generate random similarity scores between 0.5 and 1.0\n",
    "np.random.seed(42)\n",
    "data = []\n",
    "for res in responsibilities:\n",
    "    for req in requirements:\n",
    "        data.append(\n",
    "            {\n",
    "                \"responsibility\": res,\n",
    "                \"requirement\": req,\n",
    "                \"composite_score\": round(np.random.uniform(0.5, 1.0), 2),\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_dummy = pd.DataFrame(data)\n",
    "\n",
    "# Pivot table for heatmap\n",
    "pivot_df = df_dummy.pivot(\n",
    "    index=\"responsibility\", columns=\"requirement\", values=\"composite_score\"\n",
    ")\n",
    "\n",
    "# Create the heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "cmap = sns.color_palette(\"coolwarm\", as_cmap=True)  # Define color scheme\n",
    "\n",
    "# Generate heatmap\n",
    "sns.heatmap(\n",
    "    pivot_df,\n",
    "    annot=False,\n",
    "    fmt=\".2f\",\n",
    "    cmap=cmap,\n",
    "    linewidths=1,\n",
    "    linecolor=\"black\",\n",
    "    cbar=True,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to wrap text inside heatmap cells\n",
    "def wrap_text(text, width=20):\n",
    "    return \"\\n\".join(textwrap.wrap(str(text), width))\n",
    "\n",
    "\n",
    "# Overlay text inside each cell (score + requirement)\n",
    "for i, res in enumerate(pivot_df.index):\n",
    "    for j, req in enumerate(pivot_df.columns):\n",
    "        match = df_dummy[\n",
    "            (df_dummy[\"responsibility\"] == res) & (df_dummy[\"requirement\"] == req)\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            score = match.iloc[0][\"composite_score\"]\n",
    "            req_text = wrap_text(\n",
    "                match.iloc[0][\"requirement\"], width=20\n",
    "            )  # Wrap text for better display\n",
    "            display_text = f\"{score:.2f}\\n{req_text}\"  # Display similarity score + wrapped requirement text\n",
    "\n",
    "            ax.text(\n",
    "                j + 0.5,\n",
    "                i + 0.5,\n",
    "                display_text,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=8,\n",
    "                color=\"black\",\n",
    "            )\n",
    "\n",
    "# Formatting adjustments\n",
    "ax.set_title(\"Dummy Responsibility vs Requirement Heatmap (Text Inside Cells)\")\n",
    "ax.set_xlabel(\"Requirements\")\n",
    "ax.set_ylabel(\"Responsibilities\")\n",
    "plt.xticks(rotation=45, ha=\"right\")  # Rotate x-axis labels for better readability\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "\n",
    "# Load similarity metrics CSV\n",
    "file_path = file_list[1]  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a wrapped version of the requirement text (width=20)\n",
    "df[\"wrapped_requirement\"] = df[\"requirement\"].apply(\n",
    "    lambda x: \"\\n\".join(textwrap.wrap(str(x), width=20))\n",
    ")\n",
    "df[\"score_text\"] = df[\"composite_score\"].apply(lambda x: f\"{x:.2f}\")\n",
    "df[\"label\"] = df[\"score_text\"] + \"\\n\" + df[\"wrapped_requirement\"]\n",
    "\n",
    "# Build the heatmap chart\n",
    "heatmap = (\n",
    "    alt.Chart(df)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=alt.X(\"requirement:N\", title=\"Requirements\", axis=alt.Axis(labelAngle=45)),\n",
    "        y=alt.Y(\"responsibility:N\", title=\"Responsibilities\"),\n",
    "        color=alt.Color(\n",
    "            \"composite_score:Q\",\n",
    "            scale=alt.Scale(scheme=\"redblue\"),\n",
    "            title=\"Composite Score\",\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Build the text overlay chart\n",
    "# The key here is using the \"detail\" encoding so that each row is rendered individually.\n",
    "text_overlay = (\n",
    "    alt.Chart(df)\n",
    "    .mark_text(\n",
    "        fontSize=8,\n",
    "        color=\"black\",\n",
    "        align=\"left\",  # Set left alignment (change to 'center' if preferred)\n",
    "        baseline=\"middle\",\n",
    "    )\n",
    "    .encode(\n",
    "        x=alt.X(\"requirement:N\"),\n",
    "        y=alt.Y(\"responsibility:N\"),\n",
    "        text=alt.Text(\"label:N\"),\n",
    "        detail=\"label:N\",  # Force each label to be treated as a distinct detail\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine the heatmap and text overlay\n",
    "chart = (\n",
    "    (heatmap + text_overlay)\n",
    "    .properties(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        title=\"Responsibility vs Requirement Matching Grid (Text Inside Cells)\",\n",
    "    )\n",
    "    .configure_view(strokeWidth=0)\n",
    ")\n",
    "\n",
    "chart.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Cross Tab in Excel Instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "\n",
    "def create_pivot_table(sim_metrics_csv, output_csv):\n",
    "    \"\"\"\n",
    "    Reads the similarity metrics CSV and creates a pivot table:\n",
    "      - Index: responsibility_key\n",
    "      - Columns: requirement_key\n",
    "      - Values: responsibility\n",
    "    Then saves it as a new CSV file.\n",
    "    \"\"\"\n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(sim_metrics_csv)\n",
    "    # display(df.head(5))\n",
    "\n",
    "    # Pivot table with responsibility_key as index, requirement_key as columns, and responsibility as values\n",
    "    # Multi-index for columns: (requirement_key, requirement)\n",
    "    pivot_table = df.pivot(\n",
    "        index=\"responsibility_key\",\n",
    "        columns=[\"requirement_key\", \"requirement\"],  # Multi-index for columns\n",
    "        values=[\"responsibility\", \"composite_score\"],  # Multi-values in pivot\n",
    "    )\n",
    "\n",
    "    # Fill missing values with empty string\n",
    "    pivot_table = pivot_table.fillna(\"\")\n",
    "\n",
    "    # Save to CSV\n",
    "    pivot_table.to_csv(output_csv)\n",
    "\n",
    "    print(f\"Pivot table saved to {output_csv}\")\n",
    "\n",
    "    display(pivot_table.head(10))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define input and output file paths\n",
    "    input_csv = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\similarity_metrics\\Microsoft_Head_of_Partner_Intelligence_and_Strategy_sim_metrics_iter1.csv\"\n",
    "    output_csv = (\n",
    "        r\"C:\\github\\job_bot\\data\\matching_examples\\resp_vs_reqs_pivot_output_1.csv\"\n",
    "    )\n",
    "\n",
    "    # Call the function\n",
    "    create_pivot_table(input_csv, output_csv)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Color Fromatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.formatting.rule import ColorScaleRule\n",
    "\n",
    "\n",
    "def create_pivot_table(sim_metrics_csv, output_excel):\n",
    "    \"\"\"\n",
    "    Reads the CSV and creates a pivot table:\n",
    "      - Index: responsibility_key\n",
    "      - Columns: (requirement_key, requirement)\n",
    "      - Values: responsibility, composite_score\n",
    "    Then saves it as an Excel file and applies conditional formatting.\n",
    "    \"\"\"\n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(sim_metrics_csv)\n",
    "\n",
    "    # Format responsibility text based on composite_score\n",
    "    def format_responsibility(row):\n",
    "        if pd.isna(row[\"composite_score\"]):  # Handle NaN values\n",
    "            return row[\"responsibility\"]\n",
    "        elif row[\"composite_score\"] >= 0.75:\n",
    "            return f\" {row['responsibility']}\"  # Highlight important ones\n",
    "        elif row[\"composite_score\"] < 0.3:\n",
    "            return f\" {row['responsibility']}\"  # Mark low ones\n",
    "        return row[\"responsibility\"]\n",
    "\n",
    "    df[\"formatted_responsibility\"] = df.apply(format_responsibility, axis=1)\n",
    "\n",
    "    # Create pivot table\n",
    "    pivot_table = df.pivot_table(\n",
    "        index=\"responsibility_key\",\n",
    "        columns=[\"requirement_key\", \"requirement\"],\n",
    "        values=[\"formatted_responsibility\", \"composite_score\"],\n",
    "        aggfunc=\"first\",\n",
    "    )\n",
    "\n",
    "    pivot_table = pivot_table.fillna(\"\")\n",
    "    pivot_table.to_excel(output_excel)\n",
    "\n",
    "    # Apply Conditional Formatting\n",
    "    apply_conditional_formatting(output_excel)\n",
    "    print(f\"Pivot table saved and formatted at: {output_excel}\")\n",
    "\n",
    "\n",
    "def apply_conditional_formatting(excel_file):\n",
    "    \"\"\"Finds composite_score columns in the pivot and applies a color scale formatting.\"\"\"\n",
    "    wb = load_workbook(excel_file)\n",
    "    ws = wb.active\n",
    "\n",
    "    # Define a Color Scale Rule (Red - Yellow - Green)\n",
    "    color_rule = ColorScaleRule(\n",
    "        start_type=\"num\",\n",
    "        start_value=0,\n",
    "        start_color=\"FF6347\",  # Red\n",
    "        mid_type=\"num\",\n",
    "        mid_value=0.5,\n",
    "        mid_color=\"FFFF00\",  # Yellow\n",
    "        end_type=\"num\",\n",
    "        end_value=1,\n",
    "        end_color=\"00FF00\",  # Green\n",
    "    )\n",
    "\n",
    "    # Detect composite_score columns explicitly\n",
    "    for col in range(2, ws.max_column + 1):  # Columns start at 2\n",
    "        header = ws.cell(row=1, column=col).value  # Get column header\n",
    "        if header and \"composite_score\" in str(header):  # Ensure it's a valid column\n",
    "            col_letter = ws.cell(row=1, column=col).column_letter\n",
    "            ws.conditional_formatting.add(\n",
    "                f\"{col_letter}2:{col_letter}{ws.max_row}\", color_rule\n",
    "            )\n",
    "\n",
    "    wb.save(excel_file)\n",
    "    print(\" Conditional formatting applied successfully!\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_csv = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\similarity_metrics\\Microsoft_Head_of_Partner_Intelligence_and_Strategy_sim_metrics_iter1.csv\"\n",
    "    output_excel = (\n",
    "        r\"C:\\github\\job_bot\\data\\matching_examples\\resp_vs_reqs_pivot_output_1.xlsx\"\n",
    "    )\n",
    "\n",
    "    create_pivot_table(input_csv, output_excel)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Xlxings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlwings as xw\n",
    "\n",
    "\n",
    "def create_pivot_table(sim_metrics_csv, output_excel):\n",
    "    \"\"\"\n",
    "    Reads the CSV and creates a pivot table:\n",
    "      - Index: responsibility_key\n",
    "      - Columns: (requirement_key, requirement)\n",
    "      - Values: responsibility, composite_score\n",
    "    Then saves it as an Excel file and applies conditional formatting using xlwings.\n",
    "    \"\"\"\n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(sim_metrics_csv)\n",
    "\n",
    "    # Format responsibility text based on composite_score\n",
    "    def format_responsibility(row):\n",
    "        if pd.isna(row[\"composite_score\"]):  # Handle NaN values\n",
    "            return row[\"responsibility\"]\n",
    "        elif row[\"composite_score\"] >= 0.75:\n",
    "            return f\"{row['responsibility']}\"  # Highlight important ones\n",
    "        elif row[\"composite_score\"] < 0.3:\n",
    "            return f\"{row['responsibility']}\"  # Mark low ones\n",
    "        return row[\"responsibility\"]\n",
    "\n",
    "    df[\"formatted_responsibility\"] = df.apply(format_responsibility, axis=1)\n",
    "\n",
    "    # Create pivot table\n",
    "    pivot_table = df.pivot_table(\n",
    "        index=\"responsibility_key\",\n",
    "        columns=[\"requirement_key\", \"requirement\"],\n",
    "        values=[\"formatted_responsibility\", \"composite_score\"],\n",
    "        aggfunc=\"first\",\n",
    "    )\n",
    "\n",
    "    pivot_table = pivot_table.fillna(\"\")\n",
    "    pivot_table.to_excel(output_excel)\n",
    "\n",
    "    # Apply Conditional Formatting with xlwings\n",
    "    apply_xlwings_formatting(output_excel)\n",
    "    print(f\"Pivot table saved and formatted at: {output_excel}\")\n",
    "\n",
    "\n",
    "def apply_xlwings_formatting(excel_file):\n",
    "    \"\"\"Applies conditional formatting to value cells (not headers) based on their composite_score.\"\"\"\n",
    "    app = xw.App(visible=True)  # Keep Excel open for debugging\n",
    "    wb = xw.Book(excel_file)\n",
    "    ws = wb.sheets[0]\n",
    "\n",
    "    # Detect last row and last column\n",
    "    last_row = ws.range(\"A1\").expand(\"down\").last_cell.row\n",
    "    last_col = ws.range(\"A1\").expand(\"right\").last_cell.column\n",
    "\n",
    "    # Iterate through all data cells (excluding headers)\n",
    "    for row in range(2, last_row + 1):  # Start from row 2 to avoid header\n",
    "        for col in range(2, last_col + 1):  # Start from col 2 to avoid row labels\n",
    "            cell = ws.cells(row, col)\n",
    "            try:\n",
    "                value = float(cell.value)  # Convert value to float\n",
    "                if value >= 0.75:\n",
    "                    cell.api.Interior.Color = xw.utils.rgb_to_int(\n",
    "                        (0, 255, 0)\n",
    "                    )  # Green for high scores\n",
    "                elif value < 0.3:\n",
    "                    cell.api.Interior.Color = xw.utils.rgb_to_int(\n",
    "                        (255, 0, 0)\n",
    "                    )  # Red for low scores\n",
    "                else:\n",
    "                    cell.api.Interior.Color = xw.utils.rgb_to_int(\n",
    "                        (255, 255, 0)\n",
    "                    )  # Yellow for mid-range scores\n",
    "            except (ValueError, TypeError):\n",
    "                pass  # Ignore non-numeric values\n",
    "\n",
    "    wb.save()\n",
    "    wb.close()\n",
    "    app.quit()\n",
    "    print(\" Conditional formatting applied to value cells!\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_csv = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\similarity_metrics\\Microsoft_Head_of_Partner_Intelligence_and_Strategy_sim_metrics_iter1.csv\"\n",
    "    output_excel = (\n",
    "        r\"C:\\github\\job_bot\\data\\matching_examples\\resp_vs_reqs_pivot_output_1.xlsx\"\n",
    "    )\n",
    "\n",
    "    create_pivot_table(input_csv, output_excel)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_1\\responsibilities\\older_files\\PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_resps_nested_iter1.json\"\n",
    "\n",
    "with open(input_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "    for _ in range(30):  # Print first 30 lines\n",
    "        print(f.readline().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "import xlsxwriter\n",
    "\n",
    "\n",
    "def create_two_row_header_excel(sim_metrics_csv, output_file):\n",
    "    \"\"\"\n",
    "    Reads the similarity metrics CSV and creates an Excel file with:\n",
    "      - Row 1: \"Resp Key / Req Key\" + requirement keys\n",
    "      - Row 2: \"Requirements\" + requirement texts\n",
    "      - Rows 3+: One row per responsibility key, showing matched responsibility texts\n",
    "    \"\"\"\n",
    "    # 1) Load the similarity metrics CSV\n",
    "    df = pd.read_csv(sim_metrics_csv)\n",
    "\n",
    "    # 2) Extract unique requirements and map to their texts\n",
    "    req_map = df.groupby(\"requirement_key\")[\"requirement\"].first().to_dict()\n",
    "    req_keys = sorted(req_map.keys())  # Ordered list of requirement keys\n",
    "    req_texts = [req_map[k] for k in req_keys]  # Corresponding requirement texts\n",
    "\n",
    "    # 3) Extract unique responsibilities\n",
    "    resp_keys = sorted(df[\"responsibility_key\"].unique())\n",
    "\n",
    "    # 4) Create a dataframe to ensure all `requirement_keys` appear\n",
    "    full_pivot = pd.DataFrame(index=resp_keys, columns=req_keys).fillna(\"\")\n",
    "\n",
    "    # 5) Pivot the table to get optimized_text per (responsibility, requirement) pair\n",
    "    pivot = df.pivot(\n",
    "        index=\"responsibility_key\", columns=\"requirement_key\", values=\"responsibility\"\n",
    "    )\n",
    "\n",
    "    # 6) Merge the pivoted data into `full_pivot` to retain all columns\n",
    "    full_pivot.update(pivot)\n",
    "\n",
    "    # 7) Reset index so responsibility_key becomes a column\n",
    "    full_pivot = full_pivot.reset_index()\n",
    "\n",
    "    # 8) Prepare the first two header rows (Multi-layer Headers)\n",
    "    header1 = [\"Resp Key / Req Key\"] + req_keys  # First row (Keys)\n",
    "    header2 = [\"Requirements\"] + req_texts  # Second row (Descriptions)\n",
    "\n",
    "    # 9) Write to Excel using xlsxwriter (Multi-layer Headers)\n",
    "    workbook = xlsxwriter.Workbook(output_file)\n",
    "    worksheet = workbook.add_worksheet(\"CrossTab\")\n",
    "\n",
    "    # Apply formatting\n",
    "    bold_format = workbook.add_format(\n",
    "        {\"bold\": True, \"bg_color\": \"#002b36\", \"font_color\": \"white\"}\n",
    "    )\n",
    "    wrap_format = workbook.add_format({\"text_wrap\": True, \"align\": \"top\"})\n",
    "\n",
    "    # Merge header rows for multi-layer effect\n",
    "    worksheet.write_row(0, 0, header1, bold_format)  # Row 1: Requirement Keys\n",
    "    worksheet.write_row(1, 0, header2, wrap_format)  # Row 2: Requirement Texts\n",
    "\n",
    "    # Write responsibilities data (row 3+)\n",
    "    for row_idx, row in enumerate(full_pivot.itertuples(index=False), start=2):\n",
    "        worksheet.write_row(row_idx, 0, row, wrap_format)\n",
    "\n",
    "    # Adjust column widths for readability\n",
    "    worksheet.set_column(0, 0, 25)  # Responsibility Key column\n",
    "    worksheet.set_column(1, len(req_keys), 50)  # Requirement columns\n",
    "\n",
    "    workbook.close()\n",
    "    print(f\"Excel file created: {output_file}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Create a 2-row-header Excel from similarity metrics CSV.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sim_metrics_csv\",\n",
    "        required=True,\n",
    "        help=\"Path to the similarity metrics CSV file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output\",\n",
    "        required=True,\n",
    "        help=\"Path to the output Excel file (e.g., output.xlsx)\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    output_dir = os.path.dirname(args.output)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    create_two_row_header_excel(args.sim_metrics_csv, args.output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example file paths (adjust these as needed)\n",
    "    input_csv = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_1\\similarity_metrics\\Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_sim_metrics_iter1.csv\"\n",
    "    output_excel = (\n",
    "        r\"C:\\github\\job_bot\\data\\matching_examples\\resp_vs_reqs_crosstab_output_1.xlsx\"\n",
    "    )\n",
    "\n",
    "    # Directly call the function with desired column names:\n",
    "    create_two_row_header_excel(\n",
    "        sim_metrics_csv=input_csv,\n",
    "        output_file=output_excel,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_cross_tab(sim_metric_csv_file: Path, output_excel_file: Path):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(sim_metric_csv_file)\n",
    "\n",
    "    # Create a pivot table (cross-tab) based on responsibility_key and requirement_key\n",
    "    cross_tab = pd.pivot_table(\n",
    "        df,\n",
    "        values=\"responsibility\",\n",
    "        index=\"responsibility_key\",\n",
    "        columns=\"requirement_key\",\n",
    "        aggfunc=lambda x: \" \".join(x),\n",
    "    )\n",
    "\n",
    "    # Extract unique requirements and their corresponding keys\n",
    "    requirements = (\n",
    "        df[[\"requirement_key\", \"requirement\"]]\n",
    "        .drop_duplicates()\n",
    "        .set_index(\"requirement_key\")[\"requirement\"]\n",
    "    )\n",
    "\n",
    "    # Create a DataFrame for the requirements row with the same columns as cross_tab\n",
    "    requirements_row = pd.DataFrame([requirements], columns=cross_tab.columns)\n",
    "\n",
    "    # Combine the requirements row with the cross-tab table\n",
    "    cross_tab_with_requirements = pd.concat([requirements_row, cross_tab], axis=0)\n",
    "\n",
    "    # Reset the index to make the table cleaner\n",
    "    cross_tab_with_requirements.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Save the cross-tab table with requirements to an Excel file\n",
    "    cross_tab_with_requirements.to_excel(output_excel_file, index=False)\n",
    "\n",
    "    print(f\"Cross-tab table with requirements saved to {output_excel_file}\")\n",
    "\n",
    "\n",
    "# Input and output file paths\n",
    "input_csv = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_1\\similarity_metrics\\Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_sim_metrics_iter1.csv\"\n",
    "output_excel = (\n",
    "    r\"C:\\github\\job_bot\\data\\matching_examples\\resp_vs_reqs_crosstab_output_1.xlsx\"\n",
    ")\n",
    "\n",
    "# Create the cross-tab table\n",
    "create_cross_tab(Path(input_csv), Path(output_excel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsibilities=\"{'0.responsibilities.0': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Led strategic initiatives to optimize the service partner network for a prominent international IT company in the Asia Pacific market, resulting in enhanced local execution outcomes. Possess extensive experience in analytical roles.'), '1.down_to_earth.1': OptimizedText(optimized_text=\"Led the optimization of a major global IT vendor's service partner ecosystem in the Asia Pacific region, resulting in improved local implementation outcomes. Leveraged extensive client-facing experience to drive these strategic enhancements.\"), '1.down_to_earth.2': OptimizedText(optimized_text='Led strategic consulting and analytics initiatives for a leading global IT vendor, driving enhancements to their partner ecosystem in the Asia Pacific region and delivering improved local implementation outcomes.'), '1.down_to_earth.3': OptimizedText(optimized_text=\"Led the optimization of a major global IT vendor's service partner ecosystem in the Asia Pacific region, driving improved local implementation results.\"), '2.other.0': OptimizedText(optimized_text='Led strategic initiatives that optimized the service partner network of a leading global IT vendor in the Asia Pacific region, resulting in enhanced local implementation and improved client outcomes.')}), '0.responsibilities.1': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Led the strategic growth of a leading international services provider by identifying and scaling new engineering service opportunities in key emerging markets.'), '1.down_to_earth.1': OptimizedText(optimized_text=\"Led the evaluation and scaling of new engineering service opportunities in vital emerging markets to support a leading international services provider's growth strategy.\"), '1.down_to_earth.2': OptimizedText(optimized_text='Led strategic analysis to identify and capitalize on new engineering service opportunities in key emerging markets, driving growth for a leading international services provider.'), '1.down_to_earth.3': OptimizedText(optimized_text='Led the evaluation and scaling of new engineering service opportunities in vital emerging markets to support the growth strategy of a U.S.-based international services provider.'), '2.other.0': OptimizedText(optimized_text='Led the expansion strategy for a leading international services provider by identifying and scaling new engineering service opportunities in key emerging markets.')}), '0.responsibilities.2': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Authored impactful industry reports analyzing engineering services merger and acquisition trends, providing strategic insights into deal sizes, capability gaps, and emerging opportunities to inform decisions on IT and operational technology convergence.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led the co-authorship of an industry-recognized report on M&A trends in the engineering services sector, providing strategic insights into deal sizes, capability gaps, and emerging opportunities to guide decision-making on IT and operational technology convergence.'), '1.down_to_earth.2': OptimizedText(optimized_text='Authored insightful industry reports analyzing mergers and acquisitions in the engineering services sector. Provided comprehensive insights into deal sizes, capability gaps, and emerging opportunities, informing strategic decisions on IT and operational technology convergence.'), '1.down_to_earth.3': OptimizedText(optimized_text='Led the development of an industry-recognized report on mergers and acquisitions in the engineering services sector, delivering in-depth analysis of deal dynamics, capability gaps, and emerging opportunities at the intersection of IT and operational technology. Leveraged these insights to drive strategic planning and execution.'), '2.other.0': OptimizedText(optimized_text='Authored a comprehensive industry report on mergers and acquisitions in the engineering services sector, providing in-depth analysis of deal sizes, capability gaps, and emerging opportunities. The report informed strategic decisions regarding the convergence of information technology and operational technology.')}), '0.responsibilities.3': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Led efforts to enhance data quality and consistency through thorough financial analysis, standardized methodologies, and collaborative vendor engagements.'), '1.down_to_earth.1': OptimizedText(optimized_text='Drove the enhancement of data quality and consistency by integrating thorough financial analysis, standardizing methodologies, and conducting in-depth vendor engagements.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led consultative analytics engagements, leveraging financial analysis, standardized methodologies, and vendor collaborations to enhance data quality and consistency.'), '1.down_to_earth.3': OptimizedText(optimized_text='Transformed data quality and consistency by integrating financial analysis, standardizing methodologies, and engaging vendors.'), '2.other.0': OptimizedText(optimized_text='Drove impactful improvements in data quality and consistency by integrating thorough financial analysis, standardizing methodologies, and conducting in-depth vendor engagements.')}), '0.responsibilities.4': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Led the optimization of resource allocation through centralization of tasks, transitioning a significant portion of work to an offshore team in India, which resulted in increased efficiency and cost savings.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led offshore teams, optimized resource utilization, and enhanced operational efficiency. Extensive client-facing experience.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led the centralization of over 40% of tasks to an offshore team in India, optimizing resource allocation and driving significant improvements in team productivity and efficiency.'), '1.down_to_earth.3': OptimizedText(optimized_text='Centralized over 40% of tasks to an offshore team, optimizing resource allocation for enhanced efficiency.'), '2.other.0': OptimizedText(optimized_text='Centralized over 40% of tasks to an offshore team, optimizing resource allocation and supporting product development through client services feedback.')}), '0.responsibilities.5': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Automated and streamlined internal processes using Python, driving over 40% improvements in report preparation and data analysis.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led the development of custom Python tools that automated and optimized internal workflows, resulting in a 40% decrease in report generation and data analysis time. Leveraged extensive experience collaborating with clients to deliver tailored solutions.'), '1.down_to_earth.2': OptimizedText(optimized_text='Developed custom Python tools that streamlined and accelerated internal processes, delivering over 40% reduction in report preparation and data analysis time. Led consultative analytics engagements with clients.'), '1.down_to_earth.3': OptimizedText(optimized_text='Led the development of custom Python tools that streamlined and accelerated internal processes, driving significant improvements in efficiency across report preparation and data analysis.'), '2.other.0': OptimizedText(optimized_text='Leveraged advanced Python programming skills to create custom tools that streamlined internal operations, driving over 40% improvements in report preparation and data analysis efficiency.')}), '0.responsibilities.6': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Analytical leader with a proven track record of pioneering groundbreaking industry research and publications. Collaborated extensively with engineering services teams to develop market forecasts, analyze the impact of COVID-19, and identify emerging trends in mergers and acquisitions within the engineering services sector.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led the engineering services research team in pioneering the engineering services tracker, authored impactful publications on market forecasts, the impact of COVID-19 on services, and trends in mergers and acquisitions within the engineering services industry. Demonstrated substantial client-facing experience.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led the development of the engineering services tracker and authored influential publications on market forecasts, the impact of COVID-19 on services, and trends in M&A within the engineering services industry.'), '1.down_to_earth.3': OptimizedText(optimized_text='Pioneered industry-leading engineering services tracker and authored impactful publications on market forecasts, COVID-19 impact, and engineering services M&A trends. Demonstrated ability to effectively manage complex projects and deliver valuable insights to stakeholders.'), '2.other.0': OptimizedText(optimized_text='Led engineering services research team to pioneer engineering services tracker, authored influential publications on market forecasts, the impact of COVID-19 on services, and industry trends. Leveraged these insights to drive product development through client services feedback.')}), '0.responsibilities.7': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Seasoned data analyst who led global teams (US, Canada, Latin America, Europe, MEA, APAC) to maintain data integrity, achieve objectives, and share expertise. Adept at identifying and implementing innovative analytical tools and techniques.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led collaborative efforts with global analyst teams to ensure data quality, meet deadlines, share knowledge, and implement best practices and new tools.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led consultative analytics engagements with global analyst teams. Ensured data quality, met deadlines, and shared knowledge, best practices, and methodology to procure new tools.'), '1.down_to_earth.3': OptimizedText(optimized_text='Collaborated with global analyst teams to ensure data quality, meet deadlines, share knowledge, implement best practices, and procure new tools.'), '2.other.0': OptimizedText(optimized_text='Led international analyst teams to maintain data integrity, achieve project milestones, exchange expertise and best practices, and acquire innovative tools in support of product development initiatives.')}), '1.responsibilities.0': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Seasoned leader with a proven record in full P&L oversight, including budgeting, HR, vendor relations, partnerships, research, and business development. Drove significant growth, expanding program bookings by over 50%. Extensive experience in analytical roles, with a strong foundation in data-driven decision-making and strategic planning.'), '1.down_to_earth.1': OptimizedText(optimized_text='Skilled leader with a proven track record in full P&L management, overseeing budgeting, HR, vendor relations, partnerships, research, and business development. Drove significant growth, expanding program bookings by over 50%. Excelled in client-facing roles, delivering exceptional service and driving impactful business results.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led full P&L management, including budgeting, HR, vendor relationships, partnerships, research, and business development. Drove significant expansion, growing program bookings by over 50%.'), '1.down_to_earth.3': OptimizedText(optimized_text='Adept leader with a proven record of full P&L management, overseeing diverse responsibilities including budgeting, human resources, vendor relationships, strategic partnerships, research, and business development. Drove significant growth, expanding program bookings by over 50%, showcasing exceptional project management skills.'), '2.other.0': OptimizedText(optimized_text='Led full profit and loss responsibilities, excelling at budgeting, human resources, vendor relationships, partnerships, research, and business development. Drove significant growth, increasing program bookings by over 50%.')}), '1.responsibilities.1': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Directed and expanded diverse global research teams, leading a global team of over 15 professionals across the US, India, and Mexico.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led a global research team, leveraging diverse perspectives to drive innovation across multiple locations.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led and grew a diverse global research team spanning multiple locations.'), '1.down_to_earth.3': OptimizedText(optimized_text='Led and managed diverse, global research teams to drive successful project outcomes.'), '2.other.0': OptimizedText(optimized_text='Led and expanded a diverse, global research team across strategic locations, enabling informed product development through client feedback.')}), '1.responsibilities.2': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Managed cross-functional teams to deliver innovative software solutions.'), '1.down_to_earth.1': OptimizedText(optimized_text='Managed cross-functional teams to deliver innovative software solutions for clients.'), '1.down_to_earth.2': OptimizedText(optimized_text='Spearheaded cross-functional teams to ideate, build, and deploy innovative software solutions that addressed client needs. Led an external software development team to build and implement new tools.'), '1.down_to_earth.3': OptimizedText(optimized_text='Spearheaded the development and implementation of innovative software tools and solutions by leading an external software development team.'), '2.other.0': OptimizedText(optimized_text='Collaborated with an external software development team to build and implement new tools that enhanced product development efforts.')}), '1.responsibilities.3': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Experienced leader who championed cutting-edge technology initiatives, including machine learning, natural language processing, chatbots, ontologies, web scraping, APIs, and user experience design. Demonstrated strong analytical skills with a data-driven approach honed over 8+ years.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led impactful and innovative technology projects leveraging cutting-edge tools like machine learning, natural language processing, chatbots, ontologies, web scraping, APIs, and user experience design. Collaborated extensively with stakeholders to deliver tailored solutions that exceeded expectations.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led innovative technology initiatives that leveraged cutting-edge tools and techniques, including machine learning, natural language processing, chatbots, ontologies, web scraping, APIs, and user experience design.'), '1.down_to_earth.3': OptimizedText(optimized_text='Led the successful implementation of cutting-edge technology initiatives, including machine learning, natural language processing, chatbots, ontology development, web scraping, API integration, and user experience design. Extensive experience in managing complex technology projects and delivering innovative solutions that drive business growth.'), '2.other.0': OptimizedText(optimized_text='Spearheaded innovative product development and enhanced user experience by leveraging cutting-edge technologies, including machine learning, natural language processing, chatbots, ontologies, web scraping, and APIs.')}), '1.responsibilities.4': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Developed and led a team to create Python-based automated tools that streamlined report preparation, driving 40% time savings.'), '1.down_to_earth.1': OptimizedText(optimized_text='Drove development of automated Python tools, reducing report preparation time by 40%.'), '1.down_to_earth.2': OptimizedText(optimized_text='Developed and implemented automated Python tools, driving a 40% reduction in report preparation time.'), '1.down_to_earth.3': OptimizedText(optimized_text='Adept project manager who led teams in developing custom Python-based tools, enhancing reporting efficiency by 40%.'), '2.other.0': OptimizedText(optimized_text='Developed Python-based automated solutions that streamlined report generation and enhanced overall operational efficiency.')}), '1.responsibilities.5': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Pioneered cutting-edge technologies, leading the implementation of machine learning, chatbots, APIs, and ontology development. Excels in analytical roles, delivering impactful solutions that drive business success.'), '1.down_to_earth.1': OptimizedText(optimized_text='Pioneered cutting-edge technology projects, including deploying machine learning, chatbots, APIs, and ontology development. Delivered client-focused solutions with a proven track record.'), '1.down_to_earth.2': OptimizedText(optimized_text='Pioneering technology executive with a track record of leading transformative initiatives, including the implementation of cutting-edge solutions such as machine learning, chatbots, APIs, and ontology development. Excels at driving strategic analytics engagements and delivering impactful consultative services to clients.'), '1.down_to_earth.3': OptimizedText(optimized_text='Innovative technology leader who pioneered cutting-edge solutions including machine learning, chatbots, APIs, and ontology development. Skilled at driving high-impact projects and delivering measurable results.'), '2.other.0': OptimizedText(optimized_text='Led the implementation of machine learning, launch of a chatbot, development of APIs, and construction of an ontology to drive innovation with emerging technologies. Collaborated closely with clients to provide valuable feedback that informed and supported ongoing product development efforts.')}), '1.responsibilities.6': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Leveraged analytical expertise to advise services firms on deal pursuit and sales orchestration strategies, driving business development and sales execution.'), '1.down_to_earth.1': OptimizedText(optimized_text='Guided professional services firms in developing their deal pursuit and sales strategy.'), '1.down_to_earth.2': OptimizedText(optimized_text='Advised services firms on deal pursuit and sales orchestration strategies, providing strategic guidance and expertise.'), '1.down_to_earth.3': OptimizedText(optimized_text='Proven leader who advised services firms on developing and executing effective deal pursuit and sales strategies.'), '2.other.0': OptimizedText(optimized_text='Drove deal pursuit and sales orchestration strategies for professional services firms, leveraging client insights to inform product development.')}), '1.responsibilities.7': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Advised software vendors on partnership strategy, leveraging extensive analytical expertise to provide strategic advisory services.'), '1.down_to_earth.1': OptimizedText(optimized_text='Advised software vendors on strategic partnerships and delivered client-facing services.'), '1.down_to_earth.2': OptimizedText(optimized_text='Guided software vendors on partnership opportunities and drove consultative analytics engagements with clients.'), '1.down_to_earth.3': OptimizedText(optimized_text='Guided software vendors on partnership strategy, leveraging extensive experience to deliver strategic guidance and drive successful initiatives.'), '2.other.0': OptimizedText(optimized_text='Guided software vendors on strategic services partnerships, driving successful client engagements.')}), '1.responsibilities.8': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Prolific content creator who authored reports, blogs, presentations, and custom research. Leveraged industry insights to drive strategic decision-making, analyzing go-to-market strategies, deal signing, renewal analysis, buyer studies, and technology trends (cloud, AI, ML, digital, etc.). Demonstrated extensive experience in an analytical role.'), '1.down_to_earth.1': OptimizedText(optimized_text='Prolific author of reports, blogs, presentations, and custom research. Adept at analyzing go-to-market strategies, deal signing, renewal trends, buyer behavior, and the adoption of emerging technologies such as cloud, AI, ML, and digital solutions. Proven track record of providing valuable industry insights and trend analysis to clients.'), '1.down_to_earth.2': OptimizedText(optimized_text='Seasoned professional who authors reports, blogs, presentations, and custom research. Adept at analyzing go-to-market strategies, deal signing, renewal trends, buyer behavior, and technology adoptions (cloud, AI, ML, digital, etc.), as well as identifying industry trends. Skilled in delivering consultative analytics engagements to clients.'), '1.down_to_earth.3': OptimizedText(optimized_text='Authored impactful reports, blogs, presentations, and custom research on go-to-market strategy, deal analysis, buyer studies, and industry trends. Leveraged emerging technologies like cloud, AI, and ML to deliver actionable insights.'), '2.other.0': OptimizedText(optimized_text='Accomplished professional who has authored impactful reports, blogs, presentations, and custom research projects. Expertise spans developing go-to-market strategies, conducting deal and renewal analyses, executing buyer studies, and analyzing technology adoption trends (e.g., cloud, AI, ML, digital). Regularly provided valuable insights and feedback to drive product development efforts.')}), '2.responsibilities.0': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Led quarterly webinars analyzing industry trends in outsourcing and managed services.'), '1.down_to_earth.1': OptimizedText(optimized_text='Conducted quarterly webinars on outsourcing and managed services trends.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led quarterly webinar series to present industry insights and best practices to clients.'), '1.down_to_earth.3': OptimizedText(optimized_text='Seasoned professional who has delivered quarterly webinars showcasing industry insights and best practices on outsourcing and managed services signing trends.'), '2.other.0': OptimizedText(optimized_text='Conducted quarterly webinars to share industry insights and client feedback, driving product development initiatives.')}), '2.responsibilities.1': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Authored insightful pursuit strategy reports and industry trend research.'), '1.down_to_earth.1': OptimizedText(optimized_text='Authored compelling pursuit strategy reports and conducted in-depth industry trend research, leveraging a strong background in client-facing roles.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led consultative analytics engagements and produced industry-leading research reports.'), '1.down_to_earth.3': OptimizedText(optimized_text='Authored strategic planning and industry analysis reports, demonstrating a proven track record in project management.'), '2.other.0': OptimizedText(optimized_text='Drove product development by leveraging client feedback and industry research.')}), '3.responsibilities.0': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Designed and architected complex database systems, integrating diverse data sources and enhancing data quality through deduplication initiatives. Demonstrated a proven track record in analytical roles over multiple years.'), '1.down_to_earth.1': OptimizedText(optimized_text='Designed and architected a complex company database, integrating external and internal data sources to significantly reduce data duplication. Led client-facing initiatives throughout my career, demonstrating extensive experience in this area.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led the technical design and architecture of a large-scale enterprise database, integrating multiple data sources to enhance data integrity and streamline operations. Demonstrated extensive expertise in complex data architecture and integration, collaborating with stakeholders to deliver impactful solutions that reduced data duplication by 50%.'), '1.down_to_earth.3': OptimizedText(optimized_text='Designed and architected sophisticated database solutions, integrating diverse data sources to enhance integrity and optimize management processes. Reduced data duplication by 50% in a complex company database with 100K+ unique records, seamlessly integrating DnB API and internal databases.'), '2.other.0': OptimizedText(optimized_text='Led the design and implementation of a comprehensive database system, consolidating diverse data sources to enhance data quality and streamline operations.')}), '3.responsibilities.1': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Drove implementation of process automation solutions that boosted productivity across multiple industries.'), '1.down_to_earth.1': OptimizedText(optimized_text='Results-driven professional with a proven track record of leading successful client-facing projects, including managing the implementation of two Appian solutions that enhanced team productivity by 20 to 30%.'), '1.down_to_earth.2': OptimizedText(optimized_text='Driven leader who managed multiple Appian implementations that delivered substantial productivity gains for client teams.'), '1.down_to_earth.3': OptimizedText(optimized_text='Accomplished project manager who led two successful Appian implementations that drove 20-30% improvements in team productivity.'), '2.other.0': OptimizedText(optimized_text='Led two Appian implementations that drove 20-30% improvements in team productivity.')}), '3.responsibilities.2': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Managed daily content operations, including leading a team of offshore and nearshore content team, as well as other sales and research related activities. Seasoned professional with a proven track record in managing content operations, leading cross-functional teams, and supporting sales and research initiatives.'), '1.down_to_earth.1': OptimizedText(optimized_text='Directed daily content operations, leading a team of offshore and nearshore content specialists, and supporting sales and research initiatives. Demonstrated extensive client-facing expertise.'), '1.down_to_earth.2': OptimizedText(optimized_text='Managed daily content operations, leading a team of offshore and nearshore content professionals, and overseeing a range of sales and research-related initiatives.'), '1.down_to_earth.3': OptimizedText(optimized_text='Managed daily content operations, including leading a team of offshore and nearshore content professionals as well as sales and research-related initiatives. Skilled at project management and delivering high-quality results.'), '2.other.0': OptimizedText(optimized_text='Led a talented content team to drive daily operations, collaborating with sales and research to support strategic initiatives.')}), '3.responsibilities.3': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Analyzed and modeled financials for 20-30 IT vendors and over 1,500 services contracts, delivering critical insights to support vendor and contract management.'), '1.down_to_earth.1': OptimizedText(optimized_text=\"Analyzed and modeled financials for 20 to 30 IT vendors' diverse portfolios. Reviewed and negotiated over 1,500 service contracts with extensive client-facing experience.\"), '1.down_to_earth.2': OptimizedText(optimized_text='Analyzed and modeled financials for 20 to 30 IT vendors and over 1,500 service contracts to support consultative engagements.'), '1.down_to_earth.3': OptimizedText(optimized_text='Analyzed and modeled financial data for 20 to 30 IT vendors and over 1,500 services contracts, leveraging insights to drive successful contract management.'), '2.other.0': OptimizedText(optimized_text='Analyzed and modeled financial data for 20 to 30 IT vendors and over 1,500 service contracts to support product development efforts by gathering and incorporating client services feedback.')}), '3.responsibilities.4': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Experienced data integration project manager who led the successful delivery of mission-critical platform initiatives.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led three major data integration projects critical to the successful launch of a new platform. Adept at delivering high-impact client-facing solutions.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led multiple data integration projects critical to the successful launch of a new enterprise platform, demonstrating strong experience managing client-facing analytics engagements.'), '1.down_to_earth.3': OptimizedText(optimized_text='Led the successful delivery of three mission-critical data integration projects instrumental in launching the new platform.'), '2.other.0': OptimizedText(optimized_text='Led the successful implementation of three mission-critical data integration projects that were instrumental in launching a new platform.')}), '3.responsibilities.5': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Established research leader who advanced to Research Manager role, drawing on over 10 years of analytical expertise.'), '1.down_to_earth.1': OptimizedText(optimized_text='Results-driven Research Manager with a proven track record of client engagement. Led teams and implemented strategies to deliver insights and drive improvements.'), '1.down_to_earth.2': OptimizedText(optimized_text='Managed analytical initiatives and partnered with clients to deliver impactful solutions. Promoted to Research Manager in 2007.'), '1.down_to_earth.3': OptimizedText(optimized_text='Promoted research professional with a decade of career advancement, culminating in a Research Manager role.'), '2.other.0': OptimizedText(optimized_text='Managed research initiatives and oversaw product development, driving continuous improvements based on client feedback. Transitioned from Senior Research Analyst to Research Manager.')}), '4.responsibilities.0': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Drove strategic product decisions through extensive market research and analysis.'), '1.down_to_earth.1': OptimizedText(optimized_text='Researched market dynamics to drive strategic product development and strengthen client relationships.'), '1.down_to_earth.2': OptimizedText(optimized_text='Conducted market research and data analysis to inform strategic product decisions and improve client engagements.'), '1.down_to_earth.3': OptimizedText(optimized_text='Leveraged market research insights to develop and execute effective product strategies.'), '2.other.0': OptimizedText(optimized_text='Guided product strategy and development efforts by leveraging market research insights.')})}\"\n",
    "print(responsibilities)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
