{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import textwrap\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from project_config import (\n",
    "    JOB_POSTING_URLS_FILE,\n",
    "    JOB_POSTING_URLS_FILTERED_FILE,\n",
    "    JOB_POSTING_URLS_TO_EXCLUDE_FILE,\n",
    "    JOB_DESCRIPTIONS_JSON_FILE,\n",
    "    JOB_REQUIREMENTS_JSON_FILE,\n",
    ")\n",
    "\n",
    "\n",
    "def clean_json_string(json_string: str):\n",
    "    \"\"\"\n",
    "    Remove unwanted control characters from the JSON string.\n",
    "    \"\"\"\n",
    "    # Remove control characters (non-printable characters)\n",
    "    return re.sub(r\"[\\x00-\\x1F\\x7F]\", \"\", json_string)\n",
    "\n",
    "\n",
    "def load_and_decode_json(json_file):\n",
    "    \"\"\"Load a JSON file and decode all Unicode escape sequences.\"\"\"\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        json_string = f.read()\n",
    "        cleaned_json_string = clean_json_string(json_string)  # Clean the JSON string\n",
    "        data = json.loads(cleaned_json_string)  # Decode the cleaned JSON\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def format_json_readable(json_obj, indent=2, wrap_width=80):\n",
    "    \"\"\"\n",
    "    Formats JSON with indentation and wraps long text for easier readability.\n",
    "    \"\"\"\n",
    "    formatted_json = json.dumps(\n",
    "        json_obj, indent=indent, ensure_ascii=False\n",
    "    )  # Pretty print JSON\n",
    "\n",
    "    # Wrap long lines within values\n",
    "    formatted_json = \"\\n\".join(\n",
    "        [\n",
    "            textwrap.fill(line, width=wrap_width) if len(line) > wrap_width else line\n",
    "            for line in formatted_json.split(\"\\n\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Optional: Simulate line breaks after lists or objects (but avoid unnecessary newlines)\n",
    "    formatted_json = formatted_json.replace(\n",
    "        \"]\", \"]\"\n",
    "    )  # Avoid adding newlines after closing brackets\n",
    "\n",
    "    return formatted_json\n",
    "\n",
    "\n",
    "def display_json_pretty(json_input: dict | str | Path, wrap_width: int = 120):\n",
    "    \"\"\"Display JSON from a string or a file in a readable format.\"\"\"\n",
    "    if isinstance(json_input, dict):  # If it's already a dict, just format it\n",
    "        data = json_input\n",
    "    elif isinstance(json_input, Path) or (\n",
    "        isinstance(json_input, str) and not json_input.strip().startswith((\"{\", \"[\"))\n",
    "    ):\n",
    "        data = load_and_decode_json(\n",
    "            str(json_input)\n",
    "        )  # Convert Path to string if necessary\n",
    "    else:\n",
    "        data = json.loads(json_input)  # If it's a JSON string, parse it\n",
    "\n",
    "    # Format JSON for readability\n",
    "    formatted_json = format_json_readable(data, wrap_width=wrap_width)\n",
    "\n",
    "    # Display with Markdown to prevent horizontal scrolling\n",
    "    display(Markdown(f\"```json\\n{formatted_json}\\n```\"))\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# json_data = {\"name\": \"John Doe\", \"age\": 30, \"city\": \"New York\"}\n",
    "\n",
    "# # Format the JSON data for readability\n",
    "# formatted_json = format_json_readable(json_data)\n",
    "\n",
    "# # Directly display the formatted JSON string without json.loads()\n",
    "# display_json_pretty(\n",
    "#     formatted_json\n",
    "# )  # No need to call json.loads again, since it's already formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Job URLs, Descriptions/Postings, & Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Posting URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Pipeline to Filter URLs File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 15:56:18,323 - pipelines.filter_job_posting_urls_mini_pipeline - INFO - Loading main job postings from C:\\github\\job_bot\\input_output\\input\\job_posting_urls.json\n",
      "2025-03-13 15:56:18,336 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\input\\job_posting_urls.json\n",
      "2025-03-13 15:56:18,337 - pipelines.filter_job_posting_urls_mini_pipeline - INFO - Loading exclusion URLs from C:\\github\\job_bot\\input_output\\input\\job_posting_urls_to_exclude.json\n",
      "2025-03-13 15:56:18,350 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\input\\job_posting_urls_to_exclude.json\n",
      "2025-03-13 15:56:18,351 - pipelines.filter_job_posting_urls_mini_pipeline - INFO - Excluding 19 URLs from main job postings.\n",
      "2025-03-13 15:56:18,352 - pipelines.filter_job_posting_urls_mini_pipeline - INFO - Filtered out 19 job postings; 13 remain.\n",
      "2025-03-13 15:56:18,354 - utils.generic_utils - INFO - Data successfully saved to C:\\github\\job_bot\\input_output\\input\\job_posting_urls_filtered.json.\n",
      "2025-03-13 15:56:18,355 - pipelines.filter_job_posting_urls_mini_pipeline - INFO - Filtered job postings saved successfully to C:\\github\\job_bot\\input_output\\input\\job_posting_urls_filtered.json\n"
     ]
    }
   ],
   "source": [
    "from pipelines.filter_job_posting_urls_mini_pipeline import (\n",
    "    run_filtering_job_posting_urls_mini_pipe_line as filter_urls,\n",
    ")\n",
    "\n",
    "filter_urls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "['Accenture', 'Adobe', 'Advisor360 Degrees', 'Airtable', 'Amazon', 'Amazon', 'Amazon', 'Amazon', 'Amplitude', 'Blend', 'Capital One', 'DEPT', 'Deloitte', 'Deloitte', 'Deloitte', 'DigitalOcean', 'Figma', 'Flextronics', 'Glean', 'Google', 'Liberty Mutual', 'Liberty Mutual', 'Liberty Mutual Insurance', 'Meta', 'Microsoft', 'MongoDB', 'Oracle', 'PwC', 'Snowflake', 'TRACE3', 'ThermoFisher Scientific', 'Veeva']\n"
     ]
    }
   ],
   "source": [
    "json_input = JOB_POSTING_URLS_FILE\n",
    "\n",
    "data = load_and_decode_json(json_file=json_input)\n",
    "print(len(data))\n",
    "companies = sorted(\n",
    "    [job_data.get(\"company\", \"Unknown Company\") for job_data in data.values()]\n",
    ")\n",
    "print(companies)\n",
    "# for key, value in data.items():\n",
    "\n",
    "\n",
    "# display_json_pretty(json_file, wrap_width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtered URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Accenture',\n",
       " 'Advisor360 Degrees',\n",
       " 'Airtable',\n",
       " 'Amazon',\n",
       " 'Blend',\n",
       " 'Deloitte',\n",
       " 'Deloitte',\n",
       " 'Deloitte',\n",
       " 'DigitalOcean',\n",
       " 'Glean',\n",
       " 'Liberty Mutual',\n",
       " 'Snowflake',\n",
       " 'Veeva']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "json_input = JOB_POSTING_URLS_FILTERED_FILE\n",
    "\n",
    "data = load_and_decode_json(json_file=json_input)\n",
    "print(len(data))\n",
    "companies = sorted(\n",
    "    [job_data.get(\"company\", \"Unknown Company\") for job_data in data.values()]\n",
    ")\n",
    "display(companies)\n",
    "# for key, value in data.items():\n",
    "\n",
    "\n",
    "# display_json_pretty(json_file, wrap_width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Postings/Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "https://careers.snowflake.com/us/en/job/SNCOUS5AF10A9C7A01464788ABD17AECBEE52EEXTERNALENUS1CC71A00229E4662B768527743E6164F/Director-Product-Marketing-Analytics?utm_source=Q2P9NP2NNP&utm_medium=phenom-feeds&gh_src=ed5543a62\n"
     ]
    }
   ],
   "source": [
    "json_input = JOB_DESCRIPTIONS_JSON_FILE\n",
    "\n",
    "data = load_and_decode_json(json_file=json_input)\n",
    "print(len(data))\n",
    "for key in data.keys():\n",
    "    print(key) if \"snowflake\" in key else None\n",
    "# json_file = r\"C:\\github\\job_bot\\input_output\\preprocessing\\jobpostings.json\"\n",
    "# display_json_pretty(JOB_REQUIREMENTS_JSON_FILE, wrap_width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "dict_keys(['https://www.google.com/about/careers/applications/jobs/results/113657145978692294-ai-market-intelligence-principal/?src=Online/LinkedIn/linkedin_us&utm_source=linkedin&utm_medium=jobposting&utm_campaign=contract&utm_medium=jobboard&utm_source=linkedin', 'https://www.capitalonecareers.com/job/-/-/234/66270465536?p_sid=ep3Sfxb&p_uid=sDBMWC5VxQ&source=rd_linkedin_job_posting_tm&ss=paid&utm_campaign=capone_all_jobs_24&utm_content=pj_board&utm_medium=jobad&utm_source=linkedin+slotted&dclid=CPGV3bef44gDFUEGTwgd4DoHPg', 'https://boards.greenhouse.io/embed/job_app?token=7600823002&gh_src=ab9f35b82', 'https://www.amazon.jobs/en/jobs/2696123/research-manager-strategy-and-insights-gca-marketing?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid', 'https://www.amazon.jobs/en/jobs/2742527/sr-generative-ai-strategist-generative-ai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid', 'https://www.amazon.jobs/en/jobs/2684745/product-manager-artificial-general-intelligence-data-services?cmpid=SPLICX0248M&ss=paid&utm_campaign=cxro&utm_content=job_posting&utm_medium=social_media&utm_source=linkedin.com', 'https://jobs.careers.microsoft.com/us/en/job/1771714/Head-of-Partner-Intelligence-and-Strategy?jobsource=linkedin', 'https://searchjobs.libertymutualgroup.com/careers/job/618499888480?microsite=libertymutual.com&domain=libertymutual.com&utm_source=Job+Board&utm_campaign=LinkedIn+Jobs&extcmp=bof-paid-text-lkin-aljb', 'https://www.metacareers.com/jobs/522232286825036/?rx_campaign=Linkedin1&rx_ch=connector&rx_group=126320&rx_job=a1KDp00000E28eGMAR&rx_medium=post&rx_r=none&rx_source=Linkedin&rx_ts=20240927T121201Z&rx_vp=slots&utm_campaign=Job%2Bboard&utm_medium=jobs&utm_source=LIpaid&rx_viewer=e3efacca649311ef917d17a1705b89ba0dc4e1e7a57f4231bbce94a604c83931', 'https://flextronics.wd1.myworkdayjobs.com/en-US/Careers/job/Sr-Manager-AI-Strategy_WD191060?source=LinkedIn_Slots', 'https://www.digitalocean.com/careers/position/apply?gh_jid=6437995&gh_src=312a08e31us', 'https://careers.adobe.com/us/en/job/ADOBUSR151695EXTERNALENUS/Sr-Director-Applied-AI-ML-Discovery?utm_source=linkedin&utm_medium=phenom-feeds&source=LinkedIn', 'https://boards.greenhouse.io/gleanwork/jobs/4425502005?source=LinkedIn', 'https://jobs.thermofisher.com/global/en/job/R-01298008/Market-Competitive-Intelligence-Manager?rx_ch=jobpost&rx_job=R-01298008-1&rx_medium=post&rx_paid=0&rx_r=none&rx_source=linkedin&rx_ts=20250206T184002Z&rx_vp=linkedindirectindex&utm_medium=post&utm_source=recruitics_linkedindirectindex&refId=34jd24&rx_viewer=e3efacca649311ef917d17a1705b89ba0dc4e1e7a57f4231bbce94a604c83931', 'https://searchjobs.libertymutualgroup.com/careers/job/618501232921?microsite=libertymutual.com&domain=libertymutual.com&utm_source=Job+Board&utm_campaign=LinkedIn+Jobs&extcmp=bof-paid-text-lkin-aljb', 'https://job-boards.greenhouse.io/airtable/jobs/7603873002?gh_src=aef790d02us', 'https://careers.veeva.com/job/365ff44c-8e0a-42b4-a117-27b409a77753/director-crossix-analytics-services-boston-ma/?lever-source=Linkedin', 'https://job-boards.greenhouse.io/figma/jobs/5336109004?gh_jid=5336109004&gh_src=28109e334us&source=LinkedIn', 'https://job-boards.greenhouse.io/trace3/jobs/6163213?gh_src=b81c67b41us', 'https://jobs.us.pwc.com/job/-/-/932/76064801072?utm_source=linkedin.com&utm_campaign=core_media&utm_medium=social_media&utm_content=job_posting&ss=paid&dclid=CjgKEAiAwaG9BhCY3ayl47PW8lcSJAA_gCfjt-rzWhQetHLIbJdJBVocWQm2BRNcBgOARxhGyR9bgvD_BwE', 'https://boards.greenhouse.io/dept/jobs/6564521', 'https://www.mongodb.com/careers/jobs/6466537', 'https://apply.deloitte.com/careers/InviteToApply?jobId=210031&source=LinkedIn', 'https://apply.deloitte.com/careers/InviteToApply?jobId=199586&source=LinkedIn', 'https://apply.deloitte.com/careers/InviteToApply?jobId=201718&source=LinkedIn', 'https://advisor360.breezy.hr/p/2e1636328c7d-senior-product-manager-ai-analytics-insights', 'https://careers.snowflake.com/us/en/job/SNCOUS5AF10A9C7A01464788ABD17AECBEE52EEXTERNALENUS1CC71A00229E4662B768527743E6164F/Director-Product-Marketing-Analytics?utm_source=Q2P9NP2NNP&utm_medium=phenom-feeds&gh_src=ed5543a62', 'https://www.amazon.jobs/en/jobs/2905092/senior-manger-partner-strategy-genai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid', 'https://www.accenture.com/us-en/careers/jobdetails?id=R00251798_en&src=LINKEDINJP', 'https://jobs.smartrecruiters.com/Blend360/744000042638791-director-ai-strategy?trid=2d92f286-613b-4daf-9dfa-6340ffbecf73'])\n"
     ]
    }
   ],
   "source": [
    "json_input = JOB_REQUIREMENTS_JSON_FILE\n",
    "\n",
    "data = load_and_decode_json(json_file=json_input)\n",
    "print(len(data))\n",
    "print(data.keys())\n",
    "# json_file = r\"C:\\github\\job_bot\\input_output\\preprocessing\\jobpostings.json\"\n",
    "# display_json_pretty(JOB_REQUIREMENTS_JSON_FILE, wrap_width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Iteration 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import textwrap\n",
    "from IPython.display import display, Markdown\n",
    "from project_config import (\n",
    "    JOB_POSTING_URLS_FILE,\n",
    "    JOB_DESCRIPTIONS_JSON_FILE,\n",
    "    JOB_REQUIREMENTS_JSON_FILE,\n",
    "    ITERATE_0_OPENAI_DIR,\n",
    "    mapping_file_name,\n",
    "    REQS_FILES_ITERATE_0_OPENAI_DIR,\n",
    "    RESPS_FILES_ITERATE_0_OPENAI_DIR,\n",
    "    SIMILARITY_METRICS_ITERATE_0_OPENAI_DIR,\n",
    "    ITERATE_0_ANTHROPIC_DIR,\n",
    "    REQS_FILES_ITERATE_0_ANTHROPIC_DIR,\n",
    "    RESPS_FILES_ITERATE_0_ANTHROPIC_DIR,\n",
    "    SIMILARITY_METRICS_ITERATE_0_ANTHROPIC_DIR,\n",
    "    # URL_TO_FILE_MAPPING_FILE_ITERATE_0_OPENAI,\n",
    "    # URL_TO_FILE_MAPPING_FILE_ITERATE_0_ANTHROPIC,\n",
    ")\n",
    "\n",
    "\n",
    "def load_and_decode_json(json_file):\n",
    "    \"\"\"Load a JSON file and decode all Unicode escape sequences.\"\"\"\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)  # JSON decoder auto-converts \\u2013 and \\u2014\n",
    "    return data\n",
    "\n",
    "\n",
    "def format_json_readable(json_obj, indent=2, wrap_width=80):\n",
    "    \"\"\"\n",
    "    Formats JSON with indentation and wraps long text for easier readability.\n",
    "    \"\"\"\n",
    "    formatted_json = json.dumps(\n",
    "        json_obj, indent=indent, ensure_ascii=False\n",
    "    )  # Pretty print JSON\n",
    "\n",
    "    # Wrap long lines within values\n",
    "    formatted_json = \"\\n\".join(\n",
    "        [\n",
    "            textwrap.fill(line, width=wrap_width) if len(line) > wrap_width else line\n",
    "            for line in formatted_json.split(\"\\n\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Simulate line breaks: Insert extra spacing between key sections\n",
    "    formatted_json = formatted_json.replace(\"{\", \"{\\n\\n\")  # Before nested objects\n",
    "    formatted_json = formatted_json.replace(\"},\", \"},\\n\\n\")  # After objects\n",
    "    formatted_json = formatted_json.replace(\"]\", \"]\\n\\n\")  # After lists\n",
    "\n",
    "    return formatted_json\n",
    "\n",
    "\n",
    "def display_json_pretty(json_file, wrap_width=100):\n",
    "    \"\"\"Loads, decodes, formats, and displays JSON with simulated line breaks in Jupyter Notebook.\"\"\"\n",
    "\n",
    "    # Load and decode JSON\n",
    "    data = load_and_decode_json(json_file)\n",
    "\n",
    "    # Format JSON for readability\n",
    "    formatted_json = format_json_readable(data, wrap_width=wrap_width)\n",
    "\n",
    "    # Display with Markdown to prevent horizontal scrolling\n",
    "    display(Markdown(f\"```json\\n{formatted_json}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI I/O Iterate 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping File (OpenAI pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check all records from mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000001F77EC7D810>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\github\\job_bot\\env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "from models.resume_job_description_io_models import JobFileMappings\n",
    "from evaluation_optimization.create_mapping_file import load_mappings_model_from_json\n",
    "\n",
    "# from project_config import URL_TO_FILE_MAPPING_FILE_ITERATE_0_OPENAI\n",
    "\n",
    "directory = ITERATE_0_OPENAI_DIR\n",
    "mapping_file = directory / mapping_file_name\n",
    "\n",
    "file_mapping_model = load_mappings_model_from_json(mapping_file)\n",
    "\n",
    "print(\"Job URLs:\")\n",
    "print(f\"Number of URLs: {len(file_mapping_model.root.keys())}\")\n",
    "\n",
    "for index, url in enumerate(file_mapping_model.root.keys(), start=1):\n",
    "    print(f\"{index}. {url}\")\n",
    "    # print()\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"sim_metrics paths:\")\n",
    "for index, jobpaths in enumerate(file_mapping_model.root.values(), start=1):\n",
    "    print(f\"{index}. {Path(jobpaths.sim_metrics).name}\")\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for specific records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching URLs:\n",
      "1. https://www.amazon.jobs/en/jobs/2696123/research-manager-strategy-and-insights-gca-marketing?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "\n",
      "2. https://www.amazon.jobs/en/jobs/2742527/sr-generative-ai-strategist-generative-ai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "\n",
      "3. https://www.amazon.jobs/en/jobs/2684745/product-manager-artificial-general-intelligence-data-services?cmpid=SPLICX0248M&ss=paid&utm_campaign=cxro&utm_content=job_posting&utm_medium=social_media&utm_source=linkedin.com\n",
      "\n",
      "4. https://careers.snowflake.com/us/en/job/SNCOUS5AF10A9C7A01464788ABD17AECBEE52EEXTERNALENUS1CC71A00229E4662B768527743E6164F/Director-Product-Marketing-Analytics?utm_source=Q2P9NP2NNP&utm_medium=phenom-feeds&gh_src=ed5543a62\n",
      "\n",
      "5. https://jobs.smartrecruiters.com/Blend360/744000042638791-director-ai-strategy?trid=2d92f286-613b-4daf-9dfa-6340ffbecf73\n",
      "\n",
      "6. https://www.amazon.jobs/en/jobs/2905092/senior-manger-partner-strategy-genai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_terms = [\"blend\", \"Amazon\", \"Blend\", \"Snowflake\"]\n",
    "\n",
    "\n",
    "# Find URLs that contain the search term\n",
    "matching_urls = [\n",
    "    url\n",
    "    for url in file_mapping_model.root.keys()\n",
    "    if any(term.lower() in str(url).lower() for term in search_terms)\n",
    "]\n",
    "\n",
    "print(\"Matching URLs:\")\n",
    "for index, url in enumerate(matching_urls, start=1):\n",
    "    print(f\"{index}. {url}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sim Metrics (OpenAI Pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_metrics files in sim_metrics folder\n",
      "Number of files: 29\n",
      "1. Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_sim_metrics_iter0.csv\n",
      "2. Adobe_Sr__Director__Applied_AI_ML__Discovery__sim_metrics_iter0.csv\n",
      "3. Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_sim_metrics_iter0.csv\n",
      "4. Airtable_Product_Manager__AI_sim_metrics_iter0.csv\n",
      "5. Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_sim_metrics_iter0.csv\n",
      "6. Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_sim_metrics_iter0.csv\n",
      "7. Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_sim_metrics_iter0.csv\n",
      "8. Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_sim_metrics_iter0.csv\n",
      "9. Amplitude_Marketing_Strategy___Analytics_Manager_sim_metrics_iter0.csv\n",
      "10. Blend_Director__AI_Strategy_sim_metrics_iter0.csv\n",
      "11. Capital_One_Director__AI_Platforms_sim_metrics_iter0.csv\n",
      "12. Deloitte_AI_Data_Specialist_sim_metrics_iter0.csv\n",
      "13. Deloitte_Global_Business_Services__GBS__Strategy_Manager_sim_metrics_iter0.csv\n",
      "14. Deloitte_Market_Research_Sr_Manager_sim_metrics_iter0.csv\n",
      "15. DEPT__Director_of_Applied_AI_Strategy__Media_sim_metrics_iter0.csv\n",
      "16. DigitalOcean_Director__Product_Management__AI_ML__sim_metrics_iter0.csv\n",
      "17. Figma_Researcher__Strategic_Growth_sim_metrics_iter0.csv\n",
      "18. Flex_Sr__Manager_AI_Strategy_sim_metrics_iter0.csv\n",
      "19. Glean_Head_of_Competitive_Intelligence_sim_metrics_iter0.csv\n",
      "20. Google_AI_Market_Intelligence_Principal_sim_metrics_iter0.csv\n",
      "21. Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_sim_metrics_iter0.csv\n",
      "22. Meta_Product_Strategy_Lead_sim_metrics_iter0.csv\n",
      "23. Microsoft_Head_of_Partner_Intelligence_and_Strategy_sim_metrics_iter0.csv\n",
      "24. MongoDB_Director__Competitive_Intelligence_sim_metrics_iter0.csv\n",
      "25. PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_sim_metrics_iter0.csv\n",
      "26. Snowflake_Director__Product_Marketing_-_Analytics_sim_metrics_iter0.csv\n",
      "27. Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_sim_metrics_iter0.csv\n",
      "28. Trace3_Senior_Consultant__AI_Strategy__Remote__sim_metrics_iter0.csv\n",
      "29. Veeva_Systems_Director_-_Crossix_Analytics_Services_sim_metrics_iter0.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "from models.resume_job_description_io_models import JobFileMappings\n",
    "from evaluation_optimization.create_mapping_file import load_mappings_model_from_json\n",
    "\n",
    "# from project_config import URL_TO_FILE_MAPPING_FILE_ITERATE_0_OPENAI\n",
    "\n",
    "directory = SIMILARITY_METRICS_ITERATE_0_OPENAI_DIR\n",
    "file_list = get_file_names(directory_path=directory)\n",
    "\n",
    "print(\"sim_metrics files in sim_metrics folder\")\n",
    "print(f\"Number of files: {len(file_list)}\")\n",
    "\n",
    "for index, file_name in enumerate(file_list, start=1):\n",
    "    print(f\"{index}. {file_name}\")\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing records (similarity metrics files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 11:27:11,198 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\url_to_file_mapping.json\n",
      "2025-03-10 11:27:11,199 - evaluation_optimization.create_mapping_file - INFO - Loaded and validated mapping file from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\url_to_file_mapping.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing files in sim metrics folder: 0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from utils.get_file_names import get_file_names\n",
    "from models.resume_job_description_io_models import JobFileMappings\n",
    "from evaluation_optimization.create_mapping_file import load_mappings_model_from_json\n",
    "from project_config import SIMILARITY_METRICS_ITERATE_0_OPENAI_DIR\n",
    "\n",
    "# from project_config import URL_TO_FILE_MAPPING_FILE_ITERATE_0_OPENAI\n",
    "\n",
    "sim_metrics_dir = SIMILARITY_METRICS_ITERATE_0_OPENAI_DIR\n",
    "file_list_sim_metrics_dir = get_file_names(directory_path=sim_metrics_dir)\n",
    "\n",
    "file_mapping_model = load_mappings_model_from_json(mapping_file)\n",
    "file_list_mapping_file = [\n",
    "    Path(jobpaths.sim_metrics).name for jobpaths in file_mapping_model.root.values()\n",
    "]\n",
    "\n",
    "missing_files = set(file_list_mapping_file) - set(\n",
    "    file_list_sim_metrics_dir\n",
    ")  # Elements in list1 but not in list2\n",
    "\n",
    "print(f\"Number of missing files in sim metrics folder: {len(missing_files)}\")\n",
    "for idx, f_name in enumerate(missing_files, start=1):\n",
    "    print(f\"{idx}. {f_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 10:10:16,354 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\url_to_file_mapping.json\n",
      "2025-03-10 10:10:16,355 - evaluation_optimization.create_mapping_file - INFO - Loaded and validated mapping file from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\url_to_file_mapping.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in reqs dir: 30\n",
      "Files in resps dir: 30\n",
      "Files in mapping file: 30\n",
      "\n",
      "Number of missing files in sim metrics folder: 1\n",
      "1. Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_sim_metrics_iter0.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from utils.get_file_names import get_file_names\n",
    "from models.resume_job_description_io_models import JobFileMappings, Requirements\n",
    "from evaluation_optimization.create_mapping_file import load_mappings_model_from_json\n",
    "\n",
    "# from project_config import URL_TO_FILE_MAPPING_FILE_ITERATE_0_OPENAI\n",
    "\n",
    "sim_metrics_dir = SIMILARITY_METRICS_ITERATE_0_OPENAI_DIR\n",
    "file_list_sim_metrics_dir = get_file_names(directory_path=sim_metrics_dir)\n",
    "\n",
    "requirements_dir = REQS_FILES_ITERATE_0_OPENAI_DIR\n",
    "file_list_reqs_dir = get_file_names(requirements_dir)\n",
    "print(f\"Files in reqs dir: {len(file_list_reqs_dir)}\")\n",
    "\n",
    "responsibilities_dir = RESPS_FILES_ITERATE_0_OPENAI_DIR\n",
    "file_list_resps_dir = get_file_names(responsibilities_dir)\n",
    "print(f\"Files in resps dir: {len(file_list_resps_dir)}\")\n",
    "\n",
    "file_mapping_model = load_mappings_model_from_json(mapping_file)\n",
    "file_list_mapping_file = [\n",
    "    Path(jobpaths.sim_metrics).name for jobpaths in file_mapping_model.root.values()\n",
    "]\n",
    "print(f\"Files in mapping file: {len(file_list_mapping_file)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "missing_files = set(file_list_mapping_file) - set(\n",
    "    file_list_sim_metrics_dir\n",
    ")  # Elements in list1 but not in list2\n",
    "\n",
    "print(f\"Number of missing files in sim metrics folder: {len(missing_files)}\")\n",
    "for idx, f_name in enumerate(missing_files, start=1):\n",
    "    print(f\"{idx}. {f_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Responsibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "{'1.responsibilities.3', '3.responsibilities.0', '2.responsibilities.6', '0.responsibilities.4', '4.responsibilities.0', '1.responsibilities.4', '4.responsibilities.1', '1.responsibilities.7', '0.responsibilities.1', '2.responsibilities.3', '0.responsibilities.2', '3.responsibilities.1', '1.responsibilities.2', '4.responsibilities.5', '2.responsibilities.1', '1.responsibilities.0', '2.responsibilities.4', '1.responsibilities.1', '2.responsibilities.7', '1.responsibilities.5', '5.responsibilities.0', '4.responsibilities.3', '2.responsibilities.5', '4.responsibilities.4', '2.responsibilities.2', '0.responsibilities.0', '2.responsibilities.0', '0.responsibilities.3', '1.responsibilities.6', '4.responsibilities.2'}\n"
     ]
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "import pandas as pd\n",
    "\n",
    "resps_dir = RESPS_FILES_ITERATE_0_OPENAI_DIR\n",
    "file_glean = r\"C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_openai\\\\iteration_0\\\\responsibilities\\\\Glean_Head_of_Competitive_Intelligence_resps_flat_iter0.json\"\n",
    "\n",
    "data = load_and_decode_json(file_glean)\n",
    "print(len(data.get(\"responsibilities\")))\n",
    "\n",
    "csv_file = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\similarity_metrics\\Glean_Head_of_Competitive_Intelligence_sim_metrics_iter1.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "# print(df)\n",
    "no_of_resps = set(df.responsibility_key)\n",
    "print(len(no_of_resps))\n",
    "\n",
    "print(set(df.responsibility_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_reqs_flat_iter0.json\n",
      "Number of requirements: 10\n",
      "2. Adobe_Sr__Director__Applied_AI_ML__Discovery__reqs_flat_iter0.json\n",
      "Number of requirements: 7\n",
      "3. Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_reqs_flat_iter0.json\n",
      "Number of requirements: 12\n",
      "4. Airtable_Product_Manager__AI_reqs_flat_iter0.json\n",
      "Number of requirements: 8\n",
      "Skipping C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\requirements\\Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_reqs_flat_iter0.json: Validation failed - 2 validation errors for Requirements\n",
      "url\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': '1...e and Technical teams.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "requirements\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': '1...e and Technical teams.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "Skipping C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\requirements\\Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_reqs_flat_iter0.json: Validation failed - 2 validation errors for Requirements\n",
      "url\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': '1...imezones and languages'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "requirements\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': '1...imezones and languages'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "Skipping C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\requirements\\Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_reqs_flat_iter0.json: Validation failed - 2 validation errors for Requirements\n",
      "url\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': '1...ally protected status.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "requirements\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': '1...ally protected status.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "8. Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_reqs_flat_iter0.json\n",
      "Number of requirements: 12\n",
      "Skipping C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\requirements\\Amplitude_Marketing_Strategy___Analytics_Manager_reqs_flat_iter0.json: Validation failed - 2 validation errors for Requirements\n",
      "url\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': '1... in multiple locations'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "requirements\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': '1... in multiple locations'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "10. Blend_Director__AI_Strategy_reqs_flat_iter0.json\n",
      "Number of requirements: 8\n",
      "Skipping C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\requirements\\Capital_One_Director__AI_Platforms_reqs_flat_iter0.json: Validation failed - 2 validation errors for Requirements\n",
      "url\n",
      "  Field required [type=missing, input_value={'1.down_to_earth.0': \"Ba...for foundation models.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "requirements\n",
      "  Field required [type=missing, input_value={'1.down_to_earth.0': \"Ba...for foundation models.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "12. Deloitte_AI_Data_Specialist_reqs_flat_iter0.json\n",
      "Number of requirements: 14\n",
      "13. Deloitte_Global_Business_Services__GBS__Strategy_Manager_reqs_flat_iter0.json\n",
      "Number of requirements: 22\n",
      "14. Deloitte_Market_Research_Sr_Manager_reqs_flat_iter0.json\n",
      "Number of requirements: 9\n",
      "15. DEPT__Director_of_Applied_AI_Strategy__Media_reqs_flat_iter0.json\n",
      "Number of requirements: 12\n",
      "16. DigitalOcean_Director__Product_Management__AI_ML__reqs_flat_iter0.json\n",
      "Number of requirements: 9\n",
      "17. Figma_Researcher__Strategic_Growth_reqs_flat_iter0.json\n",
      "Number of requirements: 12\n",
      "18. Flex_Sr__Manager_AI_Strategy_reqs_flat_iter0.json\n",
      "Number of requirements: 12\n",
      "19. Glean_Head_of_Competitive_Intelligence_reqs_flat_iter0.json\n",
      "Number of requirements: 11\n",
      "Skipping C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\requirements\\Google_AI_Market_Intelligence_Principal_reqs_flat_iter0.json: Validation failed - 2 validation errors for Requirements\n",
      "url\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': 'M...s, exec reviews, etc.)'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "requirements\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': 'M...s, exec reviews, etc.)'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "21. Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_reqs_flat_iter0.json\n",
      "Number of requirements: 18\n",
      "Skipping C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\requirements\\Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_reqs_flat_iter0.json: Validation failed - 2 validation errors for Requirements\n",
      "url\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': 'T... a plus (not required)'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "requirements\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': 'T... a plus (not required)'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "Skipping C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\requirements\\Meta_Product_Strategy_Lead_reqs_flat_iter0.json: Validation failed - 2 validation errors for Requirements\n",
      "url\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': 'M...duct roadmap decisions'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "requirements\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': 'M...duct roadmap decisions'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "Skipping C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_0\\requirements\\Microsoft_Head_of_Partner_Intelligence_and_Strategy_reqs_flat_iter0.json: Validation failed - 2 validation errors for Requirements\n",
      "url\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': \"M...l opportunity employer'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "requirements\n",
      "  Field required [type=missing, input_value={'0.pie_in_the_sky.0': \"M...l opportunity employer'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "25. MongoDB_Director__Competitive_Intelligence_reqs_flat_iter0.json\n",
      "Number of requirements: 12\n",
      "26. PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_reqs_flat_iter0.json\n",
      "Number of requirements: 20\n",
      "27. Snowflake_Director__Product_Marketing_-_Analytics_reqs_flat_iter0.json\n",
      "Number of requirements: 10\n",
      "28. Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_reqs_flat_iter0.json\n",
      "Number of requirements: 3\n",
      "29. Trace3_Senior_Consultant__AI_Strategy__Remote__reqs_flat_iter0.json\n",
      "Number of requirements: 13\n",
      "30. Veeva_Systems_Director_-_Crossix_Analytics_Services_reqs_flat_iter0.json\n",
      "Number of requirements: 8\n"
     ]
    }
   ],
   "source": [
    "from pydantic import ValidationError\n",
    "from models.resume_job_description_io_models import Requirements\n",
    "from project_config import REQS_FILES_ITERATE_0_OPENAI_DIR\n",
    "from utils.get_file_names import get_file_names\n",
    "\n",
    "reqs_dir = REQS_FILES_ITERATE_0_OPENAI_DIR\n",
    "\n",
    "\n",
    "file_list = get_file_names(reqs_dir, True)\n",
    "\n",
    "for idx, file in enumerate(file_list, start=1):\n",
    "    try:\n",
    "        # Load JSON data\n",
    "        data = load_and_decode_json(file)\n",
    "\n",
    "        # Validate using Pydantic model\n",
    "        validated_data = Requirements(**data)\n",
    "\n",
    "        # If validation passes, print results\n",
    "        print(f\"{idx}. {Path(file).name}\")\n",
    "        print(f\"Number of requirements: {len(validated_data.requirements)}\")\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"Skipping {file}: Validation failed - {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Skipping {file}: Invalid JSON format - {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {file}: Unexpected error - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Requirements:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "\n",
       "  \"url\": \"https://www.accenture.com/us-en/careers/jobdetails?id=R00251798_en&src=LINKEDINJP\",\n",
       "  \"requirements\": {\n",
       "\n",
       "    \"0.pie_in_the_sky.0\": \"Shape vision and create opportunities for data & AI led business\n",
       "reinvention.\",\n",
       "    \"0.pie_in_the_sky.1\": \"Create strategy for AI-first products and develop commercialization\n",
       "opportunities.\",\n",
       "    \"1.down_to_earth.0\": \"5+ years of experience in business development, client relationship\n",
       "management, or marketing.\",\n",
       "    \"1.down_to_earth.1\": \"Proficiency in CRM tools such as Salesforce for tracking and analyzing\n",
       "client interactions.\",\n",
       "    \"1.down_to_earth.2\": \"Ability to build client relationships and credibility as a trusted advisor\n",
       "on how to infuse Data & AI into the business processes or functions.\",\n",
       "    \"2.cultural_fit.0\": \"Collaborative leadership style with a growth-oriented mindset.\",\n",
       "    \"2.cultural_fit.1\": \"Ability to mentor and develop high-performing teams.\",\n",
       "    \"2.cultural_fit.2\": \"Infuse Responsible AI in vision and roadmap, develop plan for leveraging\n",
       "ecosystem partners, and define operating model to foster a culture of innovation and\n",
       "experimentation.\",\n",
       "    \"3.other.0\": \"Experience working in professional services, Big Four firms, or consulting\n",
       "environments.\",\n",
       "    \"3.other.1\": \"Ability to travel up to 80%; travel as needed based on client expectations.\"\n",
       "  }\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job posting:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "\n",
       "  \"https://www.accenture.com/us-en/careers/jobdetails?id=R00251798_en&src=LINKEDINJP\": {\n",
       "\n",
       "    \"status\": \"success\",\n",
       "    \"message\": \"Job site data processed successfully.\",\n",
       "    \"data\": {\n",
       "\n",
       "      \"url\": \"https://www.accenture.com/us-en/careers/jobdetails?id=R00251798_en&src=LINKEDINJP\",\n",
       "      \"job_title\": \"Enterprise AI Value Strategy Senior Manager\",\n",
       "      \"company\": \"Accenture\",\n",
       "      \"location\": \"Multiple Locations\",\n",
       "      \"salary_info\": null,\n",
       "      \"posted_date\": null,\n",
       "      \"content\": {\n",
       "\n",
       "        \"Job Description\": \"Accenture is a leading global professional services company that helps\n",
       "the world's leading businesses, governments and other organizations build their digital core,\n",
       "optimize their operations, accelerate revenue growth, and enhance citizen services—creating tangible\n",
       "value at speed and scale. We are a talent- and innovation-led company with approximately 774,000\n",
       "people serving clients in more than 120 countries. Technology is at the core of change today, and we\n",
       "are one of the world's leaders in helping drive that change, with strong ecosystem relationships. We\n",
       "combine our strength in technology and leadership in cloud, data and AI with unmatched industry\n",
       "experience, functional expertise, and global delivery capability. We are uniquely able to deliver\n",
       "tangible outcomes because of our broad range of services, solutions and assets across Consulting,\n",
       "Strategy, Technology, Operations, Industry X and Song. These capabilities, together with our culture\n",
       "of shared success and commitment to creating 360° value, enable us to help our clients reinvent and\n",
       "build trusted, lasting relationships. We measure our success by the 360° value we create for our\n",
       "clients, each other, our shareholders, partners, and communities. Visit us at accenture.com.\\n\\nIn\n",
       "Consulting we work with C-suite executives, leaders and boards of the world's leading organizations,\n",
       "helping them reinvent every part of their enterprise to drive greater growth, enhance\n",
       "competitiveness, implement operational improvements, reduce cost, deliver sustainable 360°\n",
       "stakeholder value, and set a new performance frontier for themselves and the industry in which they\n",
       "operate. Our deep industry and functional expertise are supported by proprietary assets and\n",
       "solutions that help organizations transform faster and become more resilient.\\n\\nOur Data and AI\n",
       "Strategy practitioners work to create and execute an organizations business strategy for data and\n",
       "AI, including defining a compelling industry vision, creating value models, describing\n",
       "business/technology roadmap, and creating operating model and platform and ecosystem architecture,\n",
       "in support of data-led transformation. Use scaled agile disciplines to transform around iterative\n",
       "approach sequencing use cases focused on critical data elements aligned to data product and platform\n",
       "feature development.\\n\\nAs a Data & AI Strategy Senior Manager, you will:\\n\\n- Shape vision and\n",
       "create opportunities for data & AI led business reinvention.\\n- Build client relationships and\n",
       "credibility as a trusted advisor on how to infuse Data & AI into the business processes or\n",
       "functions\\n- Define and structure an organization's data and AI strategy to build and optimize data\n",
       "assets, AI technologies for growth & competitive advantages.\\n- Assess maturity of an organization's\n",
       "data and AI foundation. Define building blocks required to convert to an AI-first organization,\n",
       "including technology and AI platform blueprint, data strategy and future-ready operating model.\\n-\n",
       "Create the business case, investment profile and roadmap to deliver on the strategy.\\n- Infuse\n",
       "Responsible AI in vision and roadmap, develop plan for leveraging ecosystem partners, and define\n",
       "operating model to foster a culture of innovation and experimentation.\\n- Identify people,\n",
       "processes, and technologies to develop and operationalize AI solutions.\\n- Create strategy for AI-\n",
       "first products and develop commercialization opportunities.\\n- Originate new opportunities and see\n",
       "through sales cycle.\\n\\nAbility to travel up to 80%; travel as needed based on client\n",
       "expectations.\",\n",
       "        \"Qualification\": \"Locations\",\n",
       "        \"Additional Information\": \"About Accenture\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydantic import ValidationError\n",
    "from models.resume_job_description_io_models import Requirements\n",
    "from project_config import REQS_FILES_ITERATE_0_OPENAI_DIR\n",
    "from utils.get_file_names import get_file_names\n",
    "\n",
    "reqs_dir = REQS_FILES_ITERATE_0_OPENAI_DIR\n",
    "\n",
    "\n",
    "file_list = get_file_names(reqs_dir, True)\n",
    "\n",
    "acn_requirements_file = file_list[0]\n",
    "\n",
    "print(\"Job Requirements:\")\n",
    "display_json_pretty(acn_requirements_file)\n",
    "\n",
    "data = load_and_decode_json(acn_requirements_file)\n",
    "url = data.get(\"url\")\n",
    "\n",
    "job_postings = load_and_decode_json(JOB_DESCRIPTIONS_JSON_FILE)\n",
    "job_posting = job_postings.get(url)\n",
    "\n",
    "print(\"job posting:\")\n",
    "display_json_pretty(job_posting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anthropic I/O Iterate 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check all records from mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 15:40:39,378 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_0\\url_to_file_mapping.json\n",
      "2025-03-09 15:40:39,379 - evaluation_optimization.create_mapping_file - INFO - Loaded and validated mapping file from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_0\\url_to_file_mapping.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job URLs:\n",
      "Number of URLs: 30\n",
      "1. https://www.google.com/about/careers/applications/jobs/results/113657145978692294-ai-market-intelligence-principal/?src=Online/LinkedIn/linkedin_us&utm_source=linkedin&utm_medium=jobposting&utm_campaign=contract&utm_medium=jobboard&utm_source=linkedin\n",
      "2. https://www.capitalonecareers.com/job/-/-/234/66270465536?p_sid=ep3Sfxb&p_uid=sDBMWC5VxQ&source=rd_linkedin_job_posting_tm&ss=paid&utm_campaign=capone_all_jobs_24&utm_content=pj_board&utm_medium=jobad&utm_source=linkedin+slotted&dclid=CPGV3bef44gDFUEGTwgd4DoHPg\n",
      "3. https://boards.greenhouse.io/embed/job_app?token=7600823002&gh_src=ab9f35b82\n",
      "4. https://www.amazon.jobs/en/jobs/2696123/research-manager-strategy-and-insights-gca-marketing?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "5. https://www.amazon.jobs/en/jobs/2742527/sr-generative-ai-strategist-generative-ai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "6. https://www.amazon.jobs/en/jobs/2684745/product-manager-artificial-general-intelligence-data-services?cmpid=SPLICX0248M&ss=paid&utm_campaign=cxro&utm_content=job_posting&utm_medium=social_media&utm_source=linkedin.com\n",
      "7. https://jobs.careers.microsoft.com/us/en/job/1771714/Head-of-Partner-Intelligence-and-Strategy?jobsource=linkedin\n",
      "8. https://searchjobs.libertymutualgroup.com/careers/job/618499888480?microsite=libertymutual.com&domain=libertymutual.com&utm_source=Job+Board&utm_campaign=LinkedIn+Jobs&extcmp=bof-paid-text-lkin-aljb\n",
      "9. https://www.metacareers.com/jobs/522232286825036/?rx_campaign=Linkedin1&rx_ch=connector&rx_group=126320&rx_job=a1KDp00000E28eGMAR&rx_medium=post&rx_r=none&rx_source=Linkedin&rx_ts=20240927T121201Z&rx_vp=slots&utm_campaign=Job%2Bboard&utm_medium=jobs&utm_source=LIpaid&rx_viewer=e3efacca649311ef917d17a1705b89ba0dc4e1e7a57f4231bbce94a604c83931\n",
      "10. https://careers.adobe.com/us/en/job/ADOBUSR151695EXTERNALENUS/Sr-Director-Applied-AI-ML-Discovery?utm_source=linkedin&utm_medium=phenom-feeds&source=LinkedIn\n",
      "11. https://www.digitalocean.com/careers/position/apply?gh_jid=6437995&gh_src=312a08e31us\n",
      "12. https://boards.greenhouse.io/gleanwork/jobs/4425502005?source=LinkedIn\n",
      "13. https://job-boards.greenhouse.io/airtable/jobs/7603873002?gh_src=aef790d02us\n",
      "14. https://jobs.thermofisher.com/global/en/job/R-01298008/Market-Competitive-Intelligence-Manager?rx_ch=jobpost&rx_job=R-01298008-1&rx_medium=post&rx_paid=0&rx_r=none&rx_source=linkedin&rx_ts=20250206T184002Z&rx_vp=linkedindirectindex&utm_medium=post&utm_source=recruitics_linkedindirectindex&refId=34jd24&rx_viewer=e3efacca649311ef917d17a1705b89ba0dc4e1e7a57f4231bbce94a604c83931\n",
      "15. https://searchjobs.libertymutualgroup.com/careers/job/618501232921?microsite=libertymutual.com&domain=libertymutual.com&utm_source=Job+Board&utm_campaign=LinkedIn+Jobs&extcmp=bof-paid-text-lkin-aljb\n",
      "16. https://careers.veeva.com/job/365ff44c-8e0a-42b4-a117-27b409a77753/director-crossix-analytics-services-boston-ma/?lever-source=Linkedin\n",
      "17. https://jobs.us.pwc.com/job/-/-/932/76064801072?utm_source=linkedin.com&utm_campaign=core_media&utm_medium=social_media&utm_content=job_posting&ss=paid&dclid=CjgKEAiAwaG9BhCY3ayl47PW8lcSJAA_gCfjt-rzWhQetHLIbJdJBVocWQm2BRNcBgOARxhGyR9bgvD_BwE\n",
      "18. https://job-boards.greenhouse.io/trace3/jobs/6163213?gh_src=b81c67b41us\n",
      "19. https://job-boards.greenhouse.io/figma/jobs/5336109004?gh_jid=5336109004&gh_src=28109e334us&source=LinkedIn\n",
      "20. https://boards.greenhouse.io/dept/jobs/6564521\n",
      "21. https://flextronics.wd1.myworkdayjobs.com/en-US/Careers/job/Sr-Manager-AI-Strategy_WD191060?source=LinkedIn_Slots\n",
      "22. https://www.mongodb.com/careers/jobs/6466537\n",
      "23. https://apply.deloitte.com/careers/InviteToApply?jobId=210031&source=LinkedIn\n",
      "24. https://apply.deloitte.com/careers/InviteToApply?jobId=201718&source=LinkedIn\n",
      "25. https://apply.deloitte.com/careers/InviteToApply?jobId=199586&source=LinkedIn\n",
      "26. https://advisor360.breezy.hr/p/2e1636328c7d-senior-product-manager-ai-analytics-insights\n",
      "27. https://jobs.smartrecruiters.com/Blend360/744000042638791-director-ai-strategy?trid=2d92f286-613b-4daf-9dfa-6340ffbecf73\n",
      "28. https://www.amazon.jobs/en/jobs/2905092/senior-manger-partner-strategy-genai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "29. https://www.accenture.com/us-en/careers/jobdetails?id=R00251798_en&src=LINKEDINJP\n",
      "30. https://careers.snowflake.com/us/en/job/SNCOUS5AF10A9C7A01464788ABD17AECBEE52EEXTERNALENUS1CC71A00229E4662B768527743E6164F/Director-Product-Marketing-Analytics?utm_source=Q2P9NP2NNP&utm_medium=phenom-feeds&gh_src=ed5543a62\n",
      "\n",
      "\n",
      "sim_metrics paths:\n",
      "1. Google_AI_Market_Intelligence_Principal_sim_metrics_iter0.csv\n",
      "2. Capital_One_Director__AI_Platforms_sim_metrics_iter0.csv\n",
      "3. Amplitude_Marketing_Strategy___Analytics_Manager_sim_metrics_iter0.csv\n",
      "4. Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_sim_metrics_iter0.csv\n",
      "5. Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_sim_metrics_iter0.csv\n",
      "6. Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_sim_metrics_iter0.csv\n",
      "7. Microsoft_Head_of_Partner_Intelligence_and_Strategy_sim_metrics_iter0.csv\n",
      "8. Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_sim_metrics_iter0.csv\n",
      "9. Meta_Product_Strategy_Lead_sim_metrics_iter0.csv\n",
      "10. Adobe_Sr__Director__Applied_AI_ML__Discovery__sim_metrics_iter0.csv\n",
      "11. DigitalOcean_Director__Product_Management__AI_ML__sim_metrics_iter0.csv\n",
      "12. Glean_Head_of_Competitive_Intelligence_sim_metrics_iter0.csv\n",
      "13. Airtable_Product_Manager__AI_sim_metrics_iter0.csv\n",
      "14. Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_sim_metrics_iter0.csv\n",
      "15. Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_sim_metrics_iter0.csv\n",
      "16. Veeva_Systems_Director_-_Crossix_Analytics_Services_sim_metrics_iter0.csv\n",
      "17. PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_sim_metrics_iter0.csv\n",
      "18. Trace3_Senior_Consultant__AI_Strategy__Remote__sim_metrics_iter0.csv\n",
      "19. Figma_Researcher__Strategic_Growth_sim_metrics_iter0.csv\n",
      "20. DEPT__Director_of_Applied_AI_Strategy__Media_sim_metrics_iter0.csv\n",
      "21. Flex_Sr__Manager_AI_Strategy_sim_metrics_iter0.csv\n",
      "22. MongoDB_Director__Competitive_Intelligence_sim_metrics_iter0.csv\n",
      "23. Deloitte_Market_Research_Sr_Manager_sim_metrics_iter0.csv\n",
      "24. Deloitte_Global_Business_Services__GBS__Strategy_Manager_sim_metrics_iter0.csv\n",
      "25. Deloitte_AI_Data_Specialist_sim_metrics_iter0.csv\n",
      "26. Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_sim_metrics_iter0.csv\n",
      "27. Blend_Director__AI_Strategy_sim_metrics_iter0.csv\n",
      "28. Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_sim_metrics_iter0.csv\n",
      "29. Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_sim_metrics_iter0.csv\n",
      "30. Snowflake_Director__Product_Marketing_-_Analytics_sim_metrics_iter0.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "from models.resume_job_description_io_models import JobFileMappings\n",
    "from evaluation_optimization.create_mapping_file import load_mappings_model_from_json\n",
    "\n",
    "# from project_config import URL_TO_FILE_MAPPING_FILE_ITERATE_0_OPENAI\n",
    "\n",
    "directory = ITERATE_0_ANTHROPIC_DIR\n",
    "mapping_file = directory / mapping_file_name\n",
    "\n",
    "file_mapping_model = load_mappings_model_from_json(mapping_file)\n",
    "\n",
    "print(\"Job URLs:\")\n",
    "print(f\"Number of URLs: {len(file_mapping_model.root.keys())}\")\n",
    "\n",
    "for index, url in enumerate(file_mapping_model.root.keys(), start=1):\n",
    "    print(f\"{index}. {url}\")\n",
    "    # print()\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"sim_metrics paths:\")\n",
    "for index, jobpaths in enumerate(file_mapping_model.root.values(), start=1):\n",
    "    print(f\"{index}. {Path(jobpaths.sim_metrics).name}\")\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for specific records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching URLs:\n",
      "1. https://www.amazon.jobs/en/jobs/2696123/research-manager-strategy-and-insights-gca-marketing?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "\n",
      "2. https://www.amazon.jobs/en/jobs/2742527/sr-generative-ai-strategist-generative-ai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "\n",
      "3. https://www.amazon.jobs/en/jobs/2684745/product-manager-artificial-general-intelligence-data-services?cmpid=SPLICX0248M&ss=paid&utm_campaign=cxro&utm_content=job_posting&utm_medium=social_media&utm_source=linkedin.com\n",
      "\n",
      "4. https://jobs.smartrecruiters.com/Blend360/744000042638791-director-ai-strategy?trid=2d92f286-613b-4daf-9dfa-6340ffbecf73\n",
      "\n",
      "5. https://www.amazon.jobs/en/jobs/2905092/senior-manger-partner-strategy-genai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "\n",
      "6. https://careers.snowflake.com/us/en/job/SNCOUS5AF10A9C7A01464788ABD17AECBEE52EEXTERNALENUS1CC71A00229E4662B768527743E6164F/Director-Product-Marketing-Analytics?utm_source=Q2P9NP2NNP&utm_medium=phenom-feeds&gh_src=ed5543a62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_terms = [\"blend\", \"Amazon\", \"Blend\", \"Snowflake\"]\n",
    "\n",
    "\n",
    "# Find URLs that contain the search term\n",
    "matching_urls = [\n",
    "    url\n",
    "    for url in file_mapping_model.root.keys()\n",
    "    if any(term.lower() in str(url).lower() for term in search_terms)\n",
    "]\n",
    "\n",
    "print(\"Matching URLs:\")\n",
    "for index, url in enumerate(matching_urls, start=1):\n",
    "    print(f\"{index}. {url}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sim Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_metrics files in sim_metrics folder\n",
      "Number of files: 27\n",
      "1. Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_sim_metrics_iter0.csv\n",
      "2. Adobe_Sr__Director__Applied_AI_ML__Discovery__sim_metrics_iter0.csv\n",
      "3. Airtable_Product_Manager__AI_sim_metrics_iter0.csv\n",
      "4. Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_sim_metrics_iter0.csv\n",
      "5. Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_sim_metrics_iter0.csv\n",
      "6. Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_sim_metrics_iter0.csv\n",
      "7. Amplitude_Marketing_Strategy___Analytics_Manager_sim_metrics_iter0.csv\n",
      "8. Blend_Director__AI_Strategy_sim_metrics_iter0.csv\n",
      "9. Capital_One_Director__AI_Platforms_sim_metrics_iter0.csv\n",
      "10. Deloitte_AI_Data_Specialist_sim_metrics_iter0.csv\n",
      "11. Deloitte_Global_Business_Services__GBS__Strategy_Manager_sim_metrics_iter0.csv\n",
      "12. Deloitte_Market_Research_Sr_Manager_sim_metrics_iter0.csv\n",
      "13. DEPT__Director_of_Applied_AI_Strategy__Media_sim_metrics_iter0.csv\n",
      "14. DigitalOcean_Director__Product_Management__AI_ML__sim_metrics_iter0.csv\n",
      "15. Figma_Researcher__Strategic_Growth_sim_metrics_iter0.csv\n",
      "16. Flex_Sr__Manager_AI_Strategy_sim_metrics_iter0.csv\n",
      "17. Glean_Head_of_Competitive_Intelligence_sim_metrics_iter0.csv\n",
      "18. Google_AI_Market_Intelligence_Principal_sim_metrics_iter0.csv\n",
      "19. Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_sim_metrics_iter0.csv\n",
      "20. Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_sim_metrics_iter0.csv\n",
      "21. Meta_Product_Strategy_Lead_sim_metrics_iter0.csv\n",
      "22. Microsoft_Head_of_Partner_Intelligence_and_Strategy_sim_metrics_iter0.csv\n",
      "23. MongoDB_Director__Competitive_Intelligence_sim_metrics_iter0.csv\n",
      "24. PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_sim_metrics_iter0.csv\n",
      "25. Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_sim_metrics_iter0.csv\n",
      "26. Trace3_Senior_Consultant__AI_Strategy__Remote__sim_metrics_iter0.csv\n",
      "27. Veeva_Systems_Director_-_Crossix_Analytics_Services_sim_metrics_iter0.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "from models.resume_job_description_io_models import JobFileMappings\n",
    "from evaluation_optimization.create_mapping_file import load_mappings_model_from_json\n",
    "\n",
    "# from project_config import URL_TO_FILE_MAPPING_FILE_ITERATE_0_OPENAI\n",
    "\n",
    "directory = SIMILARITY_METRICS_ITERATE_0_ANTHROPIC_DIR\n",
    "file_list = get_file_names(directory_path=directory)\n",
    "\n",
    "print(\"sim_metrics files in sim_metrics folder\")\n",
    "print(f\"Number of files: {len(file_list)}\")\n",
    "\n",
    "for index, file_name in enumerate(file_list, start=1):\n",
    "    print(f\"{index}. {file_name}\")\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing records (similarity metrics files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 15:41:24,273 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_0\\url_to_file_mapping.json\n",
      "2025-03-09 15:41:24,275 - evaluation_optimization.create_mapping_file - INFO - Loaded and validated mapping file from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_0\\url_to_file_mapping.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing files in sim metrics folder: 3\n",
      "1. Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_sim_metrics_iter0.csv\n",
      "2. Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_sim_metrics_iter0.csv\n",
      "3. Snowflake_Director__Product_Marketing_-_Analytics_sim_metrics_iter0.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from utils.get_file_names import get_file_names\n",
    "from models.resume_job_description_io_models import JobFileMappings\n",
    "from evaluation_optimization.create_mapping_file import load_mappings_model_from_json\n",
    "\n",
    "# from project_config import URL_TO_FILE_MAPPING_FILE_ITERATE_0_OPENAI\n",
    "\n",
    "sim_metrics_dir = SIMILARITY_METRICS_ITERATE_0_ANTHROPIC_DIR\n",
    "file_list_sim_metrics_dir = get_file_names(directory_path=sim_metrics_dir)\n",
    "\n",
    "directory = ITERATE_0_ANTHROPIC_DIR\n",
    "mapping_file = directory / mapping_file_name\n",
    "file_mapping_model = load_mappings_model_from_json(mapping_file)\n",
    "file_list_mapping_file = [\n",
    "    Path(jobpaths.sim_metrics).name for jobpaths in file_mapping_model.root.values()\n",
    "]\n",
    "\n",
    "missing_files = set(file_list_mapping_file) - set(\n",
    "    file_list_sim_metrics_dir\n",
    ")  # Elements in list1 but not in list2\n",
    "\n",
    "print(f\"Number of missing files in sim metrics folder: {len(missing_files)}\")\n",
    "for idx, f_name in enumerate(missing_files, start=1):\n",
    "    print(f\"{idx}. {f_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 15:43:34,592 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_0\\url_to_file_mapping.json\n",
      "2025-03-09 15:43:34,592 - evaluation_optimization.create_mapping_file - INFO - Loaded and validated mapping file from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_0\\url_to_file_mapping.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in reqs dir: 30\n",
      "Files in resps dir: 30\n",
      "Files in mapping file: 30\n",
      "\n",
      "Number of missing files in sim metrics folder: 3\n",
      "1. Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_sim_metrics_iter0.csv\n",
      "2. Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_sim_metrics_iter0.csv\n",
      "3. Snowflake_Director__Product_Marketing_-_Analytics_sim_metrics_iter0.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from utils.get_file_names import get_file_names\n",
    "from models.resume_job_description_io_models import JobFileMappings, Requirements\n",
    "from evaluation_optimization.create_mapping_file import load_mappings_model_from_json\n",
    "\n",
    "# from project_config import URL_TO_FILE_MAPPING_FILE_ITERATE_0_OPENAI\n",
    "\n",
    "sim_metrics_dir = SIMILARITY_METRICS_ITERATE_0_ANTHROPIC_DIR\n",
    "file_list_sim_metrics_dir = get_file_names(directory_path=sim_metrics_dir)\n",
    "\n",
    "requirements_dir = REQS_FILES_ITERATE_0_ANTHROPIC_DIR\n",
    "file_list_reqs_dir = get_file_names(requirements_dir)\n",
    "print(f\"Files in reqs dir: {len(file_list_reqs_dir)}\")\n",
    "\n",
    "responsibilities_dir = RESPS_FILES_ITERATE_0_ANTHROPIC_DIR\n",
    "file_list_resps_dir = get_file_names(responsibilities_dir)\n",
    "print(f\"Files in resps dir: {len(file_list_resps_dir)}\")\n",
    "\n",
    "directory = ITERATE_0_ANTHROPIC_DIR\n",
    "mapping_file = directory / mapping_file_name\n",
    "file_mapping_model = load_mappings_model_from_json(mapping_file)\n",
    "file_list_mapping_file = [\n",
    "    Path(jobpaths.sim_metrics).name for jobpaths in file_mapping_model.root.values()\n",
    "]\n",
    "print(f\"Files in mapping file: {len(file_list_mapping_file)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "missing_files = set(file_list_mapping_file) - set(\n",
    "    file_list_sim_metrics_dir\n",
    ")  # Elements in list1 but not in list2\n",
    "\n",
    "print(f\"Number of missing files in sim metrics folder: {len(missing_files)}\")\n",
    "for idx, f_name in enumerate(missing_files, start=1):\n",
    "    print(f\"{idx}. {f_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_reqs_flat_iter0.json\n",
      "Number of requirements: 10\n",
      "2. Adobe_Sr__Director__Applied_AI_ML__Discovery__reqs_flat_iter0.json\n",
      "Number of requirements: 6\n",
      "3. Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_reqs_flat_iter0.json\n",
      "Number of requirements: 12\n",
      "4. Airtable_Product_Manager__AI_reqs_flat_iter0.json\n",
      "Number of requirements: 5\n",
      "5. Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_reqs_flat_iter0.json\n",
      "Number of requirements: 8\n",
      "6. Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_reqs_flat_iter0.json\n",
      "Number of requirements: 8\n",
      "7. Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_reqs_flat_iter0.json\n",
      "Number of requirements: 12\n",
      "8. Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_reqs_flat_iter0.json\n",
      "Number of requirements: 12\n",
      "9. Amplitude_Marketing_Strategy___Analytics_Manager_reqs_flat_iter0.json\n",
      "Number of requirements: 13\n",
      "10. Blend_Director__AI_Strategy_reqs_flat_iter0.json\n",
      "Number of requirements: 8\n",
      "11. Capital_One_Director__AI_Platforms_reqs_flat_iter0.json\n",
      "Number of requirements: 9\n",
      "12. Deloitte_AI_Data_Specialist_reqs_flat_iter0.json\n",
      "Number of requirements: 12\n",
      "13. Deloitte_Global_Business_Services__GBS__Strategy_Manager_reqs_flat_iter0.json\n",
      "Number of requirements: 17\n",
      "14. Deloitte_Market_Research_Sr_Manager_reqs_flat_iter0.json\n",
      "Number of requirements: 6\n",
      "15. DEPT__Director_of_Applied_AI_Strategy__Media_reqs_flat_iter0.json\n",
      "Number of requirements: 9\n",
      "16. DigitalOcean_Director__Product_Management__AI_ML__reqs_flat_iter0.json\n",
      "Number of requirements: 6\n",
      "17. Figma_Researcher__Strategic_Growth_reqs_flat_iter0.json\n",
      "Number of requirements: 9\n",
      "18. Flex_Sr__Manager_AI_Strategy_reqs_flat_iter0.json\n",
      "Number of requirements: 10\n",
      "19. Glean_Head_of_Competitive_Intelligence_reqs_flat_iter0.json\n",
      "Number of requirements: 10\n",
      "20. Google_AI_Market_Intelligence_Principal_reqs_flat_iter0.json\n",
      "Number of requirements: 12\n",
      "21. Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_reqs_flat_iter0.json\n",
      "Number of requirements: 14\n",
      "22. Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_reqs_flat_iter0.json\n",
      "Number of requirements: 14\n",
      "23. Meta_Product_Strategy_Lead_reqs_flat_iter0.json\n",
      "Number of requirements: 11\n",
      "24. Microsoft_Head_of_Partner_Intelligence_and_Strategy_reqs_flat_iter0.json\n",
      "Number of requirements: 15\n",
      "25. MongoDB_Director__Competitive_Intelligence_reqs_flat_iter0.json\n",
      "Number of requirements: 12\n",
      "26. PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_reqs_flat_iter0.json\n",
      "Number of requirements: 16\n",
      "27. Snowflake_Director__Product_Marketing_-_Analytics_reqs_flat_iter0.json\n",
      "Number of requirements: 10\n",
      "28. Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_reqs_flat_iter0.json\n",
      "Number of requirements: 1\n",
      "29. Trace3_Senior_Consultant__AI_Strategy__Remote__reqs_flat_iter0.json\n",
      "Number of requirements: 6\n",
      "30. Veeva_Systems_Director_-_Crossix_Analytics_Services_reqs_flat_iter0.json\n",
      "Number of requirements: 5\n"
     ]
    }
   ],
   "source": [
    "from models.resume_job_description_io_models import Requirements\n",
    "from project_config import REQS_FILES_ITERATE_0_ANTHROPIC_DIR\n",
    "\n",
    "reqs_dir = REQS_FILES_ITERATE_0_ANTHROPIC_DIR\n",
    "\n",
    "\n",
    "file_list = get_file_names(reqs_dir, True)\n",
    "\n",
    "for idx, file in enumerate(file_list, start=1):\n",
    "    data = load_and_decode_json(file)\n",
    "    validated_data = Requirements(**data)\n",
    "\n",
    "    print(f\"{idx}. {Path(file).name}\")\n",
    "    print(f\"Number of requirements: {len(validated_data.requirements)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Iteration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "from IPython.display import display, Markdown\n",
    "from project_config import (\n",
    "    JOB_POSTING_URLS_FILE,\n",
    "    JOB_DESCRIPTIONS_JSON_FILE,\n",
    "    JOB_REQUIREMENTS_JSON_FILE,\n",
    "    ITERATE_1_ANTHROPIC_DIR,\n",
    "    mapping_file_name,\n",
    "    REQS_FILES_ITERATE_1_ANTHROPIC_DIR,\n",
    "    RESPS_FILES_ITERATE_1_ANTHROPIC_DIR,\n",
    "    SIMILARITY_METRICS_ITERATE_1_ANTHROPIC_DIR,\n",
    "    ITERATE_1_OPENAI_DIR,\n",
    "    REQS_FILES_ITERATE_1_OPENAI_DIR,\n",
    "    RESPS_FILES_ITERATE_1_OPENAI_DIR,\n",
    "    SIMILARITY_METRICS_ITERATE_1_OPENAI_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anthropic Iterate 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Responsibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responsibilities file names: \n",
      "Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_resps_nested_iter1.json\n",
      "Adobe_Sr__Director__Applied_AI_ML__Discovery__resps_nested_iter1.json\n",
      "Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_resps_nested_iter1.json\n",
      "Airtable_Product_Manager__AI_resps_nested_iter1.json\n",
      "Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_resps_nested_iter1.json\n",
      "Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_resps_nested_iter1.json\n",
      "Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_resps_nested_iter1.json\n",
      "Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_resps_nested_iter1.json\n",
      "Amplitude_Marketing_Strategy___Analytics_Manager_resps_nested_iter1.json\n",
      "Blend_Director__AI_Strategy_resps_nested_iter1.json\n",
      "Capital_One_Director__AI_Platforms_resps_nested_iter1.json\n",
      "Deloitte_AI_Data_Specialist_resps_nested_iter1.json\n",
      "Deloitte_Global_Business_Services__GBS__Strategy_Manager_resps_nested_iter1.json\n",
      "Deloitte_Market_Research_Sr_Manager_resps_nested_iter1.json\n",
      "DEPT__Director_of_Applied_AI_Strategy__Media_resps_nested_iter1.json\n",
      "DigitalOcean_Director__Product_Management__AI_ML__resps_nested_iter1.json\n",
      "Figma_Researcher__Strategic_Growth_resps_nested_iter1.json\n",
      "Flex_Sr__Manager_AI_Strategy_resps_nested_iter1.json\n",
      "Glean_Head_of_Competitive_Intelligence_resps_nested_iter1.json\n",
      "Google_AI_Market_Intelligence_Principal_resps_nested_iter1.json\n",
      "Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_resps_nested_iter1.json\n",
      "Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_resps_nested_iter1.json\n",
      "Meta_Product_Strategy_Lead_resps_nested_iter1.json\n",
      "Microsoft_Head_of_Partner_Intelligence_and_Strategy_resps_nested_iter1.json\n",
      "MongoDB_Director__Competitive_Intelligence_resps_nested_iter1.json\n",
      "PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_resps_nested_iter1.json\n",
      "Snowflake_Director__Product_Marketing_-_Analytics_resps_nested_iter1.json\n",
      "Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_resps_nested_iter1.json\n",
      "Trace3_Senior_Consultant__AI_Strategy__Remote__resps_nested_iter1.json\n",
      "Veeva_Systems_Director_-_Crossix_Analytics_Services_resps_nested_iter1.json\n"
     ]
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "\n",
    "directory = RESPS_FILES_ITERATE_1_ANTHROPIC_DIR\n",
    "\n",
    "file_names = get_file_names(directory_path=directory)\n",
    "\n",
    "print(f\"Responsibilities file names: \\n\" + \"\\n\".join(name for name in file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "\n",
      "File: Adobe_Sr__Director__Applied_AI_ML__Discovery__resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.0 -> Matches: 6\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "Least Matched Responsibility: 3.responsibilities.0 -> Matches: 7\n",
      "\n",
      "File: Airtable_Product_Manager__AI_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.3 -> Matches: 5\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 2.responsibilities.0 -> Matches: 8\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.5 -> Matches: 8\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.4 -> Matches: 12\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "\n",
      "File: Amplitude_Marketing_Strategy___Analytics_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.2 -> Matches: 13\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Blend_Director__AI_Strategy_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "\n",
      "File: Capital_One_Director__AI_Platforms_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 2.responsibilities.0 -> Matches: 9\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Deloitte_AI_Data_Specialist_resps_nested_iter1.json\n",
      "Total Responsibilities: 31\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "\n",
      "File: Deloitte_Global_Business_Services__GBS__Strategy_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 31\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 17\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 17\n",
      "\n",
      "File: Deloitte_Market_Research_Sr_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 31\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 6\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 6\n",
      "\n",
      "File: DEPT__Director_of_Applied_AI_Strategy__Media_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 9\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 9\n",
      "\n",
      "File: DigitalOcean_Director__Product_Management__AI_ML__resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 4.responsibilities.0 -> Matches: 6\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Figma_Researcher__Strategic_Growth_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 9\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 9\n",
      "\n",
      "File: Flex_Sr__Manager_AI_Strategy_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "\n",
      "File: Glean_Head_of_Competitive_Intelligence_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "\n",
      "File: Google_AI_Market_Intelligence_Principal_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.3 -> Matches: 12\n",
      "Least Matched Responsibility: 0.responsibilities.7 -> Matches: 1\n",
      "\n",
      "File: Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.3 -> Matches: 14\n",
      "Least Matched Responsibility: 0.responsibilities.1 -> Matches: 1\n",
      "\n",
      "File: Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 1.responsibilities.8 -> Matches: 14\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Meta_Product_Strategy_Lead_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.5 -> Matches: 11\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Microsoft_Head_of_Partner_Intelligence_and_Strategy_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 3.responsibilities.3 -> Matches: 15\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: MongoDB_Director__Competitive_Intelligence_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 12\n",
      "\n",
      "File: PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 16\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 16\n",
      "\n",
      "File: Snowflake_Director__Product_Marketing_-_Analytics_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "\n",
      "File: Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Trace3_Senior_Consultant__AI_Strategy__Remote__resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 6\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 6\n",
      "\n",
      "File: Veeva_Systems_Director_-_Crossix_Analytics_Services_resps_nested_iter1.json\n",
      "Total Responsibilities: 26\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 5\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models.resume_job_description_io_models import NestedResponsibilities\n",
    "\n",
    "# Load and validate the JSON data\n",
    "# file_name = \"Blend_Director__AI_Strategy_resps_nested_iter1.json\"\n",
    "file_name = (\n",
    "    \"Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_resps_nested_iter1.json\"\n",
    ")\n",
    "\n",
    "for file in file_names:\n",
    "    # file_name = \"Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_resps_nested_iter1.json\"\n",
    "    file_path = RESPS_FILES_ITERATE_1_ANTHROPIC_DIR / file\n",
    "\n",
    "    data = load_and_decode_json(file_path)\n",
    "    validated_data = NestedResponsibilities(**data)\n",
    "\n",
    "    # Compute the number of matched requirements per responsibility\n",
    "    num_requirements_per_responsibility = {\n",
    "        resp_key: len(resp.optimized_by_requirements)\n",
    "        for resp_key, resp in validated_data.responsibilities.items()\n",
    "    }\n",
    "\n",
    "    # Display some insights\n",
    "    most_matched_resp = max(\n",
    "        num_requirements_per_responsibility,\n",
    "        key=lambda k: num_requirements_per_responsibility[k],\n",
    "    )\n",
    "\n",
    "    least_matched_resp = min(\n",
    "        num_requirements_per_responsibility,\n",
    "        key=lambda k: num_requirements_per_responsibility[k],\n",
    "    )\n",
    "\n",
    "    print(f\"File: {file}\")\n",
    "    print(f\"Total Responsibilities: {len(num_requirements_per_responsibility)}\")\n",
    "    print(\n",
    "        f\"Most Matched Responsibility: {most_matched_resp} -> Matches: {num_requirements_per_responsibility[most_matched_resp]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Least Matched Responsibility: {least_matched_resp} -> Matches: {num_requirements_per_responsibility[least_matched_resp]}\"\n",
    "    )\n",
    "    print()\n",
    "\n",
    "# Find responsibilities with zero matches\n",
    "no_match_resps = [\n",
    "    resp_key\n",
    "    for resp_key, count in num_requirements_per_responsibility.items()\n",
    "    if count == 0\n",
    "]\n",
    "# print(f\"Responsibilities with no matched requirements: {len(no_match_resps)}\")\n",
    "\n",
    "# matches_list = validated_data.responsibilities[\"2.responsibilities.7\"]\n",
    "# match_list = matches_list.model_dump()\n",
    "# match_list\n",
    "# # Distribution of matches\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.hist(num_requirements_per_responsibility.values(), bins=10, edgecolor=\"black\")\n",
    "# plt.xlabel(\"Number of Matched Requirements\")\n",
    "# plt.ylabel(\"Number of Responsibilities\")\n",
    "# plt.title(\"Distribution of Requirement Matches per Responsibility\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in requirements dir: \n",
      " Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_reqs_flat_iter1.json.\n",
      "Adobe_Sr__Director__Applied_AI_ML__Discovery__reqs_flat_iter1.json.\n",
      "Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_reqs_flat_iter1.json.\n",
      "Airtable_Product_Manager__AI_reqs_flat_iter1.json.\n",
      "Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_reqs_flat_iter1.json.\n",
      "Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_reqs_flat_iter1.json.\n",
      "Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_reqs_flat_iter1.json.\n",
      "Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_reqs_flat_iter1.json.\n",
      "Amplitude_Marketing_Strategy___Analytics_Manager_reqs_flat_iter1.json.\n",
      "Blend_Director__AI_Strategy_reqs_flat_iter1.json.\n",
      "Capital_One_Director__AI_Platforms_reqs_flat_iter1.json.\n",
      "Deloitte_AI_Data_Specialist_reqs_flat_iter1.json.\n",
      "Deloitte_Global_Business_Services__GBS__Strategy_Manager_reqs_flat_iter1.json.\n",
      "Deloitte_Market_Research_Sr_Manager_reqs_flat_iter1.json.\n",
      "DEPT__Director_of_Applied_AI_Strategy__Media_reqs_flat_iter1.json.\n",
      "DigitalOcean_Director__Product_Management__AI_ML__reqs_flat_iter1.json.\n",
      "Figma_Researcher__Strategic_Growth_reqs_flat_iter1.json.\n",
      "Flex_Sr__Manager_AI_Strategy_reqs_flat_iter1.json.\n",
      "Glean_Head_of_Competitive_Intelligence_reqs_flat_iter1.json.\n",
      "Google_AI_Market_Intelligence_Principal_reqs_flat_iter1.json.\n",
      "Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_reqs_flat_iter1.json.\n",
      "Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_reqs_flat_iter1.json.\n",
      "Meta_Product_Strategy_Lead_reqs_flat_iter1.json.\n",
      "Microsoft_Head_of_Partner_Intelligence_and_Strategy_reqs_flat_iter1.json.\n",
      "MongoDB_Director__Competitive_Intelligence_reqs_flat_iter1.json.\n",
      "PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_reqs_flat_iter1.json.\n",
      "Snowflake_Director__Product_Marketing_-_Analytics_reqs_flat_iter1.json.\n",
      "Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_reqs_flat_iter1.json.\n",
      "Trace3_Senior_Consultant__AI_Strategy__Remote__reqs_flat_iter1.json.\n",
      "Veeva_Systems_Director_-_Crossix_Analytics_Services_reqs_flat_iter1.json\n"
     ]
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "\n",
    "directory = REQS_FILES_ITERATE_1_ANTHROPIC_DIR\n",
    "\n",
    "file_names = get_file_names(directory_path=directory)\n",
    "print(f\"Files in requirements dir: \\n\", \".\\n\".join(names for names in file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Adobe_Sr__Director__Applied_AI_ML__Discovery__reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Airtable_Product_Manager__AI_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Amplitude_Marketing_Strategy___Analytics_Manager_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Blend_Director__AI_Strategy_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Capital_One_Director__AI_Platforms_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Deloitte_AI_Data_Specialist_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Deloitte_Global_Business_Services__GBS__Strategy_Manager_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Deloitte_Market_Research_Sr_Manager_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\DEPT__Director_of_Applied_AI_Strategy__Media_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\DigitalOcean_Director__Product_Management__AI_ML__reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Figma_Researcher__Strategic_Growth_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Flex_Sr__Manager_AI_Strategy_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Glean_Head_of_Competitive_Intelligence_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Google_AI_Market_Intelligence_Principal_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Meta_Product_Strategy_Lead_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Microsoft_Head_of_Partner_Intelligence_and_Strategy_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\MongoDB_Director__Competitive_Intelligence_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Snowflake_Director__Product_Marketing_-_Analytics_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Trace3_Senior_Consultant__AI_Strategy__Remote__reqs_flat_iter1.json', 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\requirements\\\\Veeva_Systems_Director_-_Crossix_Analytics_Services_reqs_flat_iter1.json']\n",
      "1. Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_reqs_flat_iter1.json\n",
      "Number of requirements: 10\n",
      "2. Adobe_Sr__Director__Applied_AI_ML__Discovery__reqs_flat_iter1.json\n",
      "Number of requirements: 6\n",
      "3. Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_reqs_flat_iter1.json\n",
      "Number of requirements: 12\n",
      "4. Airtable_Product_Manager__AI_reqs_flat_iter1.json\n",
      "Number of requirements: 5\n",
      "5. Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_reqs_flat_iter1.json\n",
      "Number of requirements: 8\n",
      "6. Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_reqs_flat_iter1.json\n",
      "Number of requirements: 8\n",
      "7. Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_reqs_flat_iter1.json\n",
      "Number of requirements: 12\n",
      "8. Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_reqs_flat_iter1.json\n",
      "Number of requirements: 12\n",
      "9. Amplitude_Marketing_Strategy___Analytics_Manager_reqs_flat_iter1.json\n",
      "Number of requirements: 13\n",
      "10. Blend_Director__AI_Strategy_reqs_flat_iter1.json\n",
      "Number of requirements: 8\n",
      "11. Capital_One_Director__AI_Platforms_reqs_flat_iter1.json\n",
      "Number of requirements: 9\n",
      "12. Deloitte_AI_Data_Specialist_reqs_flat_iter1.json\n",
      "Number of requirements: 12\n",
      "13. Deloitte_Global_Business_Services__GBS__Strategy_Manager_reqs_flat_iter1.json\n",
      "Number of requirements: 17\n",
      "14. Deloitte_Market_Research_Sr_Manager_reqs_flat_iter1.json\n",
      "Number of requirements: 6\n",
      "15. DEPT__Director_of_Applied_AI_Strategy__Media_reqs_flat_iter1.json\n",
      "Number of requirements: 9\n",
      "16. DigitalOcean_Director__Product_Management__AI_ML__reqs_flat_iter1.json\n",
      "Number of requirements: 6\n",
      "17. Figma_Researcher__Strategic_Growth_reqs_flat_iter1.json\n",
      "Number of requirements: 9\n",
      "18. Flex_Sr__Manager_AI_Strategy_reqs_flat_iter1.json\n",
      "Number of requirements: 10\n",
      "19. Glean_Head_of_Competitive_Intelligence_reqs_flat_iter1.json\n",
      "Number of requirements: 10\n",
      "20. Google_AI_Market_Intelligence_Principal_reqs_flat_iter1.json\n",
      "Number of requirements: 12\n",
      "21. Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_reqs_flat_iter1.json\n",
      "Number of requirements: 14\n",
      "22. Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_reqs_flat_iter1.json\n",
      "Number of requirements: 14\n",
      "23. Meta_Product_Strategy_Lead_reqs_flat_iter1.json\n",
      "Number of requirements: 11\n",
      "24. Microsoft_Head_of_Partner_Intelligence_and_Strategy_reqs_flat_iter1.json\n",
      "Number of requirements: 15\n",
      "25. MongoDB_Director__Competitive_Intelligence_reqs_flat_iter1.json\n",
      "Number of requirements: 12\n",
      "26. PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_reqs_flat_iter1.json\n",
      "Number of requirements: 16\n",
      "27. Snowflake_Director__Product_Marketing_-_Analytics_reqs_flat_iter1.json\n",
      "Number of requirements: 10\n",
      "28. Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_reqs_flat_iter1.json\n",
      "Number of requirements: 1\n",
      "29. Trace3_Senior_Consultant__AI_Strategy__Remote__reqs_flat_iter1.json\n",
      "Number of requirements: 6\n",
      "30. Veeva_Systems_Director_-_Crossix_Analytics_Services_reqs_flat_iter1.json\n",
      "Number of requirements: 5\n"
     ]
    }
   ],
   "source": [
    "from models.resume_job_description_io_models import Requirements\n",
    "\n",
    "# Load and validate the JSON data\n",
    "\n",
    "# file_name = \"Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_reqs_flat_iter1.json\"\n",
    "# file_name = \"Blend_Director__AI_Strategy_reqs_flat_iter1.json\"\n",
    "# file_name = 'Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_reqs_flat_iter1.json'\n",
    "\n",
    "file_list = get_file_names(REQS_FILES_ITERATE_1_ANTHROPIC_DIR, True)\n",
    "print(file_list)\n",
    "\n",
    "for idx, file in enumerate(file_list, start=1):\n",
    "    data = load_and_decode_json(file)\n",
    "    validated_data = Requirements(**data)\n",
    "\n",
    "    print(f\"{idx}. {Path(file).name}\")\n",
    "    print(f\"Number of requirements: {len(validated_data.requirements)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Iterate 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 14:15:07,624 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\url_to_file_mapping.json\n",
      "2025-03-18 14:15:07,625 - evaluation_optimization.create_mapping_file - INFO - Loaded and validated mapping file from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\url_to_file_mapping.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job URLs:\n",
      "Number of URLs: 30\n",
      "1. https://www.google.com/about/careers/applications/jobs/results/113657145978692294-ai-market-intelligence-principal/?src=Online/LinkedIn/linkedin_us&utm_source=linkedin&utm_medium=jobposting&utm_campaign=contract&utm_medium=jobboard&utm_source=linkedin\n",
      "2. https://www.capitalonecareers.com/job/-/-/234/66270465536?p_sid=ep3Sfxb&p_uid=sDBMWC5VxQ&source=rd_linkedin_job_posting_tm&ss=paid&utm_campaign=capone_all_jobs_24&utm_content=pj_board&utm_medium=jobad&utm_source=linkedin+slotted&dclid=CPGV3bef44gDFUEGTwgd4DoHPg\n",
      "3. https://boards.greenhouse.io/embed/job_app?token=7600823002&gh_src=ab9f35b82\n",
      "4. https://www.amazon.jobs/en/jobs/2696123/research-manager-strategy-and-insights-gca-marketing?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "5. https://www.amazon.jobs/en/jobs/2742527/sr-generative-ai-strategist-generative-ai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "6. https://www.amazon.jobs/en/jobs/2684745/product-manager-artificial-general-intelligence-data-services?cmpid=SPLICX0248M&ss=paid&utm_campaign=cxro&utm_content=job_posting&utm_medium=social_media&utm_source=linkedin.com\n",
      "7. https://jobs.careers.microsoft.com/us/en/job/1771714/Head-of-Partner-Intelligence-and-Strategy?jobsource=linkedin\n",
      "8. https://searchjobs.libertymutualgroup.com/careers/job/618499888480?microsite=libertymutual.com&domain=libertymutual.com&utm_source=Job+Board&utm_campaign=LinkedIn+Jobs&extcmp=bof-paid-text-lkin-aljb\n",
      "9. https://www.metacareers.com/jobs/522232286825036/?rx_campaign=Linkedin1&rx_ch=connector&rx_group=126320&rx_job=a1KDp00000E28eGMAR&rx_medium=post&rx_r=none&rx_source=Linkedin&rx_ts=20240927T121201Z&rx_vp=slots&utm_campaign=Job%2Bboard&utm_medium=jobs&utm_source=LIpaid&rx_viewer=e3efacca649311ef917d17a1705b89ba0dc4e1e7a57f4231bbce94a604c83931\n",
      "10. https://jobs.us.pwc.com/job/-/-/932/76064801072?utm_source=linkedin.com&utm_campaign=core_media&utm_medium=social_media&utm_content=job_posting&ss=paid&dclid=CjgKEAiAwaG9BhCY3ayl47PW8lcSJAA_gCfjt-rzWhQetHLIbJdJBVocWQm2BRNcBgOARxhGyR9bgvD_BwE\n",
      "11. https://job-boards.greenhouse.io/trace3/jobs/6163213?gh_src=b81c67b41us\n",
      "12. https://boards.greenhouse.io/dept/jobs/6564521\n",
      "13. https://careers.snowflake.com/us/en/job/SNCOUS5AF10A9C7A01464788ABD17AECBEE52EEXTERNALENUS1CC71A00229E4662B768527743E6164F/Director-Product-Marketing-Analytics?utm_source=Q2P9NP2NNP&utm_medium=phenom-feeds&gh_src=ed5543a62\n",
      "14. https://job-boards.greenhouse.io/airtable/jobs/7603873002?gh_src=aef790d02us\n",
      "15. https://www.accenture.com/us-en/careers/jobdetails?id=R00251798_en&src=LINKEDINJP\n",
      "16. https://boards.greenhouse.io/gleanwork/jobs/4425502005?source=LinkedIn\n",
      "17. https://jobs.smartrecruiters.com/Blend360/744000042638791-director-ai-strategy?trid=2d92f286-613b-4daf-9dfa-6340ffbecf73\n",
      "18. https://careers.veeva.com/job/365ff44c-8e0a-42b4-a117-27b409a77753/director-crossix-analytics-services-boston-ma/?lever-source=Linkedin\n",
      "19. https://flextronics.wd1.myworkdayjobs.com/en-US/Careers/job/Sr-Manager-AI-Strategy_WD191060?source=LinkedIn_Slots\n",
      "20. https://www.digitalocean.com/careers/position/apply?gh_jid=6437995&gh_src=312a08e31us\n",
      "21. https://job-boards.greenhouse.io/figma/jobs/5336109004?gh_jid=5336109004&gh_src=28109e334us&source=LinkedIn\n",
      "22. https://advisor360.breezy.hr/p/2e1636328c7d-senior-product-manager-ai-analytics-insights\n",
      "23. https://jobs.thermofisher.com/global/en/job/R-01298008/Market-Competitive-Intelligence-Manager?rx_ch=jobpost&rx_job=R-01298008-1&rx_medium=post&rx_paid=0&rx_r=none&rx_source=linkedin&rx_ts=20250206T184002Z&rx_vp=linkedindirectindex&utm_medium=post&utm_source=recruitics_linkedindirectindex&refId=34jd24&rx_viewer=e3efacca649311ef917d17a1705b89ba0dc4e1e7a57f4231bbce94a604c83931\n",
      "24. https://www.mongodb.com/careers/jobs/6466537\n",
      "25. https://searchjobs.libertymutualgroup.com/careers/job/618501232921?microsite=libertymutual.com&domain=libertymutual.com&utm_source=Job+Board&utm_campaign=LinkedIn+Jobs&extcmp=bof-paid-text-lkin-aljb\n",
      "26. https://apply.deloitte.com/careers/InviteToApply?jobId=199586&source=LinkedIn\n",
      "27. https://apply.deloitte.com/careers/InviteToApply?jobId=210031&source=LinkedIn\n",
      "28. https://www.amazon.jobs/en/jobs/2905092/senior-manger-partner-strategy-genai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "29. https://apply.deloitte.com/careers/InviteToApply?jobId=201718&source=LinkedIn\n",
      "30. https://careers.adobe.com/us/en/job/ADOBUSR151695EXTERNALENUS/Sr-Director-Applied-AI-ML-Discovery?utm_source=linkedin&utm_medium=phenom-feeds&source=LinkedIn\n",
      "\n",
      "\n",
      "https://boards.greenhouse.io/gleanwork/jobs/4425502005?source=LinkedIn\n"
     ]
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "from pathlib import Path\n",
    "\n",
    "from models.resume_job_description_io_models import JobFileMappings\n",
    "\n",
    "from evaluation_optimization.create_mapping_file import load_mappings_model_from_json\n",
    "\n",
    "\n",
    "# from project_config import URL_TO_FILE_MAPPING_FILE_ITERATE_0_OPENAI\n",
    "\n",
    "\n",
    "directory = ITERATE_1_OPENAI_DIR\n",
    "mapping_file = directory / mapping_file_name\n",
    "file_mapping_model = load_mappings_model_from_json(mapping_file)\n",
    "\n",
    "\n",
    "print(\"Job URLs:\")\n",
    "print(f\"Number of URLs: {len(file_mapping_model.root.keys())}\")\n",
    "\n",
    "\n",
    "for index, url in enumerate(file_mapping_model.root.keys(), start=1):\n",
    "    print(f\"{index}. {url}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\n",
    "    *(\n",
    "        url\n",
    "        for index, url in enumerate(file_mapping_model.root.keys(), start=1)\n",
    "        if \"glean\" in str(url)\n",
    "    ),\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "\n",
    "\n",
    "# print(\"sim_metrics paths:\")\n",
    "\n",
    "# for index, jobpaths in enumerate(file_mapping_model.root.values(), start=1):\n",
    "\n",
    "#     print(f\"{index}. {Path(jobpaths.sim_metrics).name}\")\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 14:10:10,658 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\url_to_file_mapping.json\n",
      "2025-03-18 14:10:10,660 - evaluation_optimization.create_mapping_file - INFO - Loaded and validated mapping file from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\url_to_file_mapping.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job URLs:\n",
      "Number of URLs: 30\n",
      "1. https://www.google.com/about/careers/applications/jobs/results/113657145978692294-ai-market-intelligence-principal/?src=Online/LinkedIn/linkedin_us&utm_source=linkedin&utm_medium=jobposting&utm_campaign=contract&utm_medium=jobboard&utm_source=linkedin\n",
      "2. https://www.capitalonecareers.com/job/-/-/234/66270465536?p_sid=ep3Sfxb&p_uid=sDBMWC5VxQ&source=rd_linkedin_job_posting_tm&ss=paid&utm_campaign=capone_all_jobs_24&utm_content=pj_board&utm_medium=jobad&utm_source=linkedin+slotted&dclid=CPGV3bef44gDFUEGTwgd4DoHPg\n",
      "3. https://boards.greenhouse.io/embed/job_app?token=7600823002&gh_src=ab9f35b82\n",
      "4. https://www.amazon.jobs/en/jobs/2696123/research-manager-strategy-and-insights-gca-marketing?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "5. https://www.amazon.jobs/en/jobs/2742527/sr-generative-ai-strategist-generative-ai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "6. https://www.amazon.jobs/en/jobs/2684745/product-manager-artificial-general-intelligence-data-services?cmpid=SPLICX0248M&ss=paid&utm_campaign=cxro&utm_content=job_posting&utm_medium=social_media&utm_source=linkedin.com\n",
      "7. https://jobs.careers.microsoft.com/us/en/job/1771714/Head-of-Partner-Intelligence-and-Strategy?jobsource=linkedin\n",
      "8. https://searchjobs.libertymutualgroup.com/careers/job/618499888480?microsite=libertymutual.com&domain=libertymutual.com&utm_source=Job+Board&utm_campaign=LinkedIn+Jobs&extcmp=bof-paid-text-lkin-aljb\n",
      "9. https://www.metacareers.com/jobs/522232286825036/?rx_campaign=Linkedin1&rx_ch=connector&rx_group=126320&rx_job=a1KDp00000E28eGMAR&rx_medium=post&rx_r=none&rx_source=Linkedin&rx_ts=20240927T121201Z&rx_vp=slots&utm_campaign=Job%2Bboard&utm_medium=jobs&utm_source=LIpaid&rx_viewer=e3efacca649311ef917d17a1705b89ba0dc4e1e7a57f4231bbce94a604c83931\n",
      "10. https://jobs.us.pwc.com/job/-/-/932/76064801072?utm_source=linkedin.com&utm_campaign=core_media&utm_medium=social_media&utm_content=job_posting&ss=paid&dclid=CjgKEAiAwaG9BhCY3ayl47PW8lcSJAA_gCfjt-rzWhQetHLIbJdJBVocWQm2BRNcBgOARxhGyR9bgvD_BwE\n",
      "11. https://job-boards.greenhouse.io/trace3/jobs/6163213?gh_src=b81c67b41us\n",
      "12. https://boards.greenhouse.io/dept/jobs/6564521\n",
      "13. https://careers.snowflake.com/us/en/job/SNCOUS5AF10A9C7A01464788ABD17AECBEE52EEXTERNALENUS1CC71A00229E4662B768527743E6164F/Director-Product-Marketing-Analytics?utm_source=Q2P9NP2NNP&utm_medium=phenom-feeds&gh_src=ed5543a62\n",
      "14. https://job-boards.greenhouse.io/airtable/jobs/7603873002?gh_src=aef790d02us\n",
      "15. https://www.accenture.com/us-en/careers/jobdetails?id=R00251798_en&src=LINKEDINJP\n",
      "16. https://boards.greenhouse.io/gleanwork/jobs/4425502005?source=LinkedIn\n",
      "17. https://jobs.smartrecruiters.com/Blend360/744000042638791-director-ai-strategy?trid=2d92f286-613b-4daf-9dfa-6340ffbecf73\n",
      "18. https://careers.veeva.com/job/365ff44c-8e0a-42b4-a117-27b409a77753/director-crossix-analytics-services-boston-ma/?lever-source=Linkedin\n",
      "19. https://flextronics.wd1.myworkdayjobs.com/en-US/Careers/job/Sr-Manager-AI-Strategy_WD191060?source=LinkedIn_Slots\n",
      "20. https://www.digitalocean.com/careers/position/apply?gh_jid=6437995&gh_src=312a08e31us\n",
      "21. https://job-boards.greenhouse.io/figma/jobs/5336109004?gh_jid=5336109004&gh_src=28109e334us&source=LinkedIn\n",
      "22. https://advisor360.breezy.hr/p/2e1636328c7d-senior-product-manager-ai-analytics-insights\n",
      "23. https://jobs.thermofisher.com/global/en/job/R-01298008/Market-Competitive-Intelligence-Manager?rx_ch=jobpost&rx_job=R-01298008-1&rx_medium=post&rx_paid=0&rx_r=none&rx_source=linkedin&rx_ts=20250206T184002Z&rx_vp=linkedindirectindex&utm_medium=post&utm_source=recruitics_linkedindirectindex&refId=34jd24&rx_viewer=e3efacca649311ef917d17a1705b89ba0dc4e1e7a57f4231bbce94a604c83931\n",
      "24. https://www.mongodb.com/careers/jobs/6466537\n",
      "25. https://searchjobs.libertymutualgroup.com/careers/job/618501232921?microsite=libertymutual.com&domain=libertymutual.com&utm_source=Job+Board&utm_campaign=LinkedIn+Jobs&extcmp=bof-paid-text-lkin-aljb\n",
      "26. https://apply.deloitte.com/careers/InviteToApply?jobId=199586&source=LinkedIn\n",
      "27. https://apply.deloitte.com/careers/InviteToApply?jobId=210031&source=LinkedIn\n",
      "28. https://www.amazon.jobs/en/jobs/2905092/senior-manger-partner-strategy-genai-innovation-center?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\n",
      "29. https://apply.deloitte.com/careers/InviteToApply?jobId=201718&source=LinkedIn\n",
      "30. https://careers.adobe.com/us/en/job/ADOBUSR151695EXTERNALENUS/Sr-Director-Applied-AI-ML-Discovery?utm_source=linkedin&utm_medium=phenom-feeds&source=LinkedIn\n",
      "\n",
      "\n",
      "<generator object <genexpr> at 0x000002A6D4F1E960>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Responsibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responsibilities file names: \n",
      "Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_resps_nested_iter1.json\n",
      "Adobe_Sr__Director__Applied_AI_ML__Discovery__resps_nested_iter1.json\n",
      "Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_resps_nested_iter1.json\n",
      "Airtable_Product_Manager__AI_resps_nested_iter1.json\n",
      "Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_resps_iter1.json\n",
      "Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_resps_iter1.json\n",
      "Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_resps_iter1.json\n",
      "Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_resps_nested_iter1.json\n",
      "Amplitude_Marketing_Strategy___Analytics_Manager_resps_iter1.json\n",
      "Blend_Director__AI_Strategy_resps_nested_iter1.json\n",
      "Capital_One_Director__AI_Platforms_resps_iter1.json\n",
      "Deloitte_AI_Data_Specialist_resps_nested_iter1.json\n",
      "Deloitte_Global_Business_Services__GBS__Strategy_Manager_resps_nested_iter1.json\n",
      "Deloitte_Market_Research_Sr_Manager_resps_nested_iter1.json\n",
      "DEPT__Director_of_Applied_AI_Strategy__Media_resps_nested_iter1.json\n",
      "DigitalOcean_Director__Product_Management__AI_ML__resps_nested_iter1.json\n",
      "Figma_Researcher__Strategic_Growth_resps_nested_iter1.json\n",
      "Flex_Sr__Manager_AI_Strategy_resps_nested_iter1.json\n",
      "Glean_Head_of_Competitive_Intelligence_resps_nested_iter1.json\n",
      "Google_AI_Market_Intelligence_Principal_resps_iter1.json\n",
      "Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_resps_nested_iter1.json\n",
      "Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_resps_iter1.json\n",
      "Meta_Product_Strategy_Lead_resps_iter1.json\n",
      "Microsoft_Head_of_Partner_Intelligence_and_Strategy_resps_iter1.json\n",
      "MongoDB_Director__Competitive_Intelligence_resps_nested_iter1.json\n",
      "PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_resps_nested_iter1.json\n",
      "Snowflake_Director__Product_Marketing_-_Analytics_resps_nested_iter1.json\n",
      "Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_resps_nested_iter1.json\n",
      "Trace3_Senior_Consultant__AI_Strategy__Remote__resps_nested_iter1.json\n",
      "Veeva_Systems_Director_-_Crossix_Analytics_Services_resps_nested_iter1.json\n"
     ]
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "from project_config import RESPS_FILES_ITERATE_1_OPENAI_DIR\n",
    "\n",
    "directory = RESPS_FILES_ITERATE_1_OPENAI_DIR\n",
    "\n",
    "file_names = get_file_names(directory_path=directory)\n",
    "\n",
    "print(f\"Responsibilities file names: \\n\" + \"\\n\".join(name for name in file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "\n",
      "File: Adobe_Sr__Director__Applied_AI_ML__Discovery__resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 7\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 7\n",
      "\n",
      "File: Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Airtable_Product_Manager__AI_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "\n",
      "1 validation error for NestedResponsibilities\n",
      "url\n",
      "  Field required [type=missing, input_value={'responsibilities': {'0....product decisions.'}}}}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "<built-in method json of pydantic_core._pydantic_core.ValidationError object at 0x000001EBBA3E5360>\n",
      "File: Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_resps_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "\n",
      "1 validation error for NestedResponsibilities\n",
      "url\n",
      "  Field required [type=missing, input_value={'responsibilities': {'0....product campaigns.'}}}}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "<built-in method json of pydantic_core._pydantic_core.ValidationError object at 0x000001EBBA3E53F0>\n",
      "File: Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_resps_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "\n",
      "1 validation error for NestedResponsibilities\n",
      "url\n",
      "  Field required [type=missing, input_value={'responsibilities': {'0.... product strategy.'}}}}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "<built-in method json of pydantic_core._pydantic_core.ValidationError object at 0x000001EBB957A290>\n",
      "File: Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_resps_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "\n",
      "File: Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "1 validation error for NestedResponsibilities\n",
      "url\n",
      "  Field required [type=missing, input_value={'responsibilities': {'0....us global offices.'}}}}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "<built-in method json of pydantic_core._pydantic_core.ValidationError object at 0x000001EBBA3E57E0>\n",
      "File: Amplitude_Marketing_Strategy___Analytics_Manager_resps_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Blend_Director__AI_Strategy_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "1 validation error for NestedResponsibilities\n",
      "url\n",
      "  Field required [type=missing, input_value={'responsibilities': {'0.... enhance security.'}}}}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "<built-in method json of pydantic_core._pydantic_core.ValidationError object at 0x000001EBBA3E51B0>\n",
      "File: Capital_One_Director__AI_Platforms_resps_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Deloitte_AI_Data_Specialist_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 14\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 14\n",
      "\n",
      "File: Deloitte_Global_Business_Services__GBS__Strategy_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Deloitte_Market_Research_Sr_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: DEPT__Director_of_Applied_AI_Strategy__Media_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: DigitalOcean_Director__Product_Management__AI_ML__resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Figma_Researcher__Strategic_Growth_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Flex_Sr__Manager_AI_Strategy_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Glean_Head_of_Competitive_Intelligence_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 11\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 11\n",
      "\n",
      "1 validation error for NestedResponsibilities\n",
      "url\n",
      "  Field required [type=missing, input_value={'responsibilities': {'0....executive reviews.'}}}}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "<built-in method json of pydantic_core._pydantic_core.ValidationError object at 0x000001EBBA3E5240>\n",
      "File: Google_AI_Market_Intelligence_Principal_resps_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 11\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 11\n",
      "\n",
      "File: Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "1 validation error for NestedResponsibilities\n",
      "url\n",
      "  Field required [type=missing, input_value={'responsibilities': {'0....inancial services.'}}}}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "<built-in method json of pydantic_core._pydantic_core.ValidationError object at 0x000001EBB957A290>\n",
      "File: Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_resps_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "1 validation error for NestedResponsibilities\n",
      "url\n",
      "  Field required [type=missing, input_value={'responsibilities': {'0....ategy and roadmap.'}}}}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "<built-in method json of pydantic_core._pydantic_core.ValidationError object at 0x000001EBBA3E5000>\n",
      "File: Meta_Product_Strategy_Lead_resps_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "1 validation error for NestedResponsibilities\n",
      "url\n",
      "  Field required [type=missing, input_value={'responsibilities': {'0.... product strategy.'}}}}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "<built-in method json of pydantic_core._pydantic_core.ValidationError object at 0x000001EBB957A290>\n",
      "File: Microsoft_Head_of_Partner_Intelligence_and_Strategy_resps_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: MongoDB_Director__Competitive_Intelligence_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 20\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 20\n",
      "\n",
      "File: Snowflake_Director__Product_Marketing_-_Analytics_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 10\n",
      "\n",
      "File: Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Trace3_Senior_Consultant__AI_Strategy__Remote__resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n",
      "File: Veeva_Systems_Director_-_Crossix_Analytics_Services_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models.resume_job_description_io_models import NestedResponsibilities\n",
    "from pydantic import ValidationError\n",
    "\n",
    "# Load and validate the JSON data\n",
    "# file_name = \"Blend_Director__AI_Strategy_resps_nested_iter1.json\"\n",
    "file_name = (\n",
    "    \"Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_resps_nested_iter1.json\"\n",
    ")\n",
    "\n",
    "for file in file_names:\n",
    "    # file_name = \"Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_resps_nested_iter1.json\"\n",
    "    file_path = RESPS_FILES_ITERATE_1_OPENAI_DIR / file\n",
    "\n",
    "    try:\n",
    "        data = load_and_decode_json(file_path)\n",
    "        validated_data = NestedResponsibilities(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(e)\n",
    "        print(e.json)\n",
    "\n",
    "    # Compute the number of matched requirements per responsibility\n",
    "    num_requirements_per_responsibility = {\n",
    "        resp_key: len(resp.optimized_by_requirements)\n",
    "        for resp_key, resp in validated_data.responsibilities.items()\n",
    "    }\n",
    "\n",
    "    # Display some insights\n",
    "    most_matched_resp = max(\n",
    "        num_requirements_per_responsibility,\n",
    "        key=lambda k: num_requirements_per_responsibility[k],\n",
    "    )\n",
    "\n",
    "    least_matched_resp = min(\n",
    "        num_requirements_per_responsibility,\n",
    "        key=lambda k: num_requirements_per_responsibility[k],\n",
    "    )\n",
    "\n",
    "    print(f\"File: {file}\")\n",
    "    print(f\"Total Responsibilities: {len(num_requirements_per_responsibility)}\")\n",
    "    print(\n",
    "        f\"Most Matched Responsibility: {most_matched_resp} -> Matches: {num_requirements_per_responsibility[most_matched_resp]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Least Matched Responsibility: {least_matched_resp} -> Matches: {num_requirements_per_responsibility[least_matched_resp]}\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 19:36:41,964 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\responsibilities\\Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_resps_nested_iter1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\responsibilities\\Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_resps_nested_iter1.json\n",
      "Total Responsibilities: 30\n",
      "Most Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "Least Matched Responsibility: 0.responsibilities.0 -> Matches: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.generic_utils import read_from_json_file\n",
    "\n",
    "file = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\responsibilities\\Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_resps_nested_iter1.json\"\n",
    "data = read_from_json_file(file)\n",
    "\n",
    "# Compute the number of matched requirements per responsibility\n",
    "num_requirements_per_responsibility = {\n",
    "    resp_key: len(resp.optimized_by_requirements)\n",
    "    for resp_key, resp in validated_data.responsibilities.items()\n",
    "}\n",
    "\n",
    "# Display some insights\n",
    "most_matched_resp = max(\n",
    "    num_requirements_per_responsibility,\n",
    "    key=lambda k: num_requirements_per_responsibility[k],\n",
    ")\n",
    "\n",
    "least_matched_resp = min(\n",
    "    num_requirements_per_responsibility,\n",
    "    key=lambda k: num_requirements_per_responsibility[k],\n",
    ")\n",
    "\n",
    "print(f\"File: {file}\")\n",
    "print(f\"Total Responsibilities: {len(num_requirements_per_responsibility)}\")\n",
    "print(\n",
    "    f\"Most Matched Responsibility: {most_matched_resp} -> Matches: {num_requirements_per_responsibility[most_matched_resp]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Least Matched Responsibility: {least_matched_resp} -> Matches: {num_requirements_per_responsibility[least_matched_resp]}\"\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 19:41:09,229 - utils.generic_utils - INFO - Loaded data from C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_1\\requirements\\Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_reqs_flat_iter1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.accenture.com/us-en/careers/jobdetails?id=R00251798_en&src=LINKEDINJP',\n",
       " 'requirements': {'0.pie_in_the_sky.0': 'Shape vision and create opportunities for data & AI led business reinvention.',\n",
       "  '0.pie_in_the_sky.1': 'Create strategy for AI-first products and develop commercialization opportunities.',\n",
       "  '1.down_to_earth.0': '5+ years of experience in business development, client relationship management, or marketing.',\n",
       "  '1.down_to_earth.1': 'Proficiency in CRM tools such as Salesforce for tracking and analyzing client interactions.',\n",
       "  '1.down_to_earth.2': 'Ability to build client relationships and credibility as a trusted advisor on how to infuse Data & AI into the business processes or functions.',\n",
       "  '2.cultural_fit.0': 'Collaborative leadership style with a growth-oriented mindset.',\n",
       "  '2.cultural_fit.1': 'Ability to mentor and develop high-performing teams.',\n",
       "  '2.cultural_fit.2': 'Infuse Responsible AI in vision and roadmap, develop plan for leveraging ecosystem partners, and define operating model to foster a culture of innovation and experimentation.',\n",
       "  '3.other.0': 'Experience working in professional services, Big Four firms, or consulting environments.',\n",
       "  '3.other.1': 'Ability to travel up to 80%; travel as needed based on client expectations.'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.generic_utils import read_from_json_file\n",
    "\n",
    "file = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_1\\requirements\\Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_reqs_flat_iter1.json\"\n",
    "data = read_from_json_file(file)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sim Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_sim_metrics_iter1.csv',\n",
       " 'Airtable_Product_Manager__AI_sim_metrics_iter1 - Copy.csv',\n",
       " 'Airtable_Product_Manager__AI_sim_metrics_iter1.csv',\n",
       " 'Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_sim_metrics_iter1.csv',\n",
       " 'Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_sim_metrics_iter1.csv',\n",
       " 'Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_sim_metrics_iter1.csv',\n",
       " 'Amplitude_Marketing_Strategy___Analytics_Manager_sim_metrics_iter1.csv',\n",
       " 'Glean_Head_of_Competitive_Intelligence_sim_metrics_iter1.csv',\n",
       " 'Google_AI_Market_Intelligence_Principal_sim_metrics_iter1.csv',\n",
       " 'Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_sim_metrics_iter1.csv',\n",
       " 'Meta_Product_Strategy_Lead_sim_metrics_iter1.csv',\n",
       " 'Microsoft_Head_of_Partner_Intelligence_and_Strategy_sim_metrics_iter1.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "\n",
    "sim_dir = SIMILARITY_METRICS_ITERATE_1_OPENAI_DIR\n",
    "\n",
    "get_file_names(sim_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "csv_file = sim_dir / r\"Glean_Head_of_Competitive_Intelligence_sim_metrics_iter1.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "set(df.requirement_key)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get File List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Adobe_Sr__Director__Applied_AI_ML__Discovery__sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Advisor360__Senior_Product_Manager_-_AI_Analytics___Insights_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Airtable_Product_Manager__AI_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Amazon_Product_Manager__Artificial_General_Intelligence_-_Data_Services_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Amazon_Research_Manager_-_Strategy_and_Insights_GCA_Marketing_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Amazon_Sr__Generative_AI_Strategist__Generative_AI_Innovation_Center_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Amazon_Web_Services__Inc__Senior_Manger__Partner_Strategy__GenAI_Innovation_Center_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Amplitude_Marketing_Strategy___Analytics_Manager_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Blend_Director__AI_Strategy_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Capital_One_Director__AI_Platforms_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Deloitte_AI_Data_Specialist_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Deloitte_Global_Business_Services__GBS__Strategy_Manager_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Deloitte_Market_Research_Sr_Manager_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\DEPT__Director_of_Applied_AI_Strategy__Media_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\DigitalOcean_Director__Product_Management__AI_ML__sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Figma_Researcher__Strategic_Growth_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Flex_Sr__Manager_AI_Strategy_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Glean_Head_of_Competitive_Intelligence_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Google_AI_Market_Intelligence_Principal_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Liberty_Mutual_Insurance_Senior_Manager_II__Corporate_Strategy___Research_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Liberty_Mutual_Insurance_Senior_Manager_I_-_Corporate_Strategy___Research_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Meta_Product_Strategy_Lead_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Microsoft_Head_of_Partner_Intelligence_and_Strategy_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\MongoDB_Director__Competitive_Intelligence_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Snowflake_Director__Product_Marketing_-_Analytics_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Trace3_Senior_Consultant__AI_Strategy__Remote__sim_metrics_iter1.csv',\n",
       " 'C:\\\\github\\\\job_bot\\\\input_output\\\\evaluation_optimization\\\\evaluation_optimization_by_anthropic\\\\iteration_1\\\\similarity_metrics\\\\Veeva_Systems_Director_-_Crossix_Analytics_Services_sim_metrics_iter1.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.get_file_names import get_file_names\n",
    "from project_config import (\n",
    "    ITERATE_1_ANTHROPIC_DIR,\n",
    "    SIMILARITY_METRICS_ITERATE_1_ANTHROPIC_DIR,\n",
    ")\n",
    "\n",
    "files_dir = SIMILARITY_METRICS_ITERATE_1_ANTHROPIC_DIR\n",
    "\n",
    "file_list = get_file_names(files_dir, True)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Tab Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "\n",
    "# Load similarity metrics CSV\n",
    "file_path = file_list[1]  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Pivot the data to match heatmap format\n",
    "pivot_df = df.pivot(\n",
    "    index=\"responsibility\", columns=\"requirement\", values=\"composite_score\"\n",
    ")\n",
    "\n",
    "# Create the heatmap\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "sns.heatmap(\n",
    "    pivot_df,\n",
    "    annot=False,\n",
    "    fmt=\".2f\",\n",
    "    cmap=cmap,\n",
    "    linewidths=1,\n",
    "    linecolor=\"black\",\n",
    "    cbar=True,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to wrap text inside heatmap cells\n",
    "def wrap_text(text, width=20):\n",
    "    return \"\\n\".join(textwrap.wrap(str(text), width))\n",
    "\n",
    "\n",
    "# Wrap y-axis labels\n",
    "wrapped_y_labels = [textwrap.fill(label, width=20) for label in pivot_df.index]\n",
    "ax.set_yticklabels(wrapped_y_labels, rotation=0)\n",
    "\n",
    "# Overlay text inside each cell (display composite score + wrapped requirement)\n",
    "for i, res in enumerate(pivot_df.index):\n",
    "    for j, req in enumerate(pivot_df.columns):\n",
    "        match = df[(df[\"responsibility\"] == res) & (df[\"requirement\"] == req)]\n",
    "        if not match.empty:\n",
    "            score = match.iloc[0][\"composite_score\"]\n",
    "            req_text = wrap_text(match.iloc[0][\"requirement\"], width=20)\n",
    "            display_text = f\"{score:.2f}\\n{req_text}\"\n",
    "            ax.text(\n",
    "                j + 0.5,\n",
    "                i + 0.5,\n",
    "                display_text,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=8,\n",
    "                color=\"black\",\n",
    "            )\n",
    "\n",
    "# Formatting adjustments\n",
    "ax.set_title(\"Responsibility vs Requirement Matching Grid (Text Inside Cells)\")\n",
    "ax.set_xlabel(\"Requirements\")\n",
    "ax.set_ylabel(\"Responsibilities\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Increase left margin\n",
    "plt.subplots_adjust(left=0.5)\n",
    "# box = ax.get_position()\n",
    "# ax.set_position([box.x0 + 0.2, box.y0, box.width, box.height])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "import numpy as np\n",
    "\n",
    "# Sample Responsibilities and Requirements\n",
    "responsibilities = [\n",
    "    \"Led strategic initiatives for IT transformation\",\n",
    "    \"Managed global vendor relationships\",\n",
    "    \"Optimized business intelligence reporting\",\n",
    "    \"Developed AI-driven analytics models\",\n",
    "    \"Implemented cloud security protocols\",\n",
    "]\n",
    "\n",
    "requirements = [\n",
    "    \"Experience in strategic IT leadership\",\n",
    "    \"Vendor management expertise\",\n",
    "    \"Business intelligence reporting experience\",\n",
    "    \"AI and machine learning proficiency\",\n",
    "    \"Cloud security best practices\",\n",
    "]\n",
    "\n",
    "# Generate random similarity scores between 0.5 and 1.0\n",
    "np.random.seed(42)\n",
    "data = []\n",
    "for res in responsibilities:\n",
    "    for req in requirements:\n",
    "        data.append(\n",
    "            {\n",
    "                \"responsibility\": res,\n",
    "                \"requirement\": req,\n",
    "                \"composite_score\": round(np.random.uniform(0.5, 1.0), 2),\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_dummy = pd.DataFrame(data)\n",
    "\n",
    "# Pivot table for heatmap\n",
    "pivot_df = df_dummy.pivot(\n",
    "    index=\"responsibility\", columns=\"requirement\", values=\"composite_score\"\n",
    ")\n",
    "\n",
    "# Create the heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "cmap = sns.color_palette(\"coolwarm\", as_cmap=True)  # Define color scheme\n",
    "\n",
    "# Generate heatmap\n",
    "sns.heatmap(\n",
    "    pivot_df,\n",
    "    annot=False,\n",
    "    fmt=\".2f\",\n",
    "    cmap=cmap,\n",
    "    linewidths=1,\n",
    "    linecolor=\"black\",\n",
    "    cbar=True,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to wrap text inside heatmap cells\n",
    "def wrap_text(text, width=20):\n",
    "    return \"\\n\".join(textwrap.wrap(str(text), width))\n",
    "\n",
    "\n",
    "# Overlay text inside each cell (score + requirement)\n",
    "for i, res in enumerate(pivot_df.index):\n",
    "    for j, req in enumerate(pivot_df.columns):\n",
    "        match = df_dummy[\n",
    "            (df_dummy[\"responsibility\"] == res) & (df_dummy[\"requirement\"] == req)\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            score = match.iloc[0][\"composite_score\"]\n",
    "            req_text = wrap_text(\n",
    "                match.iloc[0][\"requirement\"], width=20\n",
    "            )  # Wrap text for better display\n",
    "            display_text = f\"{score:.2f}\\n{req_text}\"  # Display similarity score + wrapped requirement text\n",
    "\n",
    "            ax.text(\n",
    "                j + 0.5,\n",
    "                i + 0.5,\n",
    "                display_text,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=8,\n",
    "                color=\"black\",\n",
    "            )\n",
    "\n",
    "# Formatting adjustments\n",
    "ax.set_title(\"Dummy Responsibility vs Requirement Heatmap (Text Inside Cells)\")\n",
    "ax.set_xlabel(\"Requirements\")\n",
    "ax.set_ylabel(\"Responsibilities\")\n",
    "plt.xticks(rotation=45, ha=\"right\")  # Rotate x-axis labels for better readability\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "\n",
    "# Load similarity metrics CSV\n",
    "file_path = file_list[1]  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a wrapped version of the requirement text (width=20)\n",
    "df[\"wrapped_requirement\"] = df[\"requirement\"].apply(\n",
    "    lambda x: \"\\n\".join(textwrap.wrap(str(x), width=20))\n",
    ")\n",
    "df[\"score_text\"] = df[\"composite_score\"].apply(lambda x: f\"{x:.2f}\")\n",
    "df[\"label\"] = df[\"score_text\"] + \"\\n\" + df[\"wrapped_requirement\"]\n",
    "\n",
    "# Build the heatmap chart\n",
    "heatmap = (\n",
    "    alt.Chart(df)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=alt.X(\"requirement:N\", title=\"Requirements\", axis=alt.Axis(labelAngle=45)),\n",
    "        y=alt.Y(\"responsibility:N\", title=\"Responsibilities\"),\n",
    "        color=alt.Color(\n",
    "            \"composite_score:Q\",\n",
    "            scale=alt.Scale(scheme=\"redblue\"),\n",
    "            title=\"Composite Score\",\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Build the text overlay chart\n",
    "# The key here is using the \"detail\" encoding so that each row is rendered individually.\n",
    "text_overlay = (\n",
    "    alt.Chart(df)\n",
    "    .mark_text(\n",
    "        fontSize=8,\n",
    "        color=\"black\",\n",
    "        align=\"left\",  # Set left alignment (change to 'center' if preferred)\n",
    "        baseline=\"middle\",\n",
    "    )\n",
    "    .encode(\n",
    "        x=alt.X(\"requirement:N\"),\n",
    "        y=alt.Y(\"responsibility:N\"),\n",
    "        text=alt.Text(\"label:N\"),\n",
    "        detail=\"label:N\",  # Force each label to be treated as a distinct detail\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine the heatmap and text overlay\n",
    "chart = (\n",
    "    (heatmap + text_overlay)\n",
    "    .properties(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        title=\"Responsibility vs Requirement Matching Grid (Text Inside Cells)\",\n",
    "    )\n",
    "    .configure_view(strokeWidth=0)\n",
    ")\n",
    "\n",
    "chart.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Cross Tab in Excel Instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "\n",
    "def create_pivot_table(sim_metrics_csv, output_csv):\n",
    "    \"\"\"\n",
    "    Reads the similarity metrics CSV and creates a pivot table:\n",
    "      - Index: responsibility_key\n",
    "      - Columns: requirement_key\n",
    "      - Values: responsibility\n",
    "    Then saves it as a new CSV file.\n",
    "    \"\"\"\n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(sim_metrics_csv)\n",
    "    # display(df.head(5))\n",
    "\n",
    "    # Pivot table with responsibility_key as index, requirement_key as columns, and responsibility as values\n",
    "    # Multi-index for columns: (requirement_key, requirement)\n",
    "    pivot_table = df.pivot(\n",
    "        index=\"responsibility_key\",\n",
    "        columns=[\"requirement_key\", \"requirement\"],  # Multi-index for columns\n",
    "        values=[\"responsibility\", \"composite_score\"],  # Multi-values in pivot\n",
    "    )\n",
    "\n",
    "    # Fill missing values with empty string\n",
    "    pivot_table = pivot_table.fillna(\"\")\n",
    "\n",
    "    # Save to CSV\n",
    "    pivot_table.to_csv(output_csv)\n",
    "\n",
    "    print(f\"Pivot table saved to {output_csv}\")\n",
    "\n",
    "    display(pivot_table.head(10))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define input and output file paths\n",
    "    input_csv = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\similarity_metrics\\Microsoft_Head_of_Partner_Intelligence_and_Strategy_sim_metrics_iter1.csv\"\n",
    "    output_csv = (\n",
    "        r\"C:\\github\\job_bot\\data\\matching_examples\\resp_vs_reqs_pivot_output_1.csv\"\n",
    "    )\n",
    "\n",
    "    # Call the function\n",
    "    create_pivot_table(input_csv, output_csv)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Color Fromatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.formatting.rule import ColorScaleRule\n",
    "\n",
    "\n",
    "def create_pivot_table(sim_metrics_csv, output_excel):\n",
    "    \"\"\"\n",
    "    Reads the CSV and creates a pivot table:\n",
    "      - Index: responsibility_key\n",
    "      - Columns: (requirement_key, requirement)\n",
    "      - Values: responsibility, composite_score\n",
    "    Then saves it as an Excel file and applies conditional formatting.\n",
    "    \"\"\"\n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(sim_metrics_csv)\n",
    "\n",
    "    # Format responsibility text based on composite_score\n",
    "    def format_responsibility(row):\n",
    "        if pd.isna(row[\"composite_score\"]):  # Handle NaN values\n",
    "            return row[\"responsibility\"]\n",
    "        elif row[\"composite_score\"] >= 0.75:\n",
    "            return f\"⭐ {row['responsibility']}\"  # Highlight important ones\n",
    "        elif row[\"composite_score\"] < 0.3:\n",
    "            return f\"❌ {row['responsibility']}\"  # Mark low ones\n",
    "        return row[\"responsibility\"]\n",
    "\n",
    "    df[\"formatted_responsibility\"] = df.apply(format_responsibility, axis=1)\n",
    "\n",
    "    # Create pivot table\n",
    "    pivot_table = df.pivot_table(\n",
    "        index=\"responsibility_key\",\n",
    "        columns=[\"requirement_key\", \"requirement\"],\n",
    "        values=[\"formatted_responsibility\", \"composite_score\"],\n",
    "        aggfunc=\"first\",\n",
    "    )\n",
    "\n",
    "    pivot_table = pivot_table.fillna(\"\")\n",
    "    pivot_table.to_excel(output_excel)\n",
    "\n",
    "    # Apply Conditional Formatting\n",
    "    apply_conditional_formatting(output_excel)\n",
    "    print(f\"Pivot table saved and formatted at: {output_excel}\")\n",
    "\n",
    "\n",
    "def apply_conditional_formatting(excel_file):\n",
    "    \"\"\"Finds composite_score columns in the pivot and applies a color scale formatting.\"\"\"\n",
    "    wb = load_workbook(excel_file)\n",
    "    ws = wb.active\n",
    "\n",
    "    # Define a Color Scale Rule (Red - Yellow - Green)\n",
    "    color_rule = ColorScaleRule(\n",
    "        start_type=\"num\",\n",
    "        start_value=0,\n",
    "        start_color=\"FF6347\",  # Red\n",
    "        mid_type=\"num\",\n",
    "        mid_value=0.5,\n",
    "        mid_color=\"FFFF00\",  # Yellow\n",
    "        end_type=\"num\",\n",
    "        end_value=1,\n",
    "        end_color=\"00FF00\",  # Green\n",
    "    )\n",
    "\n",
    "    # Detect composite_score columns explicitly\n",
    "    for col in range(2, ws.max_column + 1):  # Columns start at 2\n",
    "        header = ws.cell(row=1, column=col).value  # Get column header\n",
    "        if header and \"composite_score\" in str(header):  # Ensure it's a valid column\n",
    "            col_letter = ws.cell(row=1, column=col).column_letter\n",
    "            ws.conditional_formatting.add(\n",
    "                f\"{col_letter}2:{col_letter}{ws.max_row}\", color_rule\n",
    "            )\n",
    "\n",
    "    wb.save(excel_file)\n",
    "    print(\"✅ Conditional formatting applied successfully!\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_csv = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\similarity_metrics\\Microsoft_Head_of_Partner_Intelligence_and_Strategy_sim_metrics_iter1.csv\"\n",
    "    output_excel = (\n",
    "        r\"C:\\github\\job_bot\\data\\matching_examples\\resp_vs_reqs_pivot_output_1.xlsx\"\n",
    "    )\n",
    "\n",
    "    create_pivot_table(input_csv, output_excel)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Xlwings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlwings as xw\n",
    "\n",
    "\n",
    "def create_pivot_table(sim_metrics_csv, output_excel):\n",
    "    \"\"\"\n",
    "    Reads the CSV and creates a pivot table:\n",
    "      - Index: responsibility_key\n",
    "      - Columns: (requirement_key, requirement)\n",
    "      - Values: responsibility, composite_score\n",
    "    Then saves it as an Excel file and applies conditional formatting using xlwings.\n",
    "    \"\"\"\n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(sim_metrics_csv)\n",
    "\n",
    "    # Format responsibility text based on composite_score\n",
    "    def format_responsibility(row):\n",
    "        if pd.isna(row[\"composite_score\"]):  # Handle NaN values\n",
    "            return row[\"responsibility\"]\n",
    "        elif row[\"composite_score\"] >= 0.75:\n",
    "            return f\"{row['responsibility']}\"  # Highlight important ones\n",
    "        elif row[\"composite_score\"] < 0.3:\n",
    "            return f\"{row['responsibility']}\"  # Mark low ones\n",
    "        return row[\"responsibility\"]\n",
    "\n",
    "    df[\"formatted_responsibility\"] = df.apply(format_responsibility, axis=1)\n",
    "\n",
    "    # Create pivot table\n",
    "    pivot_table = df.pivot_table(\n",
    "        index=\"responsibility_key\",\n",
    "        columns=[\"requirement_key\", \"requirement\"],\n",
    "        values=[\"formatted_responsibility\", \"composite_score\"],\n",
    "        aggfunc=\"first\",\n",
    "    )\n",
    "\n",
    "    pivot_table = pivot_table.fillna(\"\")\n",
    "    pivot_table.to_excel(output_excel)\n",
    "\n",
    "    # Apply Conditional Formatting with xlwings\n",
    "    apply_xlwings_formatting(output_excel)\n",
    "    print(f\"Pivot table saved and formatted at: {output_excel}\")\n",
    "\n",
    "\n",
    "def apply_xlwings_formatting(excel_file):\n",
    "    \"\"\"Applies conditional formatting to value cells (not headers) based on their composite_score.\"\"\"\n",
    "    app = xw.App(visible=True)  # Keep Excel open for debugging\n",
    "    wb = xw.Book(excel_file)\n",
    "    ws = wb.sheets[0]\n",
    "\n",
    "    # Detect last row and last column\n",
    "    last_row = ws.range(\"A1\").expand(\"down\").last_cell.row\n",
    "    last_col = ws.range(\"A1\").expand(\"right\").last_cell.column\n",
    "\n",
    "    # Iterate through all data cells (excluding headers)\n",
    "    for row in range(2, last_row + 1):  # Start from row 2 to avoid header\n",
    "        for col in range(2, last_col + 1):  # Start from col 2 to avoid row labels\n",
    "            cell = ws.cells(row, col)\n",
    "            try:\n",
    "                value = float(cell.value)  # Convert value to float\n",
    "                if value >= 0.75:\n",
    "                    cell.api.Interior.Color = xw.utils.rgb_to_int(\n",
    "                        (0, 255, 0)\n",
    "                    )  # Green for high scores\n",
    "                elif value < 0.3:\n",
    "                    cell.api.Interior.Color = xw.utils.rgb_to_int(\n",
    "                        (255, 0, 0)\n",
    "                    )  # Red for low scores\n",
    "                else:\n",
    "                    cell.api.Interior.Color = xw.utils.rgb_to_int(\n",
    "                        (255, 255, 0)\n",
    "                    )  # Yellow for mid-range scores\n",
    "            except (ValueError, TypeError):\n",
    "                pass  # Ignore non-numeric values\n",
    "\n",
    "    wb.save()\n",
    "    wb.close()\n",
    "    app.quit()\n",
    "    print(\"✅ Conditional formatting applied to value cells!\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_csv = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_openai\\iteration_1\\similarity_metrics\\Microsoft_Head_of_Partner_Intelligence_and_Strategy_sim_metrics_iter1.csv\"\n",
    "    output_excel = (\n",
    "        r\"C:\\github\\job_bot\\data\\matching_examples\\resp_vs_reqs_pivot_output_1.xlsx\"\n",
    "    )\n",
    "\n",
    "    create_pivot_table(input_csv, output_excel)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_1\\responsibilities\\older_files\\PwC_Strategy__Manager_-_Digital_Value_Transformation_Contact_Center_resps_nested_iter1.json\"\n",
    "\n",
    "with open(input_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "    for _ in range(30):  # Print first 30 lines\n",
    "        print(f.readline().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "import xlsxwriter\n",
    "\n",
    "\n",
    "def create_two_row_header_excel(sim_metrics_csv, output_file):\n",
    "    \"\"\"\n",
    "    Reads the similarity metrics CSV and creates an Excel file with:\n",
    "      - Row 1: \"Resp Key / Req Key\" + requirement keys\n",
    "      - Row 2: \"Requirements\" + requirement texts\n",
    "      - Rows 3+: One row per responsibility key, showing matched responsibility texts\n",
    "    \"\"\"\n",
    "    # 1) Load the similarity metrics CSV\n",
    "    df = pd.read_csv(sim_metrics_csv)\n",
    "\n",
    "    # 2) Extract unique requirements and map to their texts\n",
    "    req_map = df.groupby(\"requirement_key\")[\"requirement\"].first().to_dict()\n",
    "    req_keys = sorted(req_map.keys())  # Ordered list of requirement keys\n",
    "    req_texts = [req_map[k] for k in req_keys]  # Corresponding requirement texts\n",
    "\n",
    "    # 3) Extract unique responsibilities\n",
    "    resp_keys = sorted(df[\"responsibility_key\"].unique())\n",
    "\n",
    "    # 4) Create a dataframe to ensure all `requirement_keys` appear\n",
    "    full_pivot = pd.DataFrame(index=resp_keys, columns=req_keys).fillna(\"\")\n",
    "\n",
    "    # 5) Pivot the table to get optimized_text per (responsibility, requirement) pair\n",
    "    pivot = df.pivot(\n",
    "        index=\"responsibility_key\", columns=\"requirement_key\", values=\"responsibility\"\n",
    "    )\n",
    "\n",
    "    # 6) Merge the pivoted data into `full_pivot` to retain all columns\n",
    "    full_pivot.update(pivot)\n",
    "\n",
    "    # 7) Reset index so responsibility_key becomes a column\n",
    "    full_pivot = full_pivot.reset_index()\n",
    "\n",
    "    # 8) Prepare the first two header rows (Multi-layer Headers)\n",
    "    header1 = [\"Resp Key / Req Key\"] + req_keys  # First row (Keys)\n",
    "    header2 = [\"Requirements\"] + req_texts  # Second row (Descriptions)\n",
    "\n",
    "    # 9) Write to Excel using xlsxwriter (Multi-layer Headers)\n",
    "    workbook = xlsxwriter.Workbook(output_file)\n",
    "    worksheet = workbook.add_worksheet(\"CrossTab\")\n",
    "\n",
    "    # Apply formatting\n",
    "    bold_format = workbook.add_format(\n",
    "        {\"bold\": True, \"bg_color\": \"#002b36\", \"font_color\": \"white\"}\n",
    "    )\n",
    "    wrap_format = workbook.add_format({\"text_wrap\": True, \"align\": \"top\"})\n",
    "\n",
    "    # Merge header rows for multi-layer effect\n",
    "    worksheet.write_row(0, 0, header1, bold_format)  # Row 1: Requirement Keys\n",
    "    worksheet.write_row(1, 0, header2, wrap_format)  # Row 2: Requirement Texts\n",
    "\n",
    "    # Write responsibilities data (row 3+)\n",
    "    for row_idx, row in enumerate(full_pivot.itertuples(index=False), start=2):\n",
    "        worksheet.write_row(row_idx, 0, row, wrap_format)\n",
    "\n",
    "    # Adjust column widths for readability\n",
    "    worksheet.set_column(0, 0, 25)  # Responsibility Key column\n",
    "    worksheet.set_column(1, len(req_keys), 50)  # Requirement columns\n",
    "\n",
    "    workbook.close()\n",
    "    print(f\"Excel file created: {output_file}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Create a 2-row-header Excel from similarity metrics CSV.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sim_metrics_csv\",\n",
    "        required=True,\n",
    "        help=\"Path to the similarity metrics CSV file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output\",\n",
    "        required=True,\n",
    "        help=\"Path to the output Excel file (e.g., output.xlsx)\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    output_dir = os.path.dirname(args.output)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    create_two_row_header_excel(args.sim_metrics_csv, args.output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example file paths (adjust these as needed)\n",
    "    input_csv = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_1\\similarity_metrics\\Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_sim_metrics_iter1.csv\"\n",
    "    output_excel = (\n",
    "        r\"C:\\github\\job_bot\\data\\matching_examples\\resp_vs_reqs_crosstab_output_1.xlsx\"\n",
    "    )\n",
    "\n",
    "    # Directly call the function with desired column names:\n",
    "    create_two_row_header_excel(\n",
    "        sim_metrics_csv=input_csv,\n",
    "        output_file=output_excel,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_cross_tab(sim_metric_csv_file: Path, output_excel_file: Path):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(sim_metric_csv_file)\n",
    "\n",
    "    # Create a pivot table (cross-tab) based on responsibility_key and requirement_key\n",
    "    cross_tab = pd.pivot_table(\n",
    "        df,\n",
    "        values=\"responsibility\",\n",
    "        index=\"responsibility_key\",\n",
    "        columns=\"requirement_key\",\n",
    "        aggfunc=lambda x: \" \".join(x),\n",
    "    )\n",
    "\n",
    "    # Extract unique requirements and their corresponding keys\n",
    "    requirements = (\n",
    "        df[[\"requirement_key\", \"requirement\"]]\n",
    "        .drop_duplicates()\n",
    "        .set_index(\"requirement_key\")[\"requirement\"]\n",
    "    )\n",
    "\n",
    "    # Create a DataFrame for the requirements row with the same columns as cross_tab\n",
    "    requirements_row = pd.DataFrame([requirements], columns=cross_tab.columns)\n",
    "\n",
    "    # Combine the requirements row with the cross-tab table\n",
    "    cross_tab_with_requirements = pd.concat([requirements_row, cross_tab], axis=0)\n",
    "\n",
    "    # Reset the index to make the table cleaner\n",
    "    cross_tab_with_requirements.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Save the cross-tab table with requirements to an Excel file\n",
    "    cross_tab_with_requirements.to_excel(output_excel_file, index=False)\n",
    "\n",
    "    print(f\"Cross-tab table with requirements saved to {output_excel_file}\")\n",
    "\n",
    "\n",
    "# Input and output file paths\n",
    "input_csv = r\"C:\\github\\job_bot\\input_output\\evaluation_optimization\\evaluation_optimization_by_anthropic\\iteration_1\\similarity_metrics\\Thermo_Fisher_Scientific_Market___Competitive_Intelligence_Manager_sim_metrics_iter1.csv\"\n",
    "output_excel = (\n",
    "    r\"C:\\github\\job_bot\\data\\matching_examples\\resp_vs_reqs_crosstab_output_1.xlsx\"\n",
    ")\n",
    "\n",
    "# Create the cross-tab table\n",
    "create_cross_tab(Path(input_csv), Path(output_excel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsibilities=\"{'0.responsibilities.0': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Led strategic initiatives to optimize the service partner network for a prominent international IT company in the Asia Pacific market, resulting in enhanced local execution outcomes. Possess extensive experience in analytical roles.'), '1.down_to_earth.1': OptimizedText(optimized_text=\"Led the optimization of a major global IT vendor's service partner ecosystem in the Asia Pacific region, resulting in improved local implementation outcomes. Leveraged extensive client-facing experience to drive these strategic enhancements.\"), '1.down_to_earth.2': OptimizedText(optimized_text='Led strategic consulting and analytics initiatives for a leading global IT vendor, driving enhancements to their partner ecosystem in the Asia Pacific region and delivering improved local implementation outcomes.'), '1.down_to_earth.3': OptimizedText(optimized_text=\"Led the optimization of a major global IT vendor's service partner ecosystem in the Asia Pacific region, driving improved local implementation results.\"), '2.other.0': OptimizedText(optimized_text='Led strategic initiatives that optimized the service partner network of a leading global IT vendor in the Asia Pacific region, resulting in enhanced local implementation and improved client outcomes.')}), '0.responsibilities.1': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Led the strategic growth of a leading international services provider by identifying and scaling new engineering service opportunities in key emerging markets.'), '1.down_to_earth.1': OptimizedText(optimized_text=\"Led the evaluation and scaling of new engineering service opportunities in vital emerging markets to support a leading international services provider's growth strategy.\"), '1.down_to_earth.2': OptimizedText(optimized_text='Led strategic analysis to identify and capitalize on new engineering service opportunities in key emerging markets, driving growth for a leading international services provider.'), '1.down_to_earth.3': OptimizedText(optimized_text='Led the evaluation and scaling of new engineering service opportunities in vital emerging markets to support the growth strategy of a U.S.-based international services provider.'), '2.other.0': OptimizedText(optimized_text='Led the expansion strategy for a leading international services provider by identifying and scaling new engineering service opportunities in key emerging markets.')}), '0.responsibilities.2': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Authored impactful industry reports analyzing engineering services merger and acquisition trends, providing strategic insights into deal sizes, capability gaps, and emerging opportunities to inform decisions on IT and operational technology convergence.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led the co-authorship of an industry-recognized report on M&A trends in the engineering services sector, providing strategic insights into deal sizes, capability gaps, and emerging opportunities to guide decision-making on IT and operational technology convergence.'), '1.down_to_earth.2': OptimizedText(optimized_text='Authored insightful industry reports analyzing mergers and acquisitions in the engineering services sector. Provided comprehensive insights into deal sizes, capability gaps, and emerging opportunities, informing strategic decisions on IT and operational technology convergence.'), '1.down_to_earth.3': OptimizedText(optimized_text='Led the development of an industry-recognized report on mergers and acquisitions in the engineering services sector, delivering in-depth analysis of deal dynamics, capability gaps, and emerging opportunities at the intersection of IT and operational technology. Leveraged these insights to drive strategic planning and execution.'), '2.other.0': OptimizedText(optimized_text='Authored a comprehensive industry report on mergers and acquisitions in the engineering services sector, providing in-depth analysis of deal sizes, capability gaps, and emerging opportunities. The report informed strategic decisions regarding the convergence of information technology and operational technology.')}), '0.responsibilities.3': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Led efforts to enhance data quality and consistency through thorough financial analysis, standardized methodologies, and collaborative vendor engagements.'), '1.down_to_earth.1': OptimizedText(optimized_text='Drove the enhancement of data quality and consistency by integrating thorough financial analysis, standardizing methodologies, and conducting in-depth vendor engagements.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led consultative analytics engagements, leveraging financial analysis, standardized methodologies, and vendor collaborations to enhance data quality and consistency.'), '1.down_to_earth.3': OptimizedText(optimized_text='Transformed data quality and consistency by integrating financial analysis, standardizing methodologies, and engaging vendors.'), '2.other.0': OptimizedText(optimized_text='Drove impactful improvements in data quality and consistency by integrating thorough financial analysis, standardizing methodologies, and conducting in-depth vendor engagements.')}), '0.responsibilities.4': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Led the optimization of resource allocation through centralization of tasks, transitioning a significant portion of work to an offshore team in India, which resulted in increased efficiency and cost savings.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led offshore teams, optimized resource utilization, and enhanced operational efficiency. Extensive client-facing experience.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led the centralization of over 40% of tasks to an offshore team in India, optimizing resource allocation and driving significant improvements in team productivity and efficiency.'), '1.down_to_earth.3': OptimizedText(optimized_text='Centralized over 40% of tasks to an offshore team, optimizing resource allocation for enhanced efficiency.'), '2.other.0': OptimizedText(optimized_text='Centralized over 40% of tasks to an offshore team, optimizing resource allocation and supporting product development through client services feedback.')}), '0.responsibilities.5': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Automated and streamlined internal processes using Python, driving over 40% improvements in report preparation and data analysis.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led the development of custom Python tools that automated and optimized internal workflows, resulting in a 40% decrease in report generation and data analysis time. Leveraged extensive experience collaborating with clients to deliver tailored solutions.'), '1.down_to_earth.2': OptimizedText(optimized_text='Developed custom Python tools that streamlined and accelerated internal processes, delivering over 40% reduction in report preparation and data analysis time. Led consultative analytics engagements with clients.'), '1.down_to_earth.3': OptimizedText(optimized_text='Led the development of custom Python tools that streamlined and accelerated internal processes, driving significant improvements in efficiency across report preparation and data analysis.'), '2.other.0': OptimizedText(optimized_text='Leveraged advanced Python programming skills to create custom tools that streamlined internal operations, driving over 40% improvements in report preparation and data analysis efficiency.')}), '0.responsibilities.6': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Analytical leader with a proven track record of pioneering groundbreaking industry research and publications. Collaborated extensively with engineering services teams to develop market forecasts, analyze the impact of COVID-19, and identify emerging trends in mergers and acquisitions within the engineering services sector.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led the engineering services research team in pioneering the engineering services tracker, authored impactful publications on market forecasts, the impact of COVID-19 on services, and trends in mergers and acquisitions within the engineering services industry. Demonstrated substantial client-facing experience.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led the development of the engineering services tracker and authored influential publications on market forecasts, the impact of COVID-19 on services, and trends in M&A within the engineering services industry.'), '1.down_to_earth.3': OptimizedText(optimized_text='Pioneered industry-leading engineering services tracker and authored impactful publications on market forecasts, COVID-19 impact, and engineering services M&A trends. Demonstrated ability to effectively manage complex projects and deliver valuable insights to stakeholders.'), '2.other.0': OptimizedText(optimized_text='Led engineering services research team to pioneer engineering services tracker, authored influential publications on market forecasts, the impact of COVID-19 on services, and industry trends. Leveraged these insights to drive product development through client services feedback.')}), '0.responsibilities.7': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Seasoned data analyst who led global teams (US, Canada, Latin America, Europe, MEA, APAC) to maintain data integrity, achieve objectives, and share expertise. Adept at identifying and implementing innovative analytical tools and techniques.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led collaborative efforts with global analyst teams to ensure data quality, meet deadlines, share knowledge, and implement best practices and new tools.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led consultative analytics engagements with global analyst teams. Ensured data quality, met deadlines, and shared knowledge, best practices, and methodology to procure new tools.'), '1.down_to_earth.3': OptimizedText(optimized_text='Collaborated with global analyst teams to ensure data quality, meet deadlines, share knowledge, implement best practices, and procure new tools.'), '2.other.0': OptimizedText(optimized_text='Led international analyst teams to maintain data integrity, achieve project milestones, exchange expertise and best practices, and acquire innovative tools in support of product development initiatives.')}), '1.responsibilities.0': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Seasoned leader with a proven record in full P&L oversight, including budgeting, HR, vendor relations, partnerships, research, and business development. Drove significant growth, expanding program bookings by over 50%. Extensive experience in analytical roles, with a strong foundation in data-driven decision-making and strategic planning.'), '1.down_to_earth.1': OptimizedText(optimized_text='Skilled leader with a proven track record in full P&L management, overseeing budgeting, HR, vendor relations, partnerships, research, and business development. Drove significant growth, expanding program bookings by over 50%. Excelled in client-facing roles, delivering exceptional service and driving impactful business results.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led full P&L management, including budgeting, HR, vendor relationships, partnerships, research, and business development. Drove significant expansion, growing program bookings by over 50%.'), '1.down_to_earth.3': OptimizedText(optimized_text='Adept leader with a proven record of full P&L management, overseeing diverse responsibilities including budgeting, human resources, vendor relationships, strategic partnerships, research, and business development. Drove significant growth, expanding program bookings by over 50%, showcasing exceptional project management skills.'), '2.other.0': OptimizedText(optimized_text='Led full profit and loss responsibilities, excelling at budgeting, human resources, vendor relationships, partnerships, research, and business development. Drove significant growth, increasing program bookings by over 50%.')}), '1.responsibilities.1': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Directed and expanded diverse global research teams, leading a global team of over 15 professionals across the US, India, and Mexico.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led a global research team, leveraging diverse perspectives to drive innovation across multiple locations.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led and grew a diverse global research team spanning multiple locations.'), '1.down_to_earth.3': OptimizedText(optimized_text='Led and managed diverse, global research teams to drive successful project outcomes.'), '2.other.0': OptimizedText(optimized_text='Led and expanded a diverse, global research team across strategic locations, enabling informed product development through client feedback.')}), '1.responsibilities.2': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Managed cross-functional teams to deliver innovative software solutions.'), '1.down_to_earth.1': OptimizedText(optimized_text='Managed cross-functional teams to deliver innovative software solutions for clients.'), '1.down_to_earth.2': OptimizedText(optimized_text='Spearheaded cross-functional teams to ideate, build, and deploy innovative software solutions that addressed client needs. Led an external software development team to build and implement new tools.'), '1.down_to_earth.3': OptimizedText(optimized_text='Spearheaded the development and implementation of innovative software tools and solutions by leading an external software development team.'), '2.other.0': OptimizedText(optimized_text='Collaborated with an external software development team to build and implement new tools that enhanced product development efforts.')}), '1.responsibilities.3': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Experienced leader who championed cutting-edge technology initiatives, including machine learning, natural language processing, chatbots, ontologies, web scraping, APIs, and user experience design. Demonstrated strong analytical skills with a data-driven approach honed over 8+ years.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led impactful and innovative technology projects leveraging cutting-edge tools like machine learning, natural language processing, chatbots, ontologies, web scraping, APIs, and user experience design. Collaborated extensively with stakeholders to deliver tailored solutions that exceeded expectations.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led innovative technology initiatives that leveraged cutting-edge tools and techniques, including machine learning, natural language processing, chatbots, ontologies, web scraping, APIs, and user experience design.'), '1.down_to_earth.3': OptimizedText(optimized_text='Led the successful implementation of cutting-edge technology initiatives, including machine learning, natural language processing, chatbots, ontology development, web scraping, API integration, and user experience design. Extensive experience in managing complex technology projects and delivering innovative solutions that drive business growth.'), '2.other.0': OptimizedText(optimized_text='Spearheaded innovative product development and enhanced user experience by leveraging cutting-edge technologies, including machine learning, natural language processing, chatbots, ontologies, web scraping, and APIs.')}), '1.responsibilities.4': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Developed and led a team to create Python-based automated tools that streamlined report preparation, driving 40% time savings.'), '1.down_to_earth.1': OptimizedText(optimized_text='Drove development of automated Python tools, reducing report preparation time by 40%.'), '1.down_to_earth.2': OptimizedText(optimized_text='Developed and implemented automated Python tools, driving a 40% reduction in report preparation time.'), '1.down_to_earth.3': OptimizedText(optimized_text='Adept project manager who led teams in developing custom Python-based tools, enhancing reporting efficiency by 40%.'), '2.other.0': OptimizedText(optimized_text='Developed Python-based automated solutions that streamlined report generation and enhanced overall operational efficiency.')}), '1.responsibilities.5': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Pioneered cutting-edge technologies, leading the implementation of machine learning, chatbots, APIs, and ontology development. Excels in analytical roles, delivering impactful solutions that drive business success.'), '1.down_to_earth.1': OptimizedText(optimized_text='Pioneered cutting-edge technology projects, including deploying machine learning, chatbots, APIs, and ontology development. Delivered client-focused solutions with a proven track record.'), '1.down_to_earth.2': OptimizedText(optimized_text='Pioneering technology executive with a track record of leading transformative initiatives, including the implementation of cutting-edge solutions such as machine learning, chatbots, APIs, and ontology development. Excels at driving strategic analytics engagements and delivering impactful consultative services to clients.'), '1.down_to_earth.3': OptimizedText(optimized_text='Innovative technology leader who pioneered cutting-edge solutions including machine learning, chatbots, APIs, and ontology development. Skilled at driving high-impact projects and delivering measurable results.'), '2.other.0': OptimizedText(optimized_text='Led the implementation of machine learning, launch of a chatbot, development of APIs, and construction of an ontology to drive innovation with emerging technologies. Collaborated closely with clients to provide valuable feedback that informed and supported ongoing product development efforts.')}), '1.responsibilities.6': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Leveraged analytical expertise to advise services firms on deal pursuit and sales orchestration strategies, driving business development and sales execution.'), '1.down_to_earth.1': OptimizedText(optimized_text='Guided professional services firms in developing their deal pursuit and sales strategy.'), '1.down_to_earth.2': OptimizedText(optimized_text='Advised services firms on deal pursuit and sales orchestration strategies, providing strategic guidance and expertise.'), '1.down_to_earth.3': OptimizedText(optimized_text='Proven leader who advised services firms on developing and executing effective deal pursuit and sales strategies.'), '2.other.0': OptimizedText(optimized_text='Drove deal pursuit and sales orchestration strategies for professional services firms, leveraging client insights to inform product development.')}), '1.responsibilities.7': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Advised software vendors on partnership strategy, leveraging extensive analytical expertise to provide strategic advisory services.'), '1.down_to_earth.1': OptimizedText(optimized_text='Advised software vendors on strategic partnerships and delivered client-facing services.'), '1.down_to_earth.2': OptimizedText(optimized_text='Guided software vendors on partnership opportunities and drove consultative analytics engagements with clients.'), '1.down_to_earth.3': OptimizedText(optimized_text='Guided software vendors on partnership strategy, leveraging extensive experience to deliver strategic guidance and drive successful initiatives.'), '2.other.0': OptimizedText(optimized_text='Guided software vendors on strategic services partnerships, driving successful client engagements.')}), '1.responsibilities.8': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Prolific content creator who authored reports, blogs, presentations, and custom research. Leveraged industry insights to drive strategic decision-making, analyzing go-to-market strategies, deal signing, renewal analysis, buyer studies, and technology trends (cloud, AI, ML, digital, etc.). Demonstrated extensive experience in an analytical role.'), '1.down_to_earth.1': OptimizedText(optimized_text='Prolific author of reports, blogs, presentations, and custom research. Adept at analyzing go-to-market strategies, deal signing, renewal trends, buyer behavior, and the adoption of emerging technologies such as cloud, AI, ML, and digital solutions. Proven track record of providing valuable industry insights and trend analysis to clients.'), '1.down_to_earth.2': OptimizedText(optimized_text='Seasoned professional who authors reports, blogs, presentations, and custom research. Adept at analyzing go-to-market strategies, deal signing, renewal trends, buyer behavior, and technology adoptions (cloud, AI, ML, digital, etc.), as well as identifying industry trends. Skilled in delivering consultative analytics engagements to clients.'), '1.down_to_earth.3': OptimizedText(optimized_text='Authored impactful reports, blogs, presentations, and custom research on go-to-market strategy, deal analysis, buyer studies, and industry trends. Leveraged emerging technologies like cloud, AI, and ML to deliver actionable insights.'), '2.other.0': OptimizedText(optimized_text='Accomplished professional who has authored impactful reports, blogs, presentations, and custom research projects. Expertise spans developing go-to-market strategies, conducting deal and renewal analyses, executing buyer studies, and analyzing technology adoption trends (e.g., cloud, AI, ML, digital). Regularly provided valuable insights and feedback to drive product development efforts.')}), '2.responsibilities.0': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Led quarterly webinars analyzing industry trends in outsourcing and managed services.'), '1.down_to_earth.1': OptimizedText(optimized_text='Conducted quarterly webinars on outsourcing and managed services trends.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led quarterly webinar series to present industry insights and best practices to clients.'), '1.down_to_earth.3': OptimizedText(optimized_text='Seasoned professional who has delivered quarterly webinars showcasing industry insights and best practices on outsourcing and managed services signing trends.'), '2.other.0': OptimizedText(optimized_text='Conducted quarterly webinars to share industry insights and client feedback, driving product development initiatives.')}), '2.responsibilities.1': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Authored insightful pursuit strategy reports and industry trend research.'), '1.down_to_earth.1': OptimizedText(optimized_text='Authored compelling pursuit strategy reports and conducted in-depth industry trend research, leveraging a strong background in client-facing roles.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led consultative analytics engagements and produced industry-leading research reports.'), '1.down_to_earth.3': OptimizedText(optimized_text='Authored strategic planning and industry analysis reports, demonstrating a proven track record in project management.'), '2.other.0': OptimizedText(optimized_text='Drove product development by leveraging client feedback and industry research.')}), '3.responsibilities.0': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Designed and architected complex database systems, integrating diverse data sources and enhancing data quality through deduplication initiatives. Demonstrated a proven track record in analytical roles over multiple years.'), '1.down_to_earth.1': OptimizedText(optimized_text='Designed and architected a complex company database, integrating external and internal data sources to significantly reduce data duplication. Led client-facing initiatives throughout my career, demonstrating extensive experience in this area.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led the technical design and architecture of a large-scale enterprise database, integrating multiple data sources to enhance data integrity and streamline operations. Demonstrated extensive expertise in complex data architecture and integration, collaborating with stakeholders to deliver impactful solutions that reduced data duplication by 50%.'), '1.down_to_earth.3': OptimizedText(optimized_text='Designed and architected sophisticated database solutions, integrating diverse data sources to enhance integrity and optimize management processes. Reduced data duplication by 50% in a complex company database with 100K+ unique records, seamlessly integrating DnB API and internal databases.'), '2.other.0': OptimizedText(optimized_text='Led the design and implementation of a comprehensive database system, consolidating diverse data sources to enhance data quality and streamline operations.')}), '3.responsibilities.1': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Drove implementation of process automation solutions that boosted productivity across multiple industries.'), '1.down_to_earth.1': OptimizedText(optimized_text='Results-driven professional with a proven track record of leading successful client-facing projects, including managing the implementation of two Appian solutions that enhanced team productivity by 20 to 30%.'), '1.down_to_earth.2': OptimizedText(optimized_text='Driven leader who managed multiple Appian implementations that delivered substantial productivity gains for client teams.'), '1.down_to_earth.3': OptimizedText(optimized_text='Accomplished project manager who led two successful Appian implementations that drove 20-30% improvements in team productivity.'), '2.other.0': OptimizedText(optimized_text='Led two Appian implementations that drove 20-30% improvements in team productivity.')}), '3.responsibilities.2': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Managed daily content operations, including leading a team of offshore and nearshore content team, as well as other sales and research related activities. Seasoned professional with a proven track record in managing content operations, leading cross-functional teams, and supporting sales and research initiatives.'), '1.down_to_earth.1': OptimizedText(optimized_text='Directed daily content operations, leading a team of offshore and nearshore content specialists, and supporting sales and research initiatives. Demonstrated extensive client-facing expertise.'), '1.down_to_earth.2': OptimizedText(optimized_text='Managed daily content operations, leading a team of offshore and nearshore content professionals, and overseeing a range of sales and research-related initiatives.'), '1.down_to_earth.3': OptimizedText(optimized_text='Managed daily content operations, including leading a team of offshore and nearshore content professionals as well as sales and research-related initiatives. Skilled at project management and delivering high-quality results.'), '2.other.0': OptimizedText(optimized_text='Led a talented content team to drive daily operations, collaborating with sales and research to support strategic initiatives.')}), '3.responsibilities.3': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Analyzed and modeled financials for 20-30 IT vendors and over 1,500 services contracts, delivering critical insights to support vendor and contract management.'), '1.down_to_earth.1': OptimizedText(optimized_text=\"Analyzed and modeled financials for 20 to 30 IT vendors' diverse portfolios. Reviewed and negotiated over 1,500 service contracts with extensive client-facing experience.\"), '1.down_to_earth.2': OptimizedText(optimized_text='Analyzed and modeled financials for 20 to 30 IT vendors and over 1,500 service contracts to support consultative engagements.'), '1.down_to_earth.3': OptimizedText(optimized_text='Analyzed and modeled financial data for 20 to 30 IT vendors and over 1,500 services contracts, leveraging insights to drive successful contract management.'), '2.other.0': OptimizedText(optimized_text='Analyzed and modeled financial data for 20 to 30 IT vendors and over 1,500 service contracts to support product development efforts by gathering and incorporating client services feedback.')}), '3.responsibilities.4': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Experienced data integration project manager who led the successful delivery of mission-critical platform initiatives.'), '1.down_to_earth.1': OptimizedText(optimized_text='Led three major data integration projects critical to the successful launch of a new platform. Adept at delivering high-impact client-facing solutions.'), '1.down_to_earth.2': OptimizedText(optimized_text='Led multiple data integration projects critical to the successful launch of a new enterprise platform, demonstrating strong experience managing client-facing analytics engagements.'), '1.down_to_earth.3': OptimizedText(optimized_text='Led the successful delivery of three mission-critical data integration projects instrumental in launching the new platform.'), '2.other.0': OptimizedText(optimized_text='Led the successful implementation of three mission-critical data integration projects that were instrumental in launching a new platform.')}), '3.responsibilities.5': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Established research leader who advanced to Research Manager role, drawing on over 10 years of analytical expertise.'), '1.down_to_earth.1': OptimizedText(optimized_text='Results-driven Research Manager with a proven track record of client engagement. Led teams and implemented strategies to deliver insights and drive improvements.'), '1.down_to_earth.2': OptimizedText(optimized_text='Managed analytical initiatives and partnered with clients to deliver impactful solutions. Promoted to Research Manager in 2007.'), '1.down_to_earth.3': OptimizedText(optimized_text='Promoted research professional with a decade of career advancement, culminating in a Research Manager role.'), '2.other.0': OptimizedText(optimized_text='Managed research initiatives and oversaw product development, driving continuous improvements based on client feedback. Transitioned from Senior Research Analyst to Research Manager.')}), '4.responsibilities.0': ResponsibilityMatch(optimized_by_requirements={'1.down_to_earth.0': OptimizedText(optimized_text='Drove strategic product decisions through extensive market research and analysis.'), '1.down_to_earth.1': OptimizedText(optimized_text='Researched market dynamics to drive strategic product development and strengthen client relationships.'), '1.down_to_earth.2': OptimizedText(optimized_text='Conducted market research and data analysis to inform strategic product decisions and improve client engagements.'), '1.down_to_earth.3': OptimizedText(optimized_text='Leveraged market research insights to develop and execute effective product strategies.'), '2.other.0': OptimizedText(optimized_text='Guided product strategy and development efforts by leveraging market research insights.')})}\"\n",
    "print(responsibilities)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Cross Tabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Code Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_responsibility</th>\n",
       "      <th>edited_responsibility_1</th>\n",
       "      <th>edited_responsibility_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>responsibility_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.0</th>\n",
       "      <td>Conversational AI &amp; NLP: Engineered the core d...</td>\n",
       "      <td>Engineered and executed AI-first strategies, f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.1</th>\n",
       "      <td>Thought Generation &amp; Processing: Designed pipe...</td>\n",
       "      <td>Thought Generation &amp; Processing: Developed adv...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.2</th>\n",
       "      <td>Automated Evaluation &amp; Adaptation: Developed a...</td>\n",
       "      <td>Developed and deployed an AI tool to monitor a...</td>\n",
       "      <td>Developed an AI-based system to assess user in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.3</th>\n",
       "      <td>State &amp; Topic Management: Built a stateful tra...</td>\n",
       "      <td>Built a stateful AI system to optimize convers...</td>\n",
       "      <td>Developed and executed a stateful tracking sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.4</th>\n",
       "      <td>Asynchronous AI Integration: Optimized API per...</td>\n",
       "      <td>Asynchronous AI Integration: Led enhancements ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                original_responsibility                            edited_responsibility_1                            edited_responsibility_2\n",
       "responsibility_key                                                                                                                                                           \n",
       "0.responsibilities.0  Conversational AI & NLP: Engineered the core d...  Engineered and executed AI-first strategies, f...                                                NaN\n",
       "0.responsibilities.1  Thought Generation & Processing: Designed pipe...  Thought Generation & Processing: Developed adv...                                                NaN\n",
       "0.responsibilities.2  Automated Evaluation & Adaptation: Developed a...  Developed and deployed an AI tool to monitor a...  Developed an AI-based system to assess user in...\n",
       "0.responsibilities.3  State & Topic Management: Built a stateful tra...  Built a stateful AI system to optimize convers...  Developed and executed a stateful tracking sys...\n",
       "0.responsibilities.4  Asynchronous AI Integration: Optimized API per...  Asynchronous AI Integration: Led enhancements ...                                                NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# * Full code that works (Grok + Meta)\n",
    "\n",
    "import xlwings as xw\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\github\\job_bot\\input_output\\human_review\\resps_reqs_matching\\openai_processed\\Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_crosstab.xlsx\"\n",
    "sht_name = \"Crosstab\"\n",
    "\n",
    "# Connect to the workbook\n",
    "wb = xw.Book(file_path)\n",
    "sheet = wb.sheets[sht_name]\n",
    "\n",
    "# Define the range of the table\n",
    "table_range = sheet.range(\"A1\").expand(\"table\")  # Adjust the range as needed\n",
    "\n",
    "# Initialize an empty list to store the underlined cells\n",
    "underlined_cells = []\n",
    "\n",
    "# Iterate over each row in the table range\n",
    "for i in range(1, table_range.rows.count + 1):\n",
    "    underlined_row = []\n",
    "    for j in range(1, table_range.columns.count + 1):\n",
    "        cell = table_range.api.Cells(i, j)\n",
    "        if j <= 2:  # * Keep the first 2 column as is\n",
    "            underlined_row.append(cell.Value)\n",
    "        elif cell.Font.Underline != -4142:  # -4142 represents no underline\n",
    "            underlined_row.append(cell.Value)\n",
    "        else:\n",
    "            underlined_row.append(None)  # or \"empty\"\n",
    "    underlined_cells.append(underlined_row)\n",
    "\n",
    "\n",
    "# Convert the list to a DataFrame and set the first column as the index\n",
    "df = pd.DataFrame(underlined_cells).set_index(0)\n",
    "\n",
    "# Delete all the None cells\n",
    "max_length = df.apply(lambda row: row.dropna().shape[0], axis=1).max()\n",
    "new_df = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Delete all the None cells\n",
    "\n",
    "\"\"\"\n",
    "What It Does to a Row:\n",
    "Starts with a row that might have missing values (like [1, NaN, 3]).\n",
    "\"Squeezes\" it by throwing out the NaNs, leaving only the real values (like [1, 3]).\n",
    "Picks the i-th value from this squeezed list (e.g., if i = 0, it picks 1; if i = 1, it picks 3).\n",
    "If i is too big (e.g., i = 2 but there are only 2 values), it returns None (or np.nan).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_ith_non_nan(row, i):\n",
    "    non_nan = row.dropna()\n",
    "    return non_nan.iloc[i] if i < len(non_nan) else np.nan\n",
    "\n",
    "\n",
    "for i in range(max_length):\n",
    "    new_df[i] = df.apply(get_ith_non_nan, args=(i,), axis=1)\n",
    "\n",
    "\n",
    "# Delete the first 3 rows (by slicing the DataFrame)\n",
    "new_df = new_df.iloc[2:]\n",
    "\n",
    "# Rename index and columns separately\n",
    "new_df.index.name = \"responsibility_key\"  # Rename the index\n",
    "new_df.columns = [\n",
    "    \"original_responsibility\",\n",
    "    \"edited_responsibility_1\",\n",
    "    \"edited_responsibility_2\",\n",
    "]  # Rename the 3 columns\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(new_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwings as xw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from docx import Document\n",
    "\n",
    "\n",
    "def load_excel_sheet(file_path, sheet_name):\n",
    "    \"\"\"Load an Excel sheet using xlwings.\"\"\"\n",
    "    wb = xw.Book(file_path)\n",
    "    sheet = wb.sheets[sheet_name]\n",
    "    return wb, sheet\n",
    "\n",
    "\n",
    "def get_underlined_cells(sheet):\n",
    "    \"\"\"Extract values from underlined cells while keeping the first two columns as is.\"\"\"\n",
    "    table_range = sheet.range(\"A1\").expand(\"table\")\n",
    "    underlined_cells = []\n",
    "\n",
    "    for i in range(1, table_range.rows.count + 1):\n",
    "        underlined_row = []\n",
    "        for j in range(1, table_range.columns.count + 1):\n",
    "            cell = table_range.api.Cells(i, j)\n",
    "            if j <= 2:  # Keep the first 2 columns as is\n",
    "                underlined_row.append(cell.Value)\n",
    "            elif cell.Font.Underline != -4142:  # -4142 represents no underline\n",
    "                underlined_row.append(cell.Value)\n",
    "            else:\n",
    "                underlined_row.append(None)  # or \"empty\"\n",
    "        underlined_cells.append(underlined_row)\n",
    "\n",
    "    return pd.DataFrame(underlined_cells).set_index(0)\n",
    "\n",
    "\n",
    "def clean_and_remove_rows(df):\n",
    "    \"\"\"Remove None values and reorganize the dataframe.\"\"\"\n",
    "    max_length = df.apply(lambda row: row.dropna().shape[0], axis=1).max()\n",
    "    new_df = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for i in range(max_length):\n",
    "        new_df[i] = df.apply(lambda row: get_ith_non_nan(row, i), axis=1)\n",
    "\n",
    "    return new_df.iloc[2:]  # Remove the first two rows\n",
    "\n",
    "\n",
    "def get_ith_non_nan(row, i):\n",
    "    \"\"\"Retrieve the ith non-NaN value from a row.\"\"\"\n",
    "    non_nan = row.dropna()\n",
    "    return non_nan.iloc[i] if i < len(non_nan) else np.nan\n",
    "\n",
    "\n",
    "def rename_dataframe_columns(df):\n",
    "    \"\"\"Rename index and columns dynamically based on the number of columns.\"\"\"\n",
    "    df.index.name = \"responsibility_key\"\n",
    "    column_names = [\"original_responsibility\"] + [\n",
    "        f\"edited_responsibility_{i}\" for i in range(1, df.shape[1])\n",
    "    ]\n",
    "    df.columns = column_names[: df.shape[1]]\n",
    "    return df\n",
    "\n",
    "\n",
    "def json_to_docx(json_data: dict, output_file: Path | str):\n",
    "    doc = Document()\n",
    "\n",
    "    if isinstance(json_data, str):\n",
    "        data = json.loads(json_data)\n",
    "    else:\n",
    "        data = json_data\n",
    "\n",
    "    for main_key, sub_dict in data.items():\n",
    "        for key, value in sub_dict.items():\n",
    "            doc.add_paragraph(f\"{key}:\")\n",
    "            doc.add_paragraph(value)\n",
    "            doc.add_paragraph(\"\")  # Add blank line\n",
    "\n",
    "    if isinstance(output_file, Path):\n",
    "        doc.save(str(output_file))\n",
    "    else:\n",
    "        doc.save(output_file)\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     file_path = r\"C:\\github\\job_bot\\input_output\\human_review\\resps_reqs_matching\\openai_processed\\Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_crosstab.xlsx\"\n",
    "#     sheet_name = \"Crosstab\"\n",
    "\n",
    "#     wb, sheet = load_excel_sheet(file_path, sheet_name)\n",
    "\n",
    "#     try:\n",
    "#         df = get_underlined_cells(sheet)\n",
    "#         cleaned_df = clean_and_remove_rows(df)\n",
    "#         final_df = rename_dataframe_columns(cleaned_df)\n",
    "\n",
    "#         pd.set_option(\"display.max_columns\", None)\n",
    "#         display(final_df.head(5))\n",
    "\n",
    "#     finally:\n",
    "#         wb.close()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Different Resume Files Per Posting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accenture Job Posting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_responsibility</th>\n",
       "      <th>edited_responsibility_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>responsibility_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.0</th>\n",
       "      <td>Conversational AI &amp; NLP: Engineered the core d...</td>\n",
       "      <td>Engineered and executed AI-first strategies, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.1</th>\n",
       "      <td>Thought Generation &amp; Processing: Designed pipe...</td>\n",
       "      <td>Thought Generation &amp; Processing: Developed adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.2</th>\n",
       "      <td>Automated Evaluation &amp; Adaptation: Developed a...</td>\n",
       "      <td>Developed an AI-based system to assess user in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.3</th>\n",
       "      <td>State &amp; Topic Management: Built a stateful tra...</td>\n",
       "      <td>Built a stateful AI system to optimize convers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.4</th>\n",
       "      <td>Asynchronous AI Integration: Optimized API per...</td>\n",
       "      <td>Asynchronous AI Integration: Led enhancements ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.0</th>\n",
       "      <td>Provided strategic insights to a major global ...</td>\n",
       "      <td>Optimized the service partner ecosystem for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.1</th>\n",
       "      <td>Assisted a U.S.-based international services p...</td>\n",
       "      <td>Assisted a U.S.-based international services p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.2</th>\n",
       "      <td>Co-authored an industry-recognized report on M...</td>\n",
       "      <td>Co-authored a seminal report on M&amp;A in the eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.3</th>\n",
       "      <td>Enhanced data quality and consistency by integ...</td>\n",
       "      <td>Enhanced data quality and consistency through ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.4</th>\n",
       "      <td>Achieved over 40% centralization of tasks to a...</td>\n",
       "      <td>Optimized resource allocation and enhanced tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.5</th>\n",
       "      <td>Developed Python tools to automate and acceler...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.6</th>\n",
       "      <td>Collaborated with the engineering services res...</td>\n",
       "      <td>Led the engineering services research team in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.7</th>\n",
       "      <td>Collaborated with analyst teams across the glo...</td>\n",
       "      <td>Collaborated with analyst teams around the wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.0</th>\n",
       "      <td>Full P&amp;L management including budgeting, HR, v...</td>\n",
       "      <td>Managed full P&amp;L responsibilities encompassing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.1</th>\n",
       "      <td>Expanded and managed a global research team of...</td>\n",
       "      <td>Expanded and managed a multinational research ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.2</th>\n",
       "      <td>Led an external software development team to b...</td>\n",
       "      <td>Led and mentored high-performing external soft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.3</th>\n",
       "      <td>Championed new technology projects using ML, N...</td>\n",
       "      <td>Championed AI-first product strategies, pionee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.4</th>\n",
       "      <td>Led a team to develop automated tools in Pytho...</td>\n",
       "      <td>Led a team in developing Python-based automati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.5</th>\n",
       "      <td>Advised services firms on deal pursuit and sal...</td>\n",
       "      <td>Advised service firms on integrating Responsib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.6</th>\n",
       "      <td>Advised software vendors on services partnersh...</td>\n",
       "      <td>Advised on strategic plans for AI-first softwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.7</th>\n",
       "      <td>Authored reports, blogs, presentations, &amp; cust...</td>\n",
       "      <td>Authored detailed reports, blogs, presentation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.responsibilities.0</th>\n",
       "      <td>Delivered quarterly webinars on outsourcing/ma...</td>\n",
       "      <td>Delivered quarterly webinars on outsourcing an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.responsibilities.1</th>\n",
       "      <td>Authored 7 to 10 pursuit strategy reports and ...</td>\n",
       "      <td>Authored multiple strategy reports and conduct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.responsibilities.0</th>\n",
       "      <td>Designed and architected a complex company dat...</td>\n",
       "      <td>Designed and architected a sophisticated compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.responsibilities.1</th>\n",
       "      <td>Oversaw two Appian implementations that increa...</td>\n",
       "      <td>Oversaw multiple Appian implementations at a B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.responsibilities.2</th>\n",
       "      <td>Managed daily content operations, including le...</td>\n",
       "      <td>Managed daily content operations and led a div...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.responsibilities.3</th>\n",
       "      <td>Analyzed and Modeled 20 to 30 IT vendors' fina...</td>\n",
       "      <td>Analyzed and modeled the financials of numerou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.responsibilities.4</th>\n",
       "      <td>Managed three major data integration projects ...</td>\n",
       "      <td>Led several major data integration projects, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.responsibilities.5</th>\n",
       "      <td>Promoted from Senior Research Analyst to Resea...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.responsibilities.0</th>\n",
       "      <td>Researched market dynamics in the Web Services...</td>\n",
       "      <td>Explored market trends in the Web Services Sec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                original_responsibility  \\\n",
       "responsibility_key                                                        \n",
       "0.responsibilities.0  Conversational AI & NLP: Engineered the core d...   \n",
       "0.responsibilities.1  Thought Generation & Processing: Designed pipe...   \n",
       "0.responsibilities.2  Automated Evaluation & Adaptation: Developed a...   \n",
       "0.responsibilities.3  State & Topic Management: Built a stateful tra...   \n",
       "0.responsibilities.4  Asynchronous AI Integration: Optimized API per...   \n",
       "1.responsibilities.0  Provided strategic insights to a major global ...   \n",
       "1.responsibilities.1  Assisted a U.S.-based international services p...   \n",
       "1.responsibilities.2  Co-authored an industry-recognized report on M...   \n",
       "1.responsibilities.3  Enhanced data quality and consistency by integ...   \n",
       "1.responsibilities.4  Achieved over 40% centralization of tasks to a...   \n",
       "1.responsibilities.5  Developed Python tools to automate and acceler...   \n",
       "1.responsibilities.6  Collaborated with the engineering services res...   \n",
       "1.responsibilities.7  Collaborated with analyst teams across the glo...   \n",
       "2.responsibilities.0  Full P&L management including budgeting, HR, v...   \n",
       "2.responsibilities.1  Expanded and managed a global research team of...   \n",
       "2.responsibilities.2  Led an external software development team to b...   \n",
       "2.responsibilities.3  Championed new technology projects using ML, N...   \n",
       "2.responsibilities.4  Led a team to develop automated tools in Pytho...   \n",
       "2.responsibilities.5  Advised services firms on deal pursuit and sal...   \n",
       "2.responsibilities.6  Advised software vendors on services partnersh...   \n",
       "2.responsibilities.7  Authored reports, blogs, presentations, & cust...   \n",
       "3.responsibilities.0  Delivered quarterly webinars on outsourcing/ma...   \n",
       "3.responsibilities.1  Authored 7 to 10 pursuit strategy reports and ...   \n",
       "4.responsibilities.0  Designed and architected a complex company dat...   \n",
       "4.responsibilities.1  Oversaw two Appian implementations that increa...   \n",
       "4.responsibilities.2  Managed daily content operations, including le...   \n",
       "4.responsibilities.3  Analyzed and Modeled 20 to 30 IT vendors' fina...   \n",
       "4.responsibilities.4  Managed three major data integration projects ...   \n",
       "4.responsibilities.5  Promoted from Senior Research Analyst to Resea...   \n",
       "5.responsibilities.0  Researched market dynamics in the Web Services...   \n",
       "\n",
       "                                                edited_responsibility_1  \n",
       "responsibility_key                                                       \n",
       "0.responsibilities.0  Engineered and executed AI-first strategies, f...  \n",
       "0.responsibilities.1  Thought Generation & Processing: Developed adv...  \n",
       "0.responsibilities.2  Developed an AI-based system to assess user in...  \n",
       "0.responsibilities.3  Built a stateful AI system to optimize convers...  \n",
       "0.responsibilities.4  Asynchronous AI Integration: Led enhancements ...  \n",
       "1.responsibilities.0  Optimized the service partner ecosystem for a ...  \n",
       "1.responsibilities.1  Assisted a U.S.-based international services p...  \n",
       "1.responsibilities.2  Co-authored a seminal report on M&A in the eng...  \n",
       "1.responsibilities.3  Enhanced data quality and consistency through ...  \n",
       "1.responsibilities.4  Optimized resource allocation and enhanced tea...  \n",
       "1.responsibilities.5                                                NaN  \n",
       "1.responsibilities.6  Led the engineering services research team in ...  \n",
       "1.responsibilities.7  Collaborated with analyst teams around the wor...  \n",
       "2.responsibilities.0  Managed full P&L responsibilities encompassing...  \n",
       "2.responsibilities.1  Expanded and managed a multinational research ...  \n",
       "2.responsibilities.2  Led and mentored high-performing external soft...  \n",
       "2.responsibilities.3  Championed AI-first product strategies, pionee...  \n",
       "2.responsibilities.4  Led a team in developing Python-based automati...  \n",
       "2.responsibilities.5  Advised service firms on integrating Responsib...  \n",
       "2.responsibilities.6  Advised on strategic plans for AI-first softwa...  \n",
       "2.responsibilities.7  Authored detailed reports, blogs, presentation...  \n",
       "3.responsibilities.0  Delivered quarterly webinars on outsourcing an...  \n",
       "3.responsibilities.1  Authored multiple strategy reports and conduct...  \n",
       "4.responsibilities.0  Designed and architected a sophisticated compa...  \n",
       "4.responsibilities.1  Oversaw multiple Appian implementations at a B...  \n",
       "4.responsibilities.2  Managed daily content operations and led a div...  \n",
       "4.responsibilities.3  Analyzed and modeled the financials of numerou...  \n",
       "4.responsibilities.4  Led several major data integration projects, e...  \n",
       "4.responsibilities.5                                                NaN  \n",
       "5.responsibilities.0  Explored market trends in the Web Services Sec...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = r\"C:\\github\\job_bot\\input_output\\human_review\\resps_reqs_matching\\openai_processed\\Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_crosstab.xlsx\"\n",
    "sheet_name = \"Crosstab\"\n",
    "\n",
    "\n",
    "wb, sheet = load_excel_sheet(file_path, sheet_name)\n",
    "df = get_underlined_cells(sheet)\n",
    "cleaned_df = clean_and_remove_rows(df)\n",
    "final_df = rename_dataframe_columns(cleaned_df)\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "display(final_df)\n",
    "\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON format: Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON String:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"original_responsibility\": {\n",
       "    \"0.responsibilities.0\": \"Conversational AI & NLP: Engineered the core dialogue system to generate dynamic questions,\n",
       "evaluate responses, and maintain conversation flow.\",\n",
       "    \"0.responsibilities.1\": \"Thought Generation & Processing: Designed pipelines for hierarchical idea expansion,\n",
       "clustering, and ranking AI-generated thoughts.\",\n",
       "    \"0.responsibilities.2\": \"Automated Evaluation & Adaptation: Developed an AI-based evaluator to assess user\n",
       "responses, generate adaptive follow-ups, and track discussion depth.\",\n",
       "    \"0.responsibilities.3\": \"State & Topic Management: Built a stateful tracking system to guide conversations, handle\n",
       "topic transitions, and prevent redundancy.\",\n",
       "    \"0.responsibilities.4\": \"Asynchronous AI Integration: Optimized API performance for OpenAI GPT-4 & Anthropic Claude\n",
       "using AsyncIO, improving efficiency and scalability.\",\n",
       "    \"1.responsibilities.0\": \"Provided strategic insights to a major global IT vendor, optimizing their service partner\n",
       "ecosystem in Asia Pacific for improved local implementation outcomes.\",\n",
       "    \"1.responsibilities.1\": \"Assisted a U.S.-based international services provider in its growth strategy by precisely\n",
       "evaluating and scaling new engineering service opportunities in vital emerging markets.\",\n",
       "    \"1.responsibilities.2\": \"Co-authored an industry-recognized report on M&A in the engineering services sector,\n",
       "offering deep dives into deal sizes, capability gaps, and emerging opportunities, influencing strategic decisions in IT\n",
       "and operational technology convergence.\",\n",
       "    \"1.responsibilities.3\": \"Enhanced data quality and consistency by integrating thorough financial analysis,\n",
       "standardizing methodologies, and conducting in-depth vendor engagements.\",\n",
       "    \"1.responsibilities.4\": \"Achieved over 40% centralization of tasks to an offshore team in India, optimizing resource\n",
       "allocation.\",\n",
       "    \"1.responsibilities.5\": \"Developed Python tools to automate and accelerate internal processes, cutting report\n",
       "preparation and data analysis time by over 40%.\",\n",
       "    \"1.responsibilities.6\": \"Collaborated with the engineering services research team to pioneer the engineering\n",
       "services tracker, authored influential publications on market forecasts, the impact of COVID-19 on services, and trends\n",
       "in M&A within the engineering services industry.\",\n",
       "    \"1.responsibilities.7\": \"Collaborated with analyst teams across the globe (US, Canada, Latin America, Europe, MEA,\n",
       "APAC) to ensure data quality, meeting deadlines, sharing knowledge/best practices/methodology, and procure new tools.\",\n",
       "    \"2.responsibilities.0\": \"Full P&L management including budgeting, HR, vendors, partnerships, research, and business\n",
       "development: expanded the programs' bookings by more than 50%.\",\n",
       "    \"2.responsibilities.1\": \"Expanded and managed a global research team of more than 15 (US, India, and Mexico).\",\n",
       "    \"2.responsibilities.2\": \"Led an external software development team to build and implement new tools.\",\n",
       "    \"2.responsibilities.3\": \"Championed new technology projects using ML, NLP, chatbot, ontology, web-scraping, API, UX\n",
       "(User Experience). First in IDC to implement ML (machine learning). First to launch a chatbot. First to implement API\n",
       "(application programming interface). First to build an ontology.\",\n",
       "    \"2.responsibilities.4\": \"Led a team to develop automated tools in Python, reducing report preparation time by 40%.\",\n",
       "    \"2.responsibilities.5\": \"Advised services firms on deal pursuit and sales orchestration strategies.\",\n",
       "    \"2.responsibilities.6\": \"Advised software vendors on services partnership strategy.\",\n",
       "    \"2.responsibilities.7\": \"Authored reports, blogs, presentations, & custom researches in go-to-market strategy, deal\n",
       "signing analysis, renewal analysis, buyer studies, technology adoptions (cloud, AI, ML, digital, etc.), and industry\n",
       "trend analysis.\",\n",
       "    \"3.responsibilities.0\": \"Delivered quarterly webinars on outsourcing/managed services signing trends.\",\n",
       "    \"3.responsibilities.1\": \"Authored 7 to 10 pursuit strategy reports and industry trend research documents.\",\n",
       "    \"4.responsibilities.0\": \"Designed and architected a complex company database with 100K+ unique records and\n",
       "integrating DnB API and internal databases, which reduced data duplication by 50%.\",\n",
       "    \"4.responsibilities.1\": \"Oversaw two Appian implementations that increased team productivity by 20 to 30%.\",\n",
       "    \"4.responsibilities.2\": \"Managed daily content operations, including leading a team of offshore and nearshore\n",
       "content team, as well as other sales and research related activities.\",\n",
       "    \"4.responsibilities.3\": \"Analyzed and Modeled 20 to 30 IT vendors' financials and over 1,500 services contracts.\",\n",
       "    \"4.responsibilities.4\": \"Managed three major data integration projects critical to the launch of the new platform.\",\n",
       "    \"4.responsibilities.5\": \"Promoted from Senior Research Analyst to Research Manager in February 2007.\",\n",
       "    \"5.responsibilities.0\": \"Researched market dynamics in the Web Services Security market to support product\n",
       "strategy.\"\n",
       "  }\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = r\"C:\\github\\job_bot\\input_output\\human_review\\resps_reqs_matching\\openai_processed\\Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_crosstab.xlsx\"\n",
    "sheet_name = \"Crosstab\"\n",
    "\n",
    "\n",
    "wb, sheet = load_excel_sheet(file_path, sheet_name)\n",
    "df = get_underlined_cells(sheet)\n",
    "cleaned_df = clean_and_remove_rows(df)\n",
    "final_df = rename_dataframe_columns(cleaned_df)\n",
    "\n",
    "final_df.drop(\"edited_responsibility_1\", axis=1, inplace=True)\n",
    "\n",
    "# print(final_df)\n",
    "json_string = final_df.to_json()\n",
    "json_data = json.loads(json_string)  # Convert string to dictionary\n",
    "\n",
    "print(\"JSON String:\")\n",
    "\n",
    "# Format JSON for readability\n",
    "formatted_json = format_json_readable(json_data, wrap_width=120)\n",
    "\n",
    "# Display with Markdown to prevent horizontal scrolling\n",
    "display(Markdown(f\"```json\\n{formatted_json}\\n```\"))\n",
    "\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON format: edited by LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON String:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"edited_responsibility_1\": {\n",
       "    \"0.responsibilities.0\": \"Engineered and executed AI-first strategies, focusing on the development and engineering of\n",
       "conversational AI systems to enhance user engagement and generate commercialization opportunities.\",\n",
       "    \"0.responsibilities.1\": \"Thought Generation & Processing: Developed advanced algorithms for structuring and\n",
       "prioritizing AI-generated ideas, demonstrating expertise in environments akin to consulting, professional services, or\n",
       "Big Four firms.\",\n",
       "    \"0.responsibilities.2\": \"Developed an AI-based system to assess user interactions and adaptively generate follow-up\n",
       "content, ensuring alignment with responsible AI practices as outlined in the strategic vision. This system also tracks\n",
       "engagement levels to support an innovative operating model, fostering a culture of innovation and experimentation.\",\n",
       "    \"0.responsibilities.3\": \"Built a stateful AI system to optimize conversation flows and strategically manage\n",
       "dialogues, supporting the creation of strategies for AI-first products and exploring commercialization opportunities.\",\n",
       "    \"0.responsibilities.4\": \"Asynchronous AI Integration: Led enhancements in API performance for leading AI models such\n",
       "as OpenAI GPT-4 and Anthropic Claude, focusing on boosting efficiency and scalability. This strategic initiative was\n",
       "crucial in reshaping the vision and opening pathways for data and AI-driven business transformation.\",\n",
       "    \"1.responsibilities.0\": \"Optimized the service partner ecosystem for a leading global IT vendor in the Asia Pacific\n",
       "region by providing strategic insights, including Data & AI, that enhanced client relationships and established\n",
       "credibility as a trusted advisor, leading to improved implementation outcomes.\",\n",
       "    \"1.responsibilities.1\": \"Assisted a U.S.-based international services provider by shaping strategic visions and\n",
       "creating scalable opportunities, particularly in new data and AI-driven engineering services in key emerging markets.\",\n",
       "    \"1.responsibilities.2\": \"Co-authored a seminal report on M&A in the engineering services sector, analyzing deal\n",
       "dimensions and capability gaps. This work influenced strategic visions and fostered new opportunities, particularly by\n",
       "driving convergence between IT and operational technology to reinvent businesses through data and AI.\",\n",
       "    \"1.responsibilities.3\": \"Enhanced data quality and consistency through comprehensive financial analysis and the\n",
       "standardization of methodologies, collaborating extensively with vendors to shape vision and unlock opportunities for\n",
       "data & AI-led business reinvention.\",\n",
       "    \"1.responsibilities.4\": \"Optimized resource allocation and enhanced team performance by centralizing over 40% of\n",
       "tasks to an offshore team in India, effectively mentoring and developing high-performing teams.\",\n",
       "    \"1.responsibilities.5\": null,\n",
       "    \"1.responsibilities.6\": \"Led the engineering services research team in pioneering the engineering services tracker,\n",
       "authored key publications on market forecasts, the impact of COVID-19 on the industry, and M&A trends, significantly\n",
       "shaping strategic insights and creating opportunities for data & AI-led business reinvention.\",\n",
       "    \"1.responsibilities.7\": \"Collaborated with analyst teams around the world, including the US, Canada, Latin America,\n",
       "Europe, MEA, and APAC, in a global professional services environment. Enhanced data quality, ensured timely project\n",
       "completions, and integrated new tools and best practices typical of Big Four and consulting firm settings.\",\n",
       "    \"2.responsibilities.0\": \"Managed full P&L responsibilities encompassing budgeting, human resources, vendor\n",
       "relations, and strategic partnerships, coupled with a focus on research and business development, which collectively led\n",
       "to a substantial increase in program bookings.\",\n",
       "    \"2.responsibilities.1\": \"Expanded and managed a multinational research team across the US, India, and Mexico,\n",
       "focusing on spearheading the strategic development of AI-first products and their commercialization strategies.\",\n",
       "    \"2.responsibilities.2\": \"Led and mentored high-performing external software development teams to innovate and\n",
       "successfully implement new tools.\",\n",
       "    \"2.responsibilities.3\": \"Championed AI-first product strategies, pioneering and commercializing cutting-edge\n",
       "technologies including machine learning, natural language processing, chatbots, ontologies, and APIs. Spearheaded the\n",
       "initial rollout of user-centric AI solutions that enhanced web interfaces and user experiences, opening significant\n",
       "avenues for commercialization.\",\n",
       "    \"2.responsibilities.4\": \"Led a team in developing Python-based automation tools, reducing report preparation time by\n",
       "40%. Boasts extensive experience in business development, client relationship management, and marketing, with over five\n",
       "years dedicated to these areas.\",\n",
       "    \"2.responsibilities.5\": \"Advised service firms on integrating Responsible AI into their strategic vision and\n",
       "roadmap, developed approaches for leveraging ecosystem partners in deal pursuits, and defined sales orchestration\n",
       "processes to enhance a culture of innovation and experimentation.\",\n",
       "    \"2.responsibilities.6\": \"Advised on strategic plans for AI-first software products, focusing on developing\n",
       "partnership strategies and exploiting commercialization opportunities.\",\n",
       "    \"2.responsibilities.7\": \"Authored detailed reports, blogs, presentations, and specialized research in go-to-market\n",
       "strategies, deal signing, renewal processes, and buyer behavior, focusing on the in-depth analysis of technology\n",
       "adoption trends such as cloud computing, artificial intelligence, machine learning, and digital transformations. This\n",
       "expertise has played a crucial role in strengthening client relationships and establishing a reputation as a trusted\n",
       "advisor, especially in guiding the integration of Data & AI into business processes and industry trends.\",\n",
       "    \"3.responsibilities.0\": \"Delivered quarterly webinars on outsourcing and managed services, emphasizing strategic\n",
       "planning and the utilization of partnerships to promote a culture of innovation and experimentation, in alignment with\n",
       "Responsible AI and ecosystem collaboration trends.\",\n",
       "    \"3.responsibilities.1\": \"Authored multiple strategy reports and conducted industry trend analyses, significantly\n",
       "enhancing client relationships and establishing credibility as a trusted advisor on incorporating Data & AI into\n",
       "business processes.\",\n",
       "    \"4.responsibilities.0\": \"Designed and architected a sophisticated company database encompassing over 100,000 unique\n",
       "records, integrating external APIs like Salesforce and internal systems, effectively reducing data duplication by 50%\n",
       "and enhancing data integrity, demonstrating adeptness in CRM tools for efficient tracking and analysis of client\n",
       "interactions.\",\n",
       "    \"4.responsibilities.1\": \"Oversaw multiple Appian implementations at a Big Four firm, enhancing team productivity\n",
       "significantly and demonstrating extensive consulting experience.\",\n",
       "    \"4.responsibilities.2\": \"Managed daily content operations and led a diverse team, significantly enhancing\n",
       "performance in sales and research, and demonstrating a strong ability to develop high-performing teams.\",\n",
       "    \"4.responsibilities.3\": \"Analyzed and modeled the financials of numerous IT vendors, managed extensive portfolios of\n",
       "service contracts, and leveraged this expertise to build strong client relationships, serving as a trusted advisor on\n",
       "integrating Data & AI into business processes.\",\n",
       "    \"4.responsibilities.4\": \"Led several major data integration projects, essential for the successful launch of a new\n",
       "platform, and successfully mentored and developed high-performing teams.\",\n",
       "    \"4.responsibilities.5\": null,\n",
       "    \"5.responsibilities.0\": \"Explored market trends in the Web Services Security sector to bolster product strategy\n",
       "through collaborative leadership and a growth-oriented approach.\"\n",
       "  }\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = r\"C:\\github\\job_bot\\input_output\\human_review\\resps_reqs_matching\\openai_processed\\Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_crosstab.xlsx\"\n",
    "sheet_name = \"Crosstab\"\n",
    "\n",
    "wb, sheet = load_excel_sheet(file_path, sheet_name)\n",
    "df = get_underlined_cells(sheet)\n",
    "cleaned_df = clean_and_remove_rows(df)\n",
    "final_df = rename_dataframe_columns(cleaned_df)\n",
    "\n",
    "final_df.drop(\"original_responsibility\", axis=1, inplace=True)\n",
    "# print(final_df)\n",
    "\n",
    "json_string = final_df.to_json()\n",
    "json_data = json.loads(json_string)  # Convert string to dictionary\n",
    "\n",
    "print(\"JSON String:\")\n",
    "# Format JSON for readability\n",
    "formatted_json = format_json_readable(json_data, wrap_width=120)\n",
    "\n",
    "# Display with Markdown to prevent horizontal scrolling\n",
    "display(Markdown(f\"```json\\n{formatted_json}\\n```\"))\n",
    "\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final trim & edit by Grok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"revised_responsibility_1\": {\n",
       "    \"0.responsibilities.0\": \"Engineered conversational AI systems to boost engagement and drive commercialization\n",
       "opportunities.\",\n",
       "    \"0.responsibilities.1\": \"Developed advanced algorithms to structure and prioritize AI-generated ideas for strategic\n",
       "applications.\",\n",
       "    \"0.responsibilities.2\": \"Built AI system to evaluate user interactions, adapt content, and measure engagement\n",
       "depth.\",\n",
       "    \"0.responsibilities.3\": \"Created stateful AI framework to optimize conversation flows and guide strategic\n",
       "dialogues.\",\n",
       "    \"0.responsibilities.4\": \"Enhanced API performance for OpenAI GPT-4 and Anthropic Claude with AsyncIO for\n",
       "scalability.\",\n",
       "    \"1.responsibilities.0\": \"Optimized IT vendor’s Asia Pacific ecosystem with data and AI-driven strategic insights.\",\n",
       "    \"1.responsibilities.1\": \"Shaped scalable data and AI engineering service strategies for a U.S. provider in emerging\n",
       "markets.\",\n",
       "    \"1.responsibilities.2\": \"Co-authored M&A report on engineering services, driving IT-OT convergence strategies.\",\n",
       "    \"1.responsibilities.3\": \"Improved data quality with financial analysis and vendor collaboration for AI-led\n",
       "outcomes.\",\n",
       "    \"1.responsibilities.4\": \"Centralized 40% of tasks to offshore India team, enhancing resource efficiency.\",\n",
       "    \"1.responsibilities.5\": null,\n",
       "    \"1.responsibilities.6\": \"Led engineering services tracker, authored influential market forecasts and M&A trend\n",
       "analyses.\",\n",
       "    \"1.responsibilities.7\": \"Collaborated globally to ensure data quality, meet deadlines, and deploy innovative\n",
       "tools.\",\n",
       "    \"2.responsibilities.0\": \"Managed P&L across budgeting and partnerships, growing bookings by over 50%.\",\n",
       "    \"2.responsibilities.1\": \"Expanded and led global research team in US, India, and Mexico for AI-first initiatives.\",\n",
       "    \"2.responsibilities.2\": \"Directed external software team to develop and deploy innovative tools.\",\n",
       "    \"2.responsibilities.3\": \"Pioneered ML, NLP, and chatbot technologies, launching AI-first solutions.\",\n",
       "    \"2.responsibilities.4\": \"Led Python tool development, cutting report preparation time by 40%.\",\n",
       "    \"2.responsibilities.5\": \"Advised firms on Responsible AI integration and sales orchestration strategies.\",\n",
       "    \"2.responsibilities.6\": \"Guided software vendors on AI-first partnership and commercialization strategies.\",\n",
       "    \"2.responsibilities.7\": \"Authored go-to-market reports on AI, cloud, and digital trends for strategic impact.\",\n",
       "    \"3.responsibilities.0\": \"Delivered webinars on outsourcing trends, emphasizing innovation and partnerships.\",\n",
       "    \"3.responsibilities.1\": \"Authored strategy reports and trend analyses to shape data and AI insights.\",\n",
       "    \"4.responsibilities.0\": \"Architected database with 100K+ records, cutting duplication by 50% via API integration.\",\n",
       "    \"4.responsibilities.1\": \"Oversaw Appian implementations, increasing team productivity by 20-30%.\",\n",
       "    \"4.responsibilities.2\": \"Managed content operations, leading offshore teams for sales and research success.\",\n",
       "    \"4.responsibilities.3\": \"Analyzed financials of IT vendors and 1,500+ contracts for strategic insights.\",\n",
       "    \"4.responsibilities.4\": \"Led critical data integration projects for new platform deployment.\",\n",
       "    \"4.responsibilities.5\": null,\n",
       "    \"5.responsibilities.0\": \"Researched Web Services Security trends to inform product strategy.\"\n",
       "  }\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = r\"C:\\github\\job_bot\\data\\Accenture_Enterprise_AI_Value_Strategy_Senior_Manager_grok_final_edit.json\"\n",
    "\n",
    "display_json_pretty(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blend Job Posting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_responsibility</th>\n",
       "      <th>edited_responsibility_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>responsibility_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.0</th>\n",
       "      <td>Conversational AI &amp; NLP: Engineered the core d...</td>\n",
       "      <td>Engineered the core dialogue system to generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.1</th>\n",
       "      <td>Thought Generation &amp; Processing: Designed pipe...</td>\n",
       "      <td>Led the design and deployment of AI-powered so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.2</th>\n",
       "      <td>Automated Evaluation &amp; Adaptation: Developed a...</td>\n",
       "      <td>Led the development of AI-powered systems that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.3</th>\n",
       "      <td>State &amp; Topic Management: Built a stateful tra...</td>\n",
       "      <td>Led the design and implementation of a statefu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.responsibilities.4</th>\n",
       "      <td>Asynchronous AI Integration: Optimized API per...</td>\n",
       "      <td>Led the optimization of high-performance AI sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.0</th>\n",
       "      <td>Provided strategic insights to a major global ...</td>\n",
       "      <td>Led strategic initiatives to optimize the serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.1</th>\n",
       "      <td>Assisted a U.S.-based international services p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.2</th>\n",
       "      <td>Co-authored an industry-recognized report on M...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.3</th>\n",
       "      <td>Enhanced data quality and consistency by integ...</td>\n",
       "      <td>Led comprehensive financial analysis and proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.4</th>\n",
       "      <td>Achieved over 40% centralization of tasks to a...</td>\n",
       "      <td>Led centralized task management initiatives, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.5</th>\n",
       "      <td>Developed Python tools to automate and acceler...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.6</th>\n",
       "      <td>Collaborated with the engineering services res...</td>\n",
       "      <td>Pioneered the engineering services tracker as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.responsibilities.7</th>\n",
       "      <td>Collaborated with analyst teams across the glo...</td>\n",
       "      <td>Led global analyst teams to ensure data integr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.0</th>\n",
       "      <td>Full P&amp;L management including budgeting, HR, v...</td>\n",
       "      <td>Seasoned professional who led full P&amp;L managem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.1</th>\n",
       "      <td>Expanded and managed a global research team of...</td>\n",
       "      <td>Led and grew a multicultural research team wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.2</th>\n",
       "      <td>Led an external software development team to b...</td>\n",
       "      <td>Led external software development teams to con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.3</th>\n",
       "      <td>Championed new technology projects using ML, N...</td>\n",
       "      <td>Innovative technology leader who championed tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.4</th>\n",
       "      <td>Led a team to develop automated tools in Pytho...</td>\n",
       "      <td>Led a team in developing automated Python tool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.5</th>\n",
       "      <td>Advised services firms on deal pursuit and sal...</td>\n",
       "      <td>Advised services firms on deal pursuit and sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.6</th>\n",
       "      <td>Advised software vendors on services partnersh...</td>\n",
       "      <td>Leveraged strong communication and interperson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.responsibilities.7</th>\n",
       "      <td>Authored reports, blogs, presentations, &amp; cust...</td>\n",
       "      <td>Led the creation of impactful content, includi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.responsibilities.0</th>\n",
       "      <td>Delivered quarterly webinars on outsourcing/ma...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.responsibilities.1</th>\n",
       "      <td>Authored 7 to 10 pursuit strategy reports and ...</td>\n",
       "      <td>Authored strategic reports and industry analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.responsibilities.0</th>\n",
       "      <td>Designed and architected a complex company dat...</td>\n",
       "      <td>Designed and implemented a comprehensive enter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.responsibilities.1</th>\n",
       "      <td>Oversaw two Appian implementations that increa...</td>\n",
       "      <td>Led successful Appian implementations that enh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.responsibilities.2</th>\n",
       "      <td>Managed daily content operations, including le...</td>\n",
       "      <td>Led cross-functional content teams and oversaw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.responsibilities.3</th>\n",
       "      <td>Analyzed and Modeled 20 to 30 IT vendors' fina...</td>\n",
       "      <td>Analyzed financials of 20-30 IT service provid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.responsibilities.4</th>\n",
       "      <td>Managed three major data integration projects ...</td>\n",
       "      <td>Led the successful delivery of three mission-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.responsibilities.5</th>\n",
       "      <td>Promoted from Senior Research Analyst to Resea...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.responsibilities.0</th>\n",
       "      <td>Researched market dynamics in the Web Services...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                original_responsibility  \\\n",
       "responsibility_key                                                        \n",
       "0.responsibilities.0  Conversational AI & NLP: Engineered the core d...   \n",
       "0.responsibilities.1  Thought Generation & Processing: Designed pipe...   \n",
       "0.responsibilities.2  Automated Evaluation & Adaptation: Developed a...   \n",
       "0.responsibilities.3  State & Topic Management: Built a stateful tra...   \n",
       "0.responsibilities.4  Asynchronous AI Integration: Optimized API per...   \n",
       "1.responsibilities.0  Provided strategic insights to a major global ...   \n",
       "1.responsibilities.1  Assisted a U.S.-based international services p...   \n",
       "1.responsibilities.2  Co-authored an industry-recognized report on M...   \n",
       "1.responsibilities.3  Enhanced data quality and consistency by integ...   \n",
       "1.responsibilities.4  Achieved over 40% centralization of tasks to a...   \n",
       "1.responsibilities.5  Developed Python tools to automate and acceler...   \n",
       "1.responsibilities.6  Collaborated with the engineering services res...   \n",
       "1.responsibilities.7  Collaborated with analyst teams across the glo...   \n",
       "2.responsibilities.0  Full P&L management including budgeting, HR, v...   \n",
       "2.responsibilities.1  Expanded and managed a global research team of...   \n",
       "2.responsibilities.2  Led an external software development team to b...   \n",
       "2.responsibilities.3  Championed new technology projects using ML, N...   \n",
       "2.responsibilities.4  Led a team to develop automated tools in Pytho...   \n",
       "2.responsibilities.5  Advised services firms on deal pursuit and sal...   \n",
       "2.responsibilities.6  Advised software vendors on services partnersh...   \n",
       "2.responsibilities.7  Authored reports, blogs, presentations, & cust...   \n",
       "3.responsibilities.0  Delivered quarterly webinars on outsourcing/ma...   \n",
       "3.responsibilities.1  Authored 7 to 10 pursuit strategy reports and ...   \n",
       "4.responsibilities.0  Designed and architected a complex company dat...   \n",
       "4.responsibilities.1  Oversaw two Appian implementations that increa...   \n",
       "4.responsibilities.2  Managed daily content operations, including le...   \n",
       "4.responsibilities.3  Analyzed and Modeled 20 to 30 IT vendors' fina...   \n",
       "4.responsibilities.4  Managed three major data integration projects ...   \n",
       "4.responsibilities.5  Promoted from Senior Research Analyst to Resea...   \n",
       "5.responsibilities.0  Researched market dynamics in the Web Services...   \n",
       "\n",
       "                                                edited_responsibility_1  \n",
       "responsibility_key                                                       \n",
       "0.responsibilities.0  Engineered the core dialogue system to generat...  \n",
       "0.responsibilities.1  Led the design and deployment of AI-powered so...  \n",
       "0.responsibilities.2  Led the development of AI-powered systems that...  \n",
       "0.responsibilities.3  Led the design and implementation of a statefu...  \n",
       "0.responsibilities.4  Led the optimization of high-performance AI sy...  \n",
       "1.responsibilities.0  Led strategic initiatives to optimize the serv...  \n",
       "1.responsibilities.1                                                NaN  \n",
       "1.responsibilities.2                                                NaN  \n",
       "1.responsibilities.3  Led comprehensive financial analysis and proce...  \n",
       "1.responsibilities.4  Led centralized task management initiatives, a...  \n",
       "1.responsibilities.5                                                NaN  \n",
       "1.responsibilities.6  Pioneered the engineering services tracker as ...  \n",
       "1.responsibilities.7  Led global analyst teams to ensure data integr...  \n",
       "2.responsibilities.0  Seasoned professional who led full P&L managem...  \n",
       "2.responsibilities.1  Led and grew a multicultural research team wit...  \n",
       "2.responsibilities.2  Led external software development teams to con...  \n",
       "2.responsibilities.3  Innovative technology leader who championed tr...  \n",
       "2.responsibilities.4  Led a team in developing automated Python tool...  \n",
       "2.responsibilities.5  Advised services firms on deal pursuit and sal...  \n",
       "2.responsibilities.6  Leveraged strong communication and interperson...  \n",
       "2.responsibilities.7  Led the creation of impactful content, includi...  \n",
       "3.responsibilities.0                                                NaN  \n",
       "3.responsibilities.1  Authored strategic reports and industry analys...  \n",
       "4.responsibilities.0  Designed and implemented a comprehensive enter...  \n",
       "4.responsibilities.1  Led successful Appian implementations that enh...  \n",
       "4.responsibilities.2  Led cross-functional content teams and oversaw...  \n",
       "4.responsibilities.3  Analyzed financials of 20-30 IT service provid...  \n",
       "4.responsibilities.4  Led the successful delivery of three mission-c...  \n",
       "4.responsibilities.5                                                NaN  \n",
       "5.responsibilities.0                                                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "company = \"Blend\"\n",
    "\n",
    "file_path = r\"C:\\github\\job_bot\\input_output\\human_review\\resps_reqs_matching\\reviewed_matchings\\Blend_Director__AI_Strategy_crosstab_reviewed.xlsx\"\n",
    "sheet_name = \"Crosstab\"\n",
    "\n",
    "wb, sheet = load_excel_sheet(file_path, sheet_name)\n",
    "df = get_underlined_cells(sheet)\n",
    "\n",
    "\n",
    "cleaned_df = clean_and_remove_rows(df)\n",
    "final_df = rename_dataframe_columns(cleaned_df)\n",
    "\n",
    "print(company)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(final_df)\n",
    "\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON format: Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON: original\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"original_responsibility\": {\n",
       "    \"0.responsibilities.0\": \"Conversational AI & NLP: Engineered the core dialogue system to generate dynamic questions,\n",
       "evaluate responses, and maintain conversation flow.\",\n",
       "    \"0.responsibilities.1\": \"Thought Generation & Processing: Designed pipelines for hierarchical idea expansion,\n",
       "clustering, and ranking AI-generated thoughts.\",\n",
       "    \"0.responsibilities.2\": \"Automated Evaluation & Adaptation: Developed an AI-based evaluator to assess user\n",
       "responses, generate adaptive follow-ups, and track discussion depth.\",\n",
       "    \"0.responsibilities.3\": \"State & Topic Management: Built a stateful tracking system to guide conversations, handle\n",
       "topic transitions, and prevent redundancy.\",\n",
       "    \"0.responsibilities.4\": \"Asynchronous AI Integration: Optimized API performance for OpenAI GPT-4 & Anthropic Claude\n",
       "using AsyncIO, improving efficiency and scalability.\",\n",
       "    \"1.responsibilities.0\": \"Provided strategic insights to a major global IT vendor, optimizing their service partner\n",
       "ecosystem in Asia Pacific for improved local implementation outcomes.\",\n",
       "    \"1.responsibilities.1\": \"Assisted a U.S.-based international services provider in its growth strategy by precisely\n",
       "evaluating and scaling new engineering service opportunities in vital emerging markets.\",\n",
       "    \"1.responsibilities.2\": \"Co-authored an industry-recognized report on M&A in the engineering services sector,\n",
       "offering deep dives into deal sizes, capability gaps, and emerging opportunities, influencing strategic decisions in IT\n",
       "and operational technology convergence.\",\n",
       "    \"1.responsibilities.3\": \"Enhanced data quality and consistency by integrating thorough financial analysis,\n",
       "standardizing methodologies, and conducting in-depth vendor engagements.\",\n",
       "    \"1.responsibilities.4\": \"Achieved over 40% centralization of tasks to an offshore team in India, optimizing resource\n",
       "allocation.\",\n",
       "    \"1.responsibilities.5\": \"Developed Python tools to automate and accelerate internal processes, cutting report\n",
       "preparation and data analysis time by over 40%.\",\n",
       "    \"1.responsibilities.6\": \"Collaborated with the engineering services research team to pioneer the engineering\n",
       "services tracker, authored influential publications on market forecasts, the impact of COVID-19 on services, and trends\n",
       "in M&A within the engineering services industry.\",\n",
       "    \"1.responsibilities.7\": \"Collaborated with analyst teams across the globe (US, Canada, Latin America, Europe, MEA,\n",
       "APAC) to ensure data quality, meeting deadlines, sharing knowledge/best practices/methodology, and procure new tools.\",\n",
       "    \"2.responsibilities.0\": \"Full P&L management including budgeting, HR, vendors, partnerships, research, and business\n",
       "development: expanded the programs' bookings by more than 50%.\",\n",
       "    \"2.responsibilities.1\": \"Expanded and managed a global research team of more than 15 (US, India, and Mexico).\",\n",
       "    \"2.responsibilities.2\": \"Led an external software development team to build and implement new tools.\",\n",
       "    \"2.responsibilities.3\": \"Championed new technology projects using ML, NLP, chatbot, ontology, web-scraping, API, UX\n",
       "(User Experience). First in IDC to implement ML (machine learning). First to launch a chatbot. First to implement API\n",
       "(application programming interface). First to build an ontology.\",\n",
       "    \"2.responsibilities.4\": \"Led a team to develop automated tools in Python, reducing report preparation time by 40%.\",\n",
       "    \"2.responsibilities.5\": \"Advised services firms on deal pursuit and sales orchestration strategies.\",\n",
       "    \"2.responsibilities.6\": \"Advised software vendors on services partnership strategy.\",\n",
       "    \"2.responsibilities.7\": \"Authored reports, blogs, presentations, & custom researches in go-to-market strategy, deal\n",
       "signing analysis, renewal analysis, buyer studies, technology adoptions (cloud, AI, ML, digital, etc.), and industry\n",
       "trend analysis.\",\n",
       "    \"3.responsibilities.0\": \"Delivered quarterly webinars on outsourcing/managed services signing trends.\",\n",
       "    \"3.responsibilities.1\": \"Authored 7 to 10 pursuit strategy reports and industry trend research documents.\",\n",
       "    \"4.responsibilities.0\": \"Designed and architected a complex company database with 100K+ unique records and\n",
       "integrating DnB API and internal databases, which reduced data duplication by 50%.\",\n",
       "    \"4.responsibilities.1\": \"Oversaw two Appian implementations that increased team productivity by 20 to 30%.\",\n",
       "    \"4.responsibilities.2\": \"Managed daily content operations, including leading a team of offshore and nearshore\n",
       "content team, as well as other sales and research related activities.\",\n",
       "    \"4.responsibilities.3\": \"Analyzed and Modeled 20 to 30 IT vendors' financials and over 1,500 services contracts.\",\n",
       "    \"4.responsibilities.4\": \"Managed three major data integration projects critical to the launch of the new platform.\",\n",
       "    \"4.responsibilities.5\": \"Promoted from Senior Research Analyst to Research Manager in February 2007.\",\n",
       "    \"5.responsibilities.0\": \"Researched market dynamics in the Web Services Security market to support product\n",
       "strategy.\"\n",
       "  }\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = r\"C:\\github\\job_bot\\input_output\\human_review\\resps_reqs_matching\\reviewed_matchings\\Blend_Director__AI_Strategy_crosstab_reviewed.xlsx\"\n",
    "sheet_name = \"Crosstab\"\n",
    "\n",
    "wb, sheet = load_excel_sheet(file_path, sheet_name)\n",
    "df = get_underlined_cells(sheet)\n",
    "cleaned_df = clean_and_remove_rows(df)\n",
    "final_df = rename_dataframe_columns(cleaned_df)\n",
    "\n",
    "final_df.drop(\"edited_responsibility_1\", axis=1, inplace=True)\n",
    "# print(final_df)\n",
    "\n",
    "json_string = final_df.to_json()\n",
    "json_data = json.loads(json_string)  # Convert string to dictionary\n",
    "\n",
    "print(\"JSON: original\")\n",
    "display_json_pretty(json_data)\n",
    "\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON format: edited by LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON String:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"edited_responsibility_1\": {\n",
       "    \"0.responsibilities.0\": \"Engineered the core dialogue system to generate dynamic questions, evaluate responses, and\n",
       "maintain conversation flow, driving substantial business value and revenue growth through strategic AI initiatives.\",\n",
       "    \"0.responsibilities.1\": \"Led the design and deployment of AI-powered solutions to drive ideation, thought\n",
       "generation, and business innovation. Developed hierarchical idea expansion, clustering, and ranking pipelines to unlock\n",
       "new insights and opportunities.\",\n",
       "    \"0.responsibilities.2\": \"Led the development of AI-powered systems that analyze user feedback, generate dynamic\n",
       "responses, and monitor conversation depth. Collaborative leadership approach focused on continuous improvement and team\n",
       "development.\",\n",
       "    \"0.responsibilities.3\": \"Led the design and implementation of a stateful tracking system to facilitate seamless\n",
       "topic management and enhance conversational efficiency. Leveraged analytical and problem-solving skills to guide\n",
       "discussions, enable smooth transitions, and ensure overall conversational effectiveness.\",\n",
       "    \"0.responsibilities.4\": \"Led the optimization of high-performance AI systems, leveraging cutting-edge technologies\n",
       "like AsyncIO to enhance the scalability and efficiency of large language models such as OpenAI GPT-4 and Anthropic\n",
       "Claude. Brings a collaborative leadership approach and a growth-oriented mindset to drive continuous improvement and\n",
       "innovation.\",\n",
       "    \"1.responsibilities.0\": \"Led strategic initiatives to optimize the service partner ecosystem of a leading global IT\n",
       "vendor in the Asia Pacific region, driving improved local implementation outcomes and demonstrating strong analytical\n",
       "and problem-solving capabilities.\",\n",
       "    \"1.responsibilities.1\": null,\n",
       "    \"1.responsibilities.2\": null,\n",
       "    \"1.responsibilities.3\": \"Led comprehensive financial analysis and process standardization initiatives, driving data\n",
       "integrity and uniformity through extensive vendor collaborations. Demonstrated a collaborative leadership style focused\n",
       "on continuous improvement and growth.\",\n",
       "    \"1.responsibilities.4\": \"Led centralized task management initiatives, achieving over 40% offshoring to leverage\n",
       "global talent and drive operational efficiency. Cultivated a collaborative, growth-oriented team environment.\",\n",
       "    \"1.responsibilities.5\": null,\n",
       "    \"1.responsibilities.6\": \"Pioneered the engineering services tracker as part of the research team. Authored\n",
       "influential publications on market forecasts, the impact of COVID-19 on services, and trends in M&A within the\n",
       "engineering services industry. Demonstrated strong communication and collaboration skills, adept at working effectively\n",
       "with cross-functional teams.\",\n",
       "    \"1.responsibilities.7\": \"Led global analyst teams to ensure data integrity, meet critical deadlines, share\n",
       "expertise, and procure innovative tools. Drove successful implementation of AI solutions in a business environment.\",\n",
       "    \"2.responsibilities.0\": \"Seasoned professional who led full P&L management, driving significant growth by expanding\n",
       "program bookings over 50%. Demonstrated expertise in budgeting, HR, vendor relations, partnerships, research, and\n",
       "business development. Possesses a deep understanding of AI technologies and their business applications.\",\n",
       "    \"2.responsibilities.1\": \"Led and grew a multicultural research team with a collaborative, growth-focused approach.\",\n",
       "    \"2.responsibilities.2\": \"Led external software development teams to conceptualize and implement cutting-edge\n",
       "solutions, leveraging strong communication and collaboration abilities to drive cross-functional alignment.\",\n",
       "    \"2.responsibilities.3\": \"Innovative technology leader who championed transformative solutions leveraging cutting-\n",
       "edge tools like machine learning, natural language processing, chatbots, ontologies, web scraping, and APIs. Drove\n",
       "substantial business value and revenue growth as the first in the organization to implement these advanced technologies,\n",
       "including launching a chatbot and building an ontology.\",\n",
       "    \"2.responsibilities.4\": \"Led a team in developing automated Python tools, driving a 40% reduction in report\n",
       "preparation time. Demonstrated a collaborative approach focused on continuous improvement and a growth-oriented\n",
       "mindset.\",\n",
       "    \"2.responsibilities.5\": \"Advised services firms on deal pursuit and sales orchestration strategies, leveraging\n",
       "excellent communication and interpersonal skills to collaborate effectively with cross-functional teams.\",\n",
       "    \"2.responsibilities.6\": \"Leveraged strong communication and interpersonal skills to develop strategic software\n",
       "partnerships by collaborating effectively across diverse teams.\",\n",
       "    \"2.responsibilities.7\": \"Led the creation of impactful content, including reports, blogs, presentations, and custom\n",
       "research, to drive strategic initiatives across areas such as go-to-market strategy, deal analysis, customer insights,\n",
       "and technology trends. Demonstrated a collaborative leadership approach and a growth-oriented mindset.\",\n",
       "    \"3.responsibilities.0\": null,\n",
       "    \"3.responsibilities.1\": \"Authored strategic reports and industry analyses, demonstrating strong communication and\n",
       "collaboration skills.\",\n",
       "    \"4.responsibilities.0\": \"Designed and implemented a comprehensive enterprise-level database system, integrating\n",
       "multiple internal and external data sources to enhance data integrity and reduce duplication by a significant margin.\n",
       "Demonstrated strong communication and technical expertise in delivering this complex project, working effectively with\n",
       "cross-functional teams.\",\n",
       "    \"4.responsibilities.1\": \"Led successful Appian implementations that enhanced team productivity.\",\n",
       "    \"4.responsibilities.2\": \"Led cross-functional content teams and oversaw daily content operations, including sales\n",
       "and research-focused initiatives. Demonstrated proficiency in analytical problem-solving and data-driven decision-\n",
       "making.\",\n",
       "    \"4.responsibilities.3\": \"Analyzed financials of 20-30 IT service providers and managed a portfolio of over 1,500\n",
       "contracts, leveraging advanced analytical and financial modeling skills to provide in-depth insights. Demonstrated a\n",
       "collaborative leadership approach and a growth-oriented mindset in driving strategic decision-making.\",\n",
       "    \"4.responsibilities.4\": \"Led the successful delivery of three mission-critical data integration projects that\n",
       "enabled the launch of a new enterprise-level platform. Drove large-scale AI strategy and implementation initiatives at\n",
       "the enterprise level.\",\n",
       "    \"4.responsibilities.5\": null,\n",
       "    \"5.responsibilities.0\": null\n",
       "  }\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = r\"C:\\github\\job_bot\\input_output\\human_review\\resps_reqs_matching\\reviewed_matchings\\Blend_Director__AI_Strategy_crosstab_reviewed.xlsx\"\n",
    "sheet_name = \"Crosstab\"\n",
    "\n",
    "wb, sheet = load_excel_sheet(file_path, sheet_name)\n",
    "\n",
    "df = get_underlined_cells(sheet)\n",
    "cleaned_df = clean_and_remove_rows(df)\n",
    "\n",
    "final_df = rename_dataframe_columns(cleaned_df)\n",
    "final_df.drop(\"original_responsibility\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# print(final_df)\n",
    "json_string = final_df.to_json()\n",
    "# json_data = json.loads(json_string)  # Convert string to dictionary\n",
    "\n",
    "print(\"JSON String:\")\n",
    "\n",
    "# # Format JSON for readability\n",
    "# formatted_json = format_json_readable(json_data, wrap_width=120)\n",
    "\n",
    "# # Display with Markdown to prevent horizontal scrolling\n",
    "# display(Markdown(f\"```json\\n{formatted_json}\\n```\"))\n",
    "\n",
    "\n",
    "display_json_pretty(json_string)\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final trim & edit by GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed and Condensed by GPT:\n",
      "Word count: 273\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"edited_responsibility_1\": {\n",
       "    \"0.responsibilities.0\": \"Developed AI-driven dialogue systems optimizing user engagement and revenue growth.\",\n",
       "    \"0.responsibilities.1\": \"Designed AI solutions for ideation and business innovation, leveraging hierarchical\n",
       "clustering and ranking algorithms.\",\n",
       "    \"0.responsibilities.2\": \"Built AI-powered feedback analysis systems to enhance response generation and conversation\n",
       "tracking.\",\n",
       "    \"0.responsibilities.3\": \"Implemented stateful tracking for seamless topic management, improving discussion flow and\n",
       "engagement.\",\n",
       "    \"0.responsibilities.4\": \"Optimized large-scale AI systems using AsyncIO for enhanced scalability and efficiency.\",\n",
       "    \"1.responsibilities.0\": \"Led strategic initiatives optimizing IT vendor ecosystems in APAC, improving implementation\n",
       "outcomes.\",\n",
       "    \"1.responsibilities.3\": \"Standardized financial analysis and vendor collaborations, improving data integrity and\n",
       "decision-making.\",\n",
       "    \"1.responsibilities.4\": \"Achieved 40% operational offshoring to enhance global talent utilization and efficiency.\",\n",
       "    \"1.responsibilities.6\": \"Developed an engineering services tracker, publishing key reports on market trends and M&A\n",
       "activity.\",\n",
       "    \"1.responsibilities.7\": \"Led global analyst teams to maintain data integrity, meet deadlines, and integrate AI-\n",
       "driven business insights.\",\n",
       "    \"2.responsibilities.0\": \"Managed full P&L, driving 50% program growth and leading strategy in budgeting, HR, and\n",
       "vendor relations.\",\n",
       "    \"2.responsibilities.1\": \"Grew a multicultural research team, fostering a collaborative, high-performance\n",
       "environment.\",\n",
       "    \"2.responsibilities.2\": \"Directed external development teams to design and implement cutting-edge AI solutions.\",\n",
       "    \"2.responsibilities.3\": \"Pioneered ML, NLP, chatbots, and ontologies, significantly advancing AI adoption within the\n",
       "organization.\",\n",
       "    \"2.responsibilities.4\": \"Led automation initiatives in Python, reducing report preparation time by 40%.\",\n",
       "    \"2.responsibilities.5\": \"Advised services firms on strategic deal pursuit and sales orchestration.\",\n",
       "    \"2.responsibilities.6\": \"Developed strategic software partnerships through cross-functional collaboration.\",\n",
       "    \"2.responsibilities.7\": \"Created high-impact content including reports, blogs, and presentations to drive business\n",
       "insights.\",\n",
       "    \"3.responsibilities.1\": \"Authored strategic industry reports, delivering high-impact insights to executive\n",
       "stakeholders.\",\n",
       "    \"4.responsibilities.0\": \"Designed an enterprise-level database, integrating multiple data sources to enhance data\n",
       "integrity.\",\n",
       "    \"4.responsibilities.1\": \"Led Appian implementations improving team productivity.\",\n",
       "    \"4.responsibilities.2\": \"Managed cross-functional content teams overseeing research and sales-focused content\n",
       "strategies.\",\n",
       "    \"4.responsibilities.3\": \"Analyzed financials of 20+ IT service providers, managing a portfolio of 1,500+\n",
       "contracts.\",\n",
       "    \"4.responsibilities.4\": \"Delivered three critical data integration projects, enabling enterprise-level AI adoption.\"\n",
       "  }\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = r\"C:\\github\\job_bot\\input_output\\human_review\\resps_reqs_matching_trimmed\\Blend_Director__AI_Strategy_crosstab_trimmed.json\"\n",
    "\n",
    "data = load_and_decode_json(file_path)\n",
    "\n",
    "word_count = 0\n",
    "\n",
    "\n",
    "# Iterate through the values of the JSON object\n",
    "def count_words(data):\n",
    "    word_count = 0\n",
    "    for v in data.values():\n",
    "        if isinstance(v, dict):\n",
    "            word_count += count_words(v)\n",
    "        elif isinstance(v, str):\n",
    "            word_count += len(v.split())\n",
    "    return word_count\n",
    "\n",
    "\n",
    "word_count = count_words(data)\n",
    "\n",
    "\n",
    "print(\"Trimmed and Condensed by GPT:\")\n",
    "print(f\"Word count: {word_count}\")\n",
    "\n",
    "\n",
    "# word_count = sum(len(v.split()) for v in data.values())\n",
    "\n",
    "\n",
    "display_json_pretty(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed and Condensed by GPT:\n",
      "Word count: 0\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\github\\job_bot\\input_output\\human_review\\resps_reqs_matching_trimmed\\Blend_Director__AI_Strategy_crosstab_trimmed.json\"\n",
    "\n",
    "data = load_and_decode_json(file_path)\n",
    "\n",
    "word_count = sum(len(v.split()) for v in data.values() if isinstance(v, str))\n",
    "\n",
    "print(\"Trimmed and Condensed by GPT:\")\n",
    "print(f\"Word count: {word_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoDB_Director_Competitive_Intelligence\n",
      "Adobe_Sr._Director_Applied_AI/ML_(Discovery)\n",
      "Flextronics_Sr._Manager_AI_Strategy\n",
      "TRACE3_Senior_Consultant_AI_Strategy_(Remote)\n",
      "PwC_Strategy&_Senior_Manager_-_Digital_Value_Transformation_Contact_Center\n",
      "Glean_Head_of_Competitive_Intelligence\n",
      "Airtable_Product_Manager_AI\n",
      "Veeva_Director_-_Crossix_Analytics_Services\n",
      "ThermoFisher_Scientific_Market_&_Competitive_Intelligence_Manager\n",
      "DigitialOcean_Director_Product_Management_(AI/ML)\n",
      "Figma_Researcher_Strategic_Growth\n",
      "DEPT_Director_of_Applied_AI_Strategy_Media\n",
      "Deloitte_Market_Research_Sr_Manager_Boston\n",
      "Deloitte_AI_Data_Specialist_Boston\n",
      "Deloitte_Global_Business_Services_(GBS)_Strategy_Manager_Boston\n",
      "Amazon_Senior_Manger_Partner_Strategy_GenAI_Innovation_Center\n",
      "Blend_Director_AI_Strategy\n",
      "Snowflake_Director_Product_Marketing_-_Analytics\n",
      "Advisor360_Degrees_Sr._Product_Manager_–_AI_Analytics_&Insights\n",
      "Oracle_Senior_AI_Product_Marketing_Manager\n",
      "Liberty_Mutual_Insurance_Senior_Manager_II_Corporate_Strategy_&_Research\n",
      "Accenture_Enterprise_AI_Value_Strategy_Senior_Manager\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, float found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(f_path)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m co, job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df\u001b[38;5;241m.\u001b[39mCompany, df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob Title\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m----> 7\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([co, job])\n\u001b[0;32m      8\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, float found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "f_path = r\"C:\\Users\\xzhan\\My Drive\\Job Search\\Job Search 2025.xlsx\"\n",
    "\n",
    "df = pd.read_excel(f_path)\n",
    "for co, job in zip(df.Company, df[\"Job Title\"]):\n",
    "    text = \"_\".join([co, job])\n",
    "    text = text.replace(\" \", \"_\")\n",
    "    text = text.replace(\",\", \"\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".monaco-workbench .notebook-cell .output pre {\n",
       "    font-size: 24px !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'This text should be bigger'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'key': 'value'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1: Set style\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        \"\"\"\n",
    "<style>\n",
    ".monaco-workbench .notebook-cell .output pre {\n",
    "    font-size: 24px !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Cell 2: Test\n",
    "display(\"This text should be bigger\")\n",
    "display({\"key\": \"value\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
