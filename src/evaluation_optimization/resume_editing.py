"""
File: resume_editing.py
Author: Xiao-Fei Zhang
Last updated: 2024 Sep 12
"""

import logging
from dotenv import load_dotenv
import os
import json
import openai
import jsonschema
import uuid
import logging_config
from prompts.prompt_templates import (
    SEMANTIC_ALIGNMENT_PROMPT,
    STRUCTURE_TRANSFER_PROMPT,
)
from utils.llm_data_utils import get_openai_api_key
from utils.validation_utils import validate_json_response
from utils.llm_data_utils import call_openai_api
from base_models import JSONResponse

# logging
logger = logging.getLogger(__name__)

# Get openai api key
openai.api_key = get_openai_api_key()

# Define the JSON schema somewhere accessible
LLM_RES_JSON_SCHEMA = {
    "type": "object",
    "properties": {
        "optimized_text": {"type": "string"},
    },
    "required": ["optimized_text"],
}


def edit_text_for_semantic_entailment(
    client,
    candidate_text,
    reference_text,
    text_id=None,
    model_id="gpt-4-turbo",
    temperature=0.6,
    max_tokens=1056,
):
    """

    Edits and optimizes text using OpenAI API based on a given requirement.

    Args:
        - client: OpenAI API client instance.
        - text_id (int): (Optional) Identifier for the responsibility text.
        Default to None (unique ids to be generated with UUID function)
        - candidate_text (str): Original text to be transformed by the model
        (i.e., the riginal responsibility text to be revised.)
        - reference_text (str): Text that the candidate text is being compared to
        (i.e., requirement text to optimize against.)
        - model_id (str): Model ID to use for the OpenAI API call
        (gpt-3.5-turbo, gpt-4-turbo, etc.)
        - max_tokens: default set to 1056

    Returns:
        dict: Contains 'resp_id' and 'optimized_text' after revision.
    """
    # Generate a unique text_id using UUID
    if text_id is None:
        text_id = str(uuid.uuid4())

    # Format the prompt using a predefined template
    try:
        prompt = SEMANTIC_ALIGNMENT_PROMPT.format(
            content_1=candidate_text, content_2=reference_text
        )
    except KeyError as e:
        logger.error(f"Error formatting STRUCTURE_TRANSFER_PROMPT: {e}")
        raise

    # Call api function and get response; deserialize from pydantic obj to dict
    response_pyd_obj = call_openai_api(
        client,
        model_id,
        prompt,
        expected_res_type="json",
        temperature=temperature,
        max_tokens=max_tokens,
    )

    # Ensure the response is in the correct format (Pydantic JSONResponse model)
    if not isinstance(response_pyd_obj, JSONResponse):
        logger.error("Received response is not in expected JSONResponse format.")
        raise ValueError("Received response is not in expected JSONResponse format.")

    # Deserialize pydantic obj. (expect a dictionary)
    response_dict = response_pyd_obj.model_dump()
    # print(f"final text: {response_dict}")

    # Validate the JSON structure using JSON Schema
    try:
        jsonschema.validate(instance=response_dict, schema=LLM_RES_JSON_SCHEMA)
        logger.info("JSON schema validation passed.")
    except jsonschema.exceptions.ValidationError as e:
        logger.error(f"JSON schema validation failed: {e}")
        raise ValueError(f"Invalid JSON format: {e}")

    # Combine w/t id, then return the combined dictionary
    result = {"resp_id": text_id, **response_dict}  # ** to unpack a dictionary

    logger.info(f"Results updated: \n{result}")
    return result


def edit_text_for_dp(
    client,
    target_text,
    source_text,
    text_id=None,
    model_id="gpt-4-turbo",
    temperature=0.8,
    max_tokens=1056,
):
    """
    Re-edit the target text to better align w/t source text's dependency parsing (DP),
    leveraging the OpenAI API.

    Example:
    Re-edit revised responsibility to match with the original responsibility text's DP
    to perserve the tone & style.

    Args:
        - client (OpenAI()): OpenAI API client instance.
        - text_id (str): Identifier of the target text (defaulted to None - unique IDs
        to be generated by UUID function)
        (i.e., the responsibility bullet text.)
        - target_text (str): The target text to be transformed (i.e.,
        revised responsibility text).
        - source_text (str): The source text from whose "dependency parsing"
        to be modeled after (i.e., original responsibility text from resume).
        - model_id (str): OpenAI model to use (default is 'gpt-4').
        - temperature (float): defaulted to 0.8 (a higher temperature setting is
        needed to give the model more flexibility/creativity).
        - max_token: default to 1056

        Note:
        - resp is short for responsibility
        - req is short for (job) requirement

    Returns:
        dict: A dictionary in the format of {'resp_id': "...", 'optimized_text': "..."}.
    """
    # Generate a unique text_id using UUID
    if text_id is None:
        text_id = str(uuid.uuid4())

    # Define the JSON schema and instructions clearly in the prompt
    try:
        prompt = STRUCTURE_TRANSFER_PROMPT.format(
            content_1=source_text, content_2=target_text
        )
        print(f"DEBUG - Formatted Prompt in edit_text_for_dp:\n{prompt}")
    except KeyError as e:
        logger.error(f"Error formatting STRUCTURE_TRANSFER_PROMPT: {e}")
        raise

    # Call API function and get response; deserialize from pydantic obj to dict
    response_pyd_obj = call_openai_api(
        client,
        model_id,
        prompt,
        expected_res_type="json",
        temperature=temperature,
        max_tokens=max_tokens,
    )

    # Ensure the response is in the correct format (Pydantic JSONResponse model)
    if not isinstance(response_pyd_obj, JSONResponse):
        logger.error("Received response is not in expected JSONResponse format.")
        raise ValueError("Received response is not in expected JSONResponse format.")

    # Deserialize pydantic obj. (expect a dictionary)
    response_dict = response_pyd_obj.model_dump()

    # Validate the JSON structure using JSON Schema
    try:
        jsonschema.validate(instance=response_dict, schema=LLM_RES_JSON_SCHEMA)
        logger.info("JSON schema validation passed.")
    except jsonschema.exceptions.ValidationError as e:
        logger.error(f"JSON schema validation failed: {e}")
        raise ValueError(f"Invalid JSON format: {e}")

    # Combine w/t id, then return the combined dictionary
    result = {"resp_id": text_id, **response_dict}  # ** to unpack a dictionary

    logger.info(f"Results updated: \n{result}")
    return result


# Function to modify resume w/t ChatGPT (unfinished...)
def modify_resume_section(section_json, requirements, model_id="gpt-3.5-turbo"):
    """
    Modifies a specific section of the resume to better align with job requirements.

    Args:
        section_json (dict): The JSON object containing the resume section details.
        requirements (dict): The extracted requirements from the job description.
        model_id (str): The model ID for OpenAI (default is gpt-3.5-turbo).

    Returns:
        dict: Modified resume section.
    """
    prompt = (
        f"Modify the following resume section in JSON format to better align with the job requirements. "
        f"Make it more concise and impactful while highlighting relevant skills and experiences:\n\n"
        f"Current Section JSON:\n{section_json}\n\n"
        f"Job Requirements JSON:\n{requirements}\n\n"
        "Return the modified section in JSON format."
    )

    response = openai.chat.completions.create(
        model=model_id, messages=[{"role": "user", "content": prompt}], temperature=0.7
    )

    return json.loads(response["choices"][0]["message"]["content"])
